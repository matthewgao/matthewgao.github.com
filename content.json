[{"title":"再见2016","date":"2016-12-31T03:50:05.000Z","path":"分布式锁/","text":"0x01 简介 数据库 KV cache zookeeper 0x02 数据库上面这种简单的实现有以下几个问题： 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 当然，我们也可以有其他方式解决上面的问题。 数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。非阻塞的？搞一个while循环，直到insert成功再返回成功。非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。 基于数据库排他锁 除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。 我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作： 123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125; 在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。 我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁： 123public void unlock()&#123; connection.commit();&#125; 通过connection.commit()操作来释放锁。 这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。 阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。但是还是无法直接解决数据库单点和可重入问题。 这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。 还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆 ###总结 总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。 数据库实现分布式锁的优点直接借助数据库，容易理解。 数据库实现分布式锁的缺点会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。操作数据库需要一定的开销，性能问题需要考虑。使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。 0x03 KV cache相比较于基于数据库实现分布式锁的方案来说，基于缓存来实现在性能方面会表现的更好一点。而且很多缓存是可以集群部署的，可以解决单点问题。 目前有很多成熟的缓存产品，包括Redis，memcached以及我们公司内部的Tair。 这里以Tair为例来分析下使用缓存实现分布式锁的方案。关于Redis和memcached在网络上有很多相关的文章，并且也有一些成熟的框架及算法可以直接使用。 基于Tair的实现分布式锁其实和Redis类似，其中主要的实现方式是使用TairManager.put方法来实现。 12345678910public boolean trylock(String key) &#123; ResultCode code = ldbTairManager.put(NAMESPACE, key, \"This is a Lock.\", 2, 0); if (ResultCode.SUCCESS.equals(code)) return true; else return false;&#125;public boolean unlock(String key) &#123; ldbTairManager.invalid(NAMESPACE, key);&#125; 以上实现方式同样存在几个问题： 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在tair中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，无论成功还是失败都直接返回。 这把锁是非重入的，一个线程获得锁之后，在释放锁之前，无法再次获得该锁，因为使用到的key在tair中已经存在。无法再执行put操作。 当然，同样有方式可以解决。 没有失效时间？tair的put方法支持传入失效时间，到达时间之后数据会自动删除。非阻塞？while重复执行。非可重入？在一个线程获取到锁之后，把当前主机信息和线程信息保存起来，下次再获取之前先检查自己是不是当前锁的拥有者。但是，失效时间我设置多长时间为好？如何设置的失效时间太短，方法没等执行完，锁就自动释放了，那么就会产生并发问题。如果设置的时间太长，其他获取锁的线程就可能要平白的多等一段时间。这个问题使用数据库实现分布式锁同样存在 总结可以使用缓存来代替数据库来实现分布式锁，这个可以提供更好的性能，同时，很多缓存服务都是集群部署的，可以避免单点问题。并且很多缓存服务都提供了可以用来实现分布式锁的方法，比如Tair的put方法，redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。 使用缓存实现分布式锁的优点性能好，实现起来较为方便。 使用缓存实现分布式锁的缺点通过超时时间来控制锁的失效时间并不是十分的靠谱。 0x04 zookeeper使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。 其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。）","tags":[{"name":"生活","slug":"生活","permalink":"http://matthewgao.github.io/tags/生活/"}]},{"title":"Golang Note","date":"2016-12-02T15:40:07.000Z","path":"go/","text":"TIP Go command executables are statically linked; the package objects need not be present to run Go programs. package name 最好和folder名字一致 Executable commands must always use package main. You write a test by creating a file with a name ending in _test.go that contains functions named TestXXX with signature func (t *testing.T). The test framework runs each such function; if the function calls a failure function such as t.Error or t.Fail, the test is considered to have failed. 在 Go 中，首字母大写的名称是被导出的。在导入包之后，你只能访问包所导出的名字，任何未导出的名字是不能被包外的代码访问的。Foo 和 FOO 都是被导出的名称。名称 foo 是不会被导出的。 函数可以返回任意数量的返回值 没有参数的 return 语句返回各个返回变量的当前值。这种用法被称作“裸”返回。 变量定义可以包含初始值，每个变量对应一个。如果初始化是使用表达式，则可以省略类型；变量从初始值中获得类型。 在函数中， := 简洁赋值语句在明确类型的地方，可以用于替代 var 定义。函数外的每个语句都必须以关键字开始（ var 、 func 、等等）， := 结构不能使用在函数外。 变量在定义时没有明确的初始化时会赋值为 零值 。 与 C 不同的是 Go 的在不同类型之间的项目赋值时需要显式转换。 试着移除例子中 float64 或 int 的转换看看会发生什么。 如果函数参数是指针那么go可以自动转指针即便传入的是值 struct{}通常被用作占位符，就是一个空对象 break labal和goto不同，前者不会再进入循环/switch 内嵌函数不能以func func_name(){}来声明，只能func_name := func() {} duck type？ shadow value: 实际上就是短声明时候的覆盖问题，你可以使用 vet 命令来发现一些这样的问题。 默认情况下，vet不会执行这样的检查，你需要设置-shadow参数：go tool vet -shadow your_file.go 你不能在一个单独的声明中重复声明一个变量，但在多变量声明中这是允许的，其中至少要有一个新的声明变量。 字符串不会为nil x [3]int是数组， x []int是slice，slice是按照传引用？如同python里面的list/dist 以小写字母开头的结构体将不会被（json、xml、gob等）编码，因此当你编码这些未导出的结构体时，你将会得到零值。 在一个nil的channel上发送和接收操作会被永久阻塞。这个行为有详细的文档解释，但它对于新的Go开发者而言是个惊喜。 如果结构体中的各个元素都可以用你可以使用等号来比较的话，那就可以使用相号, ==，来比较结构体变量。 DeepEqual()不会认为空的slice与“nil”的slice相等。这个行为与你使用bytes.Equal()函数的行为不同。bytes.Equal()认为“nil”和空的slice是相等的。 在“range”语句中生成的数据的值是真实集合元素的拷贝。它们不是原有元素的引用。这意味着更新这些值将不会修改原来的数据。同时也意味着使用这些值的地址将不会得到原有数据的指针。 当你重新划分一个slice时，新的slice将引用原有slice的数组。如果你忘了这个行为的话，在你的应用分配大量临时的slice用于创建新的slice来引用原有数据的一小部分时，会导致难以预期的内存使用（因为重新划分的slice占用大小还是原来的大小, 尽管只取了一小部分）。为了避免这个陷阱，你需要从临时的slice中拷贝数据（而不是重新划分slice）。 for语句中的迭代变量在每次迭代时被重新使用。这就意味着你在for循环中创建的闭包（即函数字面量）将会引用同一个变量（而在那些goroutine开始执行时就会得到那个变量的值）。 被defer的函数的参数会在defer声明时求值（而不是在函数实际执行时） 然而并不是所有的变量是可取址的。Map的元素就不是。通过interface引用的变量也不是， 如果你有一个struct值的map，你无法更新单个的struct值，原因就是因为他不可取指，解决方法：第一个有效的方法是使用一个临时变量，另一个有效的方法是使用指针的map。 如果你想知道变量分配的位置，在“go build”或“go run”上传入“-m“ gc标志（即，go run -gcflags -m app.go） 可以显式的唤醒调度器runtime.Gosched() iota bytes.Buffer =&gt; StringBuilder 用来拼接字符串 返回值可以返回局部变量的指针，因为go的变量不是组织在栈中的，所以只要有引用他就不会再内存中被回收 new(TYPE) === &amp;TYPE{} 引用类型： map，slice，channel, func, 方法 append(s, t...) 把t切片中所有值拼放到s里 switch x.(type) 用于判断类型 Memorize 函数 类似于python里的LRU []Printable{&amp;b, d} 声明一个接口slice，包含两个接口实现 append一个slice会可能导致cap自动变长，变长之后slice的索引会改变，所以之前生成的subslice不会得到后续的更改 type FakeString string FakeString不会自动转string，但是string可以自动转FakeString type assert 只适用于inferface，其他的还是要用type cast nil可以赋值给任何指针或引用类型的变量 new返回的是指针，不初始化属性，make是返回值 context 如果不cancel 父context是不会捕获到done的 go run file.go可以运行go，但是如果目录下有unittest，那么多说情况下还是会出错，所以go通常不适合单独运行，shebang可以让你以近似解析式语言的方式来运行go 同一个目录不能有多个package，目录名字和pacakge可以不一样 When storage is allocated for a variable, either through a declaration or a call of new, or when a new value is created, either through a composite literal or a call of make, and no explicit initialization is provided, the variable or value is given a default value. Each element of such a variable or value is set to the zero value for its type: false for booleans, 0 for integers, 0.0 for floats, “” for strings, and nil for pointers, functions, interfaces, slices, channels, and maps. This initialization is done recursively, so for instance each element of an array of structs will have its fields zeroed if no value is specified. json.Marshal 可以用过设置tag json:&quot;my_name, omitempty&quot; 来跳过某个空字段 使用string(120) 是把整型换成他对应的ascii码，应该用strconv.Itoa(120) When you have a struct implementing an interface, a pointer to that struct implements automatically that interface too. That’s why you never have *SomeInterface in the prototype of functions, as this wouldn’t add anything to SomeInterface, and you don’t need such a type in variable declaration TODO slice复制，赋值等 structstruct的tag使用\\``和“` 是一个意思 A field declared with a type but no explicit field name is an anonymous field, also called an embedded field or an embedding of the type in the struct. An embedded type must be specified as a type name T or as a pointer to a non-interface type name *T, and T itself may not be a pointer type. The unqualified type name acts as the field name. 12345678// A struct with four anonymous fields of type T1, *T2, P.T3 and *P.T4struct &#123; T1 // field name is T1 *T2 // field name is T2 P.T3 // field name is T3 *P.T4 // field name is T4 x, y int // field names are x and y&#125; A field or method f of an anonymous field in a struct x is called promoted if x.f is a legal selector that denotes that field or method f. Promoted fields act like ordinary fields of a struct except that they cannot be used as field names in composite literals of the struct. Given a struct type S and a type named T, promoted methods are included in the method set of the struct as follows: If S contains an anonymous field T, the method sets of S and S both include promoted methods with receiver T. The method set of S also includes promoted methods with receiver *T. If S contains an anonymous field T, the method sets of S and S both include promoted methods with receiver T or *T.A field declaration may be followed by an optional string literal tag, which becomes an attribute for all the fields in the corresponding field declaration. An empty tag string is equivalent to an absent tag. The tags are made visible through a reflection interface and take part in type identity for structs but are otherwise ignored. 12345678910111213struct &#123; x, y float64 \"\" // an empty tag string is like an absent tag name string \"any string is permitted as a tag\" _ [4]byte \"ceci n'est pas un champ de structure\"&#125;// A struct corresponding to a TimeStamp protocol buffer.// The tag strings define the protocol buffer field numbers;// they follow the convention outlined by the reflect package.struct &#123; microsec uint64 `protobuf:\"1\"` serverIP6 uint64 `protobuf:\"2\"`&#125; Concludeinterface是描述一个类型的关键因素，根据duck type，一个对象的方法决定了他的类型, 可以用接口的变量来描述结构（struct），这就好像是CPP里多态的基类指针 interface func (t T)Printer() {} 表示T实现了Printer接口 func (t *T)Printer() {} 表示T指针实现了Printer接口 The value of an uninitialized variable of interface type is nil. select 如果不带default那么如果channal没有内容他会阻塞，然后等有内容后恢复，之后select整个语句执行完成，如果带default那么如果发现阻塞会直接到default执行default，然后结束select整个过程 select 读取chan的时候，在一个case之间他会一直等待返回，chan才有机会读取下一个，也就是说，这个时候写会导致阻塞，小心死锁 constant常量的定义与变量类似，只不过使用 const 关键字。常量可以是字符、字符串、布尔或数字类型的值。常量不能使用 := 语法定义。 switch除非以 fallthrough 语句结束，否则分支会自动终止。没有条件的 switch 同 switch true 一样。这一构造使得可以用更清晰的形式来编写长的 if-then-else 链。 1234567891011func main() &#123; t := time.Now() switch &#123; case t.Hour() &lt; 12: fmt.Println(\"Good morning!\") case t.Hour() &lt; 17: fmt.Println(\"Good afternoon.\") default: fmt.Println(\"Good evening.\") &#125;&#125; array和sliceslice 可以包含任意的类型，包括另一个 slice。slice 可以重新切片，创建一个新的 slice 值指向相同的数组。slice 的零值是 nil 。 12345a := make([]int, 5) // len(a)=5 这会分配一个全是零值的数组并且返回一个 slice 指向这个数组：b := make([]int, 0, 5) // len(b)=0, cap(b)=5b = b[:cap(b)] // len(b)=5, cap(b)=5b = b[1:] // len(b)=4, cap(b)=4 map通过双赋值检测某个键存在：elem, ok = m[key] 如果 key 在 m 中， ok 为 true。否则， ok 为 false，并且 elem 是 map 的元素类型的零值。同样的，当从 map 中读取某个不存在的键时，结果是 map 的元素类型的零值。 嵌套的map slice要一次初始化，不然会entry nil 闭包1234567891011121314151617func adder() func(int) int &#123; sum := 0 return func(x int) int &#123; sum += x return sum &#125;&#125;func main() &#123; pos, neg := adder(), adder() for i := 0; i &lt; 10; i++ &#123; fmt.Println( pos(i), neg(-2*i), ) &#125;&#125; interface类型通过实现那些方法来实现接口。 没有显式声明的必要；所以也就没有关键字“implements“。隐式接口解藕了实现接口的包和定义接口的包：互不依赖。因此，也就无需在每一个实现上增加新的接口名称，这样同时也鼓励了明确的接口定义。 12345678910111213141516171819202122232425package mainimport ( \"fmt\" \"math\")type Abser interface &#123; Abs() float64&#125;func main() &#123; var a Abser f := MyFloat(-math.Sqrt2) v := Vertex&#123;3, 4&#125; a = f // a MyFloat 实现了 Abser a = &amp;v // a *Vertex 实现了 Abser // 下面一行，v 是一个 Vertex（而不是 *Vertex） // 所以没有实现 Abser。 a = v fmt.Println(a.Abs())&#125; deferdefer 语句会延迟函数的执行直到上层函数返回。延迟调用的参数会立刻生成，但是在上层函数返回前函数都不会被调用。延迟的函数调用被压入一个栈中。当函数返回时， 会按照后进先出的顺序调用被延迟的函数调用。12345func main() &#123; defer fmt.Println(\"world\") fmt.Println(\"hello\")&#125; if在 if 的便捷语句定义的变量同样可以在任何对应的 else 块中使用。 1234567891011121314151617181920212223package mainimport ( \"fmt\" \"math\")func pow(x, n, lim float64) float64 &#123; if v := math.Pow(x, n); v &lt; lim &#123; return v &#125; else &#123; fmt.Printf(\"%g &gt;= %g\\n\", v, lim) &#125; // 这里开始就不能使用 v 了 return lim&#125;func main() &#123; fmt.Println( pow(3, 2, 10), pow(3, 3, 20), )&#125; native typebool string int int8 int16 int32 int64uint uint8 uint16 uint32 uint64 uintptr byte // uint8 的别名 rune // int32 的别名 // 代表一个Unicode码 float32 float64 complex64 complex128这个例子演示了具有不同类型的变量。 同时与导入语句一样，变量的定义“打包”在一个语法块中。int，uint 和 uintptr 类型在32位的系统上一般是32位，而在64位系统上是64位。当你需要使用一个整数类型时，你应该首选 int，仅当有特别的理由才使用定长整数类型或者无符号整数类型。 packageGo里面有两个保留的函数：init函数（能够应用于所有的package）和main函数（只能应用于package main）。这两个函数在定义时不能有任何的参数和返回值。虽然一个package里面可以写任意多个init函数，但这无论是对于可读性还是以后的可维护性来说，我们都强烈建议用户在一个package中每个文件只写一个init函数。Go程序会自动调用init()和main()，所以你不需要在任何地方调用这两个函数。每个package中的init函数都是可选的，但package main就必须包含一个main函数。程序的初始化和执行都起始于main包。如果main包还导入了其它的包，那么就会在编译时将它们依次导入。有时一个包会被多个包同时导入，那么它只会被导入一次（例如很多包可能都会用到fmt包，但它只会被导入一次，因为没有必要导入多次）。当一个包被导入时，如果该包还导入了其它的包，那么会先将其它包导入进来，然后再对这些包中的包级常量和变量进行初始化，接着执行init函数（如果有的话），依次类推。等所有被导入的包都加载完毕了，就会开始对main包中的包级常量和变量进行初始化，然后执行main包中的init函数（如果存在的话），最后执行main函数。import 下划线（如：import hello/imp）的作用：当导入一个包时，该包下的文件里所有init()函数都会被执行，然而，有些时候我们并不需要把整个包都导入进来，仅仅是是希望它执行init()函数而已。这个时候就可以使用 import 引用该包。即使用【import _ 包路径】只是引用该包，仅仅是为了调用init()函数，所以无法通过包名来调用包中的其他函数。 内嵌内嵌是不用显式的指出内嵌类型再去调用内嵌结构的方法，而聚合需要子结构中是不能覆盖内嵌结构中的变量的12345678910111213141516type base struct &#123; a int b string&#125;type derive struct &#123; base //内嵌，这里就可以直接找得到print, 自动转换？还是调用的func (b *base) xfunc()&#123;&#125; Base base //这个就不是内嵌，是聚合所以不算是继承关系, 所以他的对象就不能调用到print, 要显式的指出 name string&#125;func (b *base) print(s string) (ret string) &#123; ret = \"aaa\" fmt.Printf(\"base\\n\") return&#125; Referenceslice and append gotchaHow to avoid Go gotchas 编码规则 全局变量：驼峰式，结合是否可导出确定首字母大小写 参数传递：驼峰式，小写字母开头 局部变量：下划线形式 包名应该为小写单词，不要使用下划线或者混合大小写。 单个函数的接口名以”er”作为后缀，如Reader,Writer，接口的实现则去掉“er” 两个函数的接口名综合两个函数名 三个以上函数的接口名，类似于结构体名 采用全部大写或者全部小写来表示缩写单词 对于少量数据，不要传递指针 对于大量数据的struct可以考虑使用指针 传入参数是map，slice，chan不要传递指针 因为map，slice，chan是引用类型，不需要传递指针的指针 返回值1234567891011v, ok = m[key] // map lookupv, ok = x.(T) // type assertionv, ok = &lt;-ch // channel receivev = m[key] // map查找，失败时返回零值v = x.(T) // type断言，失败时panic异常v = &lt;-ch // 管道接收，失败时返回零值（阻塞不算是失败）_, ok = m[key] // map返回2个值_, ok = mm[\"\"], false // map返回1个值_ = mm[\"\"] // map返回1个值 var12345var ( _ StdLogger = &amp;log.Logger&#123;&#125; _ StdLogger = &amp;Entry&#123;&#125; _ StdLogger = &amp;Logger&#123;&#125;) 数组 数组是值。将一个数组赋予另一个数组会复制其所有元素。 特别地，若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。 数组的大小是其类型的一部分。类型 [10]int 和 [20]int 是不同的。 append但如果我们要像 Append 那样将一个切片追加到另一个切片中呢？ 很简单：在调用的地方使用 …，就像我们在上面调用 Output 那样。以下代码片段的输出与上一个相同。 1234x := []int&#123;1,2,3&#125;y := []int&#123;4,5,6&#125;x = append(x, y...)fmt.Println(x) runtime.keepAliveThe purpose of keep alive is to ensure that the garbage collector does not collect a value which is no longer referenced inside a function. The usual cases where this is a problem is if you have obtained the file descriptor to an underlying os.File, or you have passed memory to cgo which was allocated inside the same function. 1234567func g() &#123; x := make([]byte, 2^24) y := x[0] if y &gt; 0 &#123; panic(\"wat\") &#125;&#125; Most people would expect that x would be garbage collected before the end of the function because it is no longer referenced. But consider this situation 12345func h() &#123; x, _ := os.Open(\"somefile\") fd := x.Fd() // use fd in some kind of select or poll operation inside this function.&#125; If you’ve follow the logic of what I’ve said up to this point, you would expect x to be dead after the assignment to fd, but we know that *os.File values have a finaliser attached to them, which will be invoked soon after x goes out of scope at the end of the second line. When that happens, the finalizer will close the file descriptor that fd references. If you’re lucky you’ll get an error about writing to a closed file. If you’re unlucky, another goroutine will open a different file, and receive the same file descriptor number causing file corruption. The workaround is to use runtime.KeepAlive to keep the reference in x live for the duration of the function. The moral of the story is finalisers are terrible, and adding one to *os.File was a mistake. 编译 go build -x 打印出编译相关的信息 cgo编译Linking golang statically 交叉编译1env GOOS=linux GOARCH=amd64 go build 接口类型作为参数 接口类型作为参数是否是copy取决于传入参数是指针类型还是struct类型，如果是一个指针类型那么就不会copy 接口传给接口也不会复制 struct赋值给接口会复制 struct指针复制给接口不会复制 实际上可以认为所有的类型都是穿值的，只不过有些是指针有些是值Copying Interface Values In Go 微服务设计 同步是一个比较大的问题，尽量需要同步的由单独的模块来做 Json token在某种情况下可以解决无状态的问题 内部服务消息化更有助于解耦和和去同步 Test go test -v -run TESTNAME 可以指定运行单个UT 或者用go test -v xxx_test.go 这里有个问题：But there’s a catch. This works well if foo.go is package foo foo_test.go is package foo_test and imports ‘foo’. If foo_test.go and foo.go are the same package (a common case), then you must name all other files required to build ‘foo_test’. In this example it would be: 1$ go test foo_test.go foo.go 单独编译成一个binary12go test -c stream_test.go -o stream.test 单独编译一个UT./stream.test -test.v 单独运行 Reflect reflect.ValueOf会成成一个含有复制这个变量的Value对象，所以Set*方法都不能用，因为unaccessable, 如果需要修改，传入的应该是一个指针 interface会复制原始对象","tags":[{"name":"go","slug":"go","permalink":"http://matthewgao.github.io/tags/go/"}]},{"title":"PHP Note","date":"2016-11-12T10:18:05.000Z","path":"php/","text":"composer一个php的包管理的，很近似于npm, 他也是默认不全局的，只是配置某个工程，然后通过json文件自动下载依赖 composer.lock是个特殊的文件，记录了创建时各个package的版本，这样下次install的时候保证版本严格一致 autoload这个脚本会自动load相应依赖，所以在工程中只要require了这个，那么这些package可以直接拿来使用 require可以返回一个instance，可以后期add package 12$loader = require __DIR__ . '/vendor/autoload.php';$loader-&gt;add('Acme\\\\Test\\\\', __DIR__); You can even add your own code to the autoloader by adding an autoload field to composer.json. 12345&#123; \"autoload\": &#123; \"psr-4\": &#123;\"Acme\\\\\": \"src/\"&#125; &#125;&#125; create a libraryAs soon as you have a composer.json in a directory, that directory is a package. When you add a require to a project, you are making a package that depends on other packages. The only difference between your project and libraries is that your project is a package without a name. Tip 函数内的变量是不受{}scope控制的。类似于js PHP接受显式的函数参数类型指派，我比较倾向于显示的指出 php namespace是在一个作用域里，如果在另外的引用文件里已经包含了对应的引用文件，本文件中不用再引用一次 mysql connection不用主动释放，执行结束会自动释放 pfsockopen 可以打开一个持久的sock connection set_include_path &amp; get_include_pathset_include_path用于限定include或者require文件的范围，并且使得代码里不必要写一个完整的路径，如果不调用这个方法，那么你可以以相对或者绝对路径的方式访问任何地方，但是如果有了这个只能在他限定的范围内查找 Magic Func __call() 访问类中不存在的对象会调到 invoke() 以类名执行类似python的call__ get(), set() Magic func doc Reflection get_class_name() get_class_method() ReferenceHow to Make Async Requests in PHP","tags":[{"name":"php","slug":"php","permalink":"http://matthewgao.github.io/tags/php/"}]},{"title":"Java Note","date":"2016-11-02T15:43:03.000Z","path":"java/","text":"返回状态值默认Java程序不会返回一个状态值，执行成功返回0，如果需要，要调用System。exit Java没有无符号整形 char 是一个UTF-16编码的，强烈不要使用char Java中boolean值是不能和整形比较的 strictfp 强制严格浮点计算 &gt;&gt;&gt; 以0填充高位的位移 ==不能用于比较字符串 问题 codepoint","tags":[{"name":"java","slug":"java","permalink":"http://matthewgao.github.io/tags/java/"}]},{"title":"回顾我的第一份工作","date":"2016-10-20T15:48:23.000Z","path":"firstjob/","text":"0x00 序2012年研究生毕业，我就来到了SonicWALL，当时自己是一个通信专业毕业但是很想去互联网开始第一份职业生涯的人，但是非科班出身的背景和毫无实习经历的我，在寻找第一个工作的时候并没有拿到我特别期待的BAT的Offer，PPS, 中兴，阿朗，SonicWALL成了我最终的候选公司，权衡了多次还是选择去SonicWALL这家看起来不大的做网络安全的外企，后来庆幸决策是对的，四个月后SonicWALL被戴尔收购，变成Dell Security，还加薪了，当时觉得感觉超好,然而悲剧在后面等着你。 想想当时被面试，到后来面试别人，发现确实仅仅通过聊天和写几个程序是完全没办法衡量一个人的潜质的，但是又没有其他更好的办法，所以即便我自认为学习能力很强，但是这种没有任何可以佐证的口号没人相信你，当然也有很怪的公司，比如宝信，竟然在你研究生毕业的时候问你的高考分数，当你报了一个很高的高考分数的时候，对你的态度全变，感觉就不用继续面下去了，就已经过了。 总结这些，我还是想对那些即将毕业的同学们说，别怕得罪你的导师，尽量去外面找实习，公司越大越好，500强，BAT。。。，等你找工作的时候即便笔试面试都不那么出众，也可以相对轻松的拿到Offer。 0x01 工作工作内容是开发一个远程接入设备（Secure Mobile Access Appliance 也叫Aventail）, 是一个Debian based server，这份工作的开始对我来说既是机遇，也是一个挑战，机遇在于这是一个全新的组，刚刚成立，开始接手本来在美国的服务器端的开发，组里只有四个人，并且没有专门的PM带，服务器里数十个Daemon，和数十个Kernel module，每个代码量从近万行到10几万行不等，几乎处于个无从下手的情况。 调试和读代码当时由于无知，费尽心思想找到一个像VS一样的IDE，让我能够在Linux系统里用单步调试一点点的去跟踪代码，但是尝试了各种，发现都是不可能的，那是一整套基于服务的系统，每一个都是一个本地socket，你想用GDB单步调试都不可能，因为block时间多一点，其他服务就认为你超时，就放弃重连，所以最终我还是回到了最开始我很不屑的打log的方法。对于我这种没有人带的完全home-grown的码农，我自己找到一套适合调试的方法： 打log 加abort, 然后分析core dump 抽出局部代码伪造错误case，试图复现 我至今都不知道行业有没有更高明的办法，处理这种依赖程度超强的大型系统的debug方法，但是我现在经常用的这三招，基本上帮助了我解决所有简单或者复杂的bug，当然精通gdb是必须的，并且要有些汇编的功底，要了解linkage的过程，和ELF文件格式，这是前提，在处理coredump的时候非常有用。 对于读代码，我也尝试了各种工具，包括被大家广为推崇的VIM，Emacs, sublime, vsc等等等等，Emacs实在是太难的，键盘的映射都要改，所以直接放弃，VIM在配了一堆插件之后确实会变成一个比较好的阅读器和编辑器，我也有自己写了一个自动化的配置脚本MyVim, 直到我碰到了source insight。 Source Insight是个非常古老的软件，甚至他连C++11的新关键字和语法都不支持，最新的一版似乎是在2015年3月更新的，也仅仅是打了个patch，但是他确实是一个Windows下看代码的神器，自动哦建立一个相当准确的索引。读代码炒鸡爽。 搞了这么多，我现在也是在vim，vsc, si之间来回的换着用，各有不同的用处，对于一个home-grown的码农来说，够了。 学习和进步最开始我也是一个对英语过敏的人，虽然身在外企，还要经常和米国人开会，csdn和google是我最多使用的东西，后来渐渐的我发现，网上大把大把收到的博文和帖子对于问题的处理大多仅仅处于处理问题，对于问题的原因解释不清，我希望我能看到最本质的东西，但是尝试去看一些源代码又太过高难，后来我发现stackoverflow上面的东西老外的回答却是精彩，而且针针见血，所以我开始集中在stackoverflow上尝试解决问题，并且发现他们引用的东西就是相关的官方文档，一点点的我开始忍住恶心看各种我用到的库或者框架的英文文档，很多东西是有中文文档的，但是在我看来中文文档要么老，要么翻译的怪，我甚至要在脑子里把它翻译成英文才能正确理解他的意思，所以我索性只看英文文档，而且我发现这些官方的Get started都写的非常清楚易懂，非常适合我们去读，当然man也是一个好东西，我不会记住每个系统调用或者标准库函数的具体参数，我也记不住，每次用的时候就man一下。 这样下来，久而久之，英语阅读越来越流畅了，也不觉得痛苦了，我觉得除了读书，官方文档是最佳的学习的地方，他会提示你所有可能用错的地方。 代码风格刚刚入职的时候，我只是一个能编程的人，但是并不是一个合格的工程师，好的代码风格，编写思路是一个好的工程师必备的能力，这几年来，我发现写代码并不是一个难事，难得是维护代码，一个写的很糟糕的代码是让人很难理解的，你即便读懂了每一行内容，但是却不知道他究竟在干什么，所以代码的可读性非常重要，当然好的文档也非常重要。但是有的时候，代码的可读性和效率是矛盾的，一些时候你可以用一些精妙的方法获得一个非常好的效率提升，但是这会导致你的代码变得难以理解，这个时候衡量可读性和效率就是你要考虑的了，当效率并没成为瓶颈的时候，也就是说你写的优化的代码并没显著提升整个程序的运行速度，那么可读性应该是你第一要保证的，因为代码以后可能不是你来维护，你要让每一个人都能理解你的代码，以至于他不会犯错误。大大降低维护成本，而且现在的计算能力越来越廉价，效率有的时候没必要放的特别重，当然我也不是说你可以乱用内存，粗暴的使用CPU，只是说要学会平和代码的可读性和效率。 开发文档我们特别注重开发文档，以至于我们在一个release要花费60-70%的时间在推敲开发文档上面，最终代码实现非常的快，这其实是有好处的，看似你花费了很多时间在一个不必要的事情上，但是这也给你大量的时间反复的设计你的软件，和系统架构，要比草草的实现，然后在重构要好很多，但是这似乎并不匹配中国的开发节奏，所以。。。理想总是骨感的。 让脚本帮你忙我们是一个linux based server，所以开发机通常是虚拟机，各种虚拟机，所以在开发不同版本，或者去解不同版本的bug的时候，你就需要一个完整的配置好的虚拟机，这样才能尝试复现问题，那么下载镜像-&gt;创建虚拟机-&gt;安装镜像-&gt;完成初始化配置这一系列动作通常会耗费我大量的时间，而且是重复劳动，我完全可以像一个异步系统一样在这个时候去做其他事情，这个时候各种脚本的价值就凸显了。 Shell和Python是我的最爱，我自己写了脚本可以让整个创建虚拟机的这个过程自动化，我只需运行我的脚本，告诉他我要的版本号，他就会自动的去下载镜像，创建虚拟机，完成初始化配置，而你只要安心的去做其他事情，过个10分钟回来就可以直接用了，所以当你经常在做一个繁琐的事情的时候，考虑让脚本拉你一把。 做一切能做的事在这次的几次面试中，几次被问到，你似乎还做运维的工作? 我什么都做，只要我能做，我觉得工作中，任何一个需要解决的问题都是工作的一部分，所以我基本上不会求IT帮我，除非我没权限，搭实验室的时候我自己学着配三层交换机，opengear，甚至自己做网线，能够自己做的事情尽量自己做，都是一种积累，修理变砖的设备也不是我一个开发应该干的，正常流程是返厂，但是我自己还是尝试自己去修，也帮sales省下了大把的销售周期，虽然这跟我没有任何关系，但是我学到了这样一个设备到底是怎么启动并且保证固件不被恶意篡改的，两全其美。 0x02 导师我非常庆幸我能在这个公司遇到两个非常好的导师，实际上也不是导师了，只是我和他们共事，Chris D Peterson和William M Perry，他们年龄都很大了，基本上和我父亲同龄，所以他在工作上给我的指导非常有价值。 Chris 1986年从MIT毕业的时候我才刚刚出生，他参与了Linux X windows这个项目的开发，他所开发的模块至今还在所有Linux发行版上使用，他是一个在C++和unix系统开发上相当专注的人，他给了我非常好的编码建议和思路，让我在这四年间受益匪浅，也许是他也很信任我，他把整个系统最核心的由他开发的模块给了我维护，并不断的给我各种建议，我真的感谢他，付出了大量的精力辅导我这么一个小白。 Bill也是很厉害，他是那种真正的全栈，也是整个Aventail的创始人之一，上从CSS下到linux kernel module他全能开发，他给我的职业生涯提供了广度，他的持续学习也深深的影响了我，快50的人了，依然在不断的学习新东西，而且不用很长时间就能上手，我想这是一个程序员的职业精神吧。 我离开Dell最舍不得的就是这两个人，真的对我影响非常之大，我由衷的崇拜和感谢他们，希望我们有机会上海或者西雅图再见面。 0x03 说说戴尔再来说说戴尔这个公司吧，总的评价是负面的，首先他不是一个科技公司，他只是个销售公司，他不知道应该怎么做研发，怎么尊重工程师，在戴尔中国，工程师的平均薪资是远远低于销售的，而且最开始被戴尔收购的时候戴尔竟然是用你写了多少行代码，删了多少行代码来评价你的performance的真是无语，戴尔在这种无知的状态下运营了我们4年，导致整个SonicWALL产品线错位，最后又收购了EMC出售了整个软件集团，更恶心的时候竟然不想赔违约的钱，所以对戴尔没什么好评价的，戴尔不是科技公司，以后任何和戴尔相关的公司都慎入，EMC的同志们，小心了。 0x04 在说说中美市场我们是一款VPN产品，那么在中国最大的竞争对手是深信服，我有研究过深信服的产品，并没有比我们强大，但是中国市场讲究的是尽可能的满足客户需求，但是米国人并不这么认为，因为他们觉得非标准化的东西是没必要提供的，然而我们恰恰就是卡在这里了，想打开市场，就要改变这个，然而，米国人不愿意，同时米国的节奏也完全的慢半拍，他们的生活确实是和工作平衡的非常好，我也承认那才是生活，但是对于customer issue也慢半拍就会搞得中国客户很不满，毕竟我只负责一部分的开发，我确实尽快解决客户的问题，但是那些由美国和印度开发的模块就完全不受控制了，所以经常说外企在中国水土不服原来越严重不是没有道理的，这根本上是价值观的不同。 0x05 推荐书 代码大全 C++ premier 鸟叔的Linux私房菜 TCP/IP详解 HTTP权威指南 Learning Python Python Programming UNIX网络编程 UNIX环境高级编程 JavaScript权威指南 深入理解Linux内核 程序员的自我修养 Effective C++/STL 0x06 总结四年来我亲手接过了四个模块的核心开发，搭建了上海的Performance lab，解决了无数bug，也帮sales修了许多台被玩坏了了的设备，但是很不幸的是，我走的时候，还没有任何人能够接手我的位置，我觉得我这一走，上海的server开发就要清零了，我是感到无比的可惜，那毕竟是我亲手一点点建立起来的，包括技术，包括信任，那都是我的心血啊，今天去实验室和我亲手搭起来的实验室见了最后一面，我走之前，大概不会再去弄他了，希望其他人可以take care them，我很想把我的所有技能传授给其他留下的人，但是有些东西真的是只能意会不能言传。 总之无奈，离开也并不是我所期待，但是真的是这四年间，戴尔毁了整个公司的节奏，加之这次出售风波，公司的前景在我看来更加不明朗了，Shanghai Site VP很努力的在帮我们争取各种利益，但是结果都是不尽人意，他在这期间苍老了很多，看着很令人心疼，真的非常感谢他，但是无奈，我也没有办法，再见了SonicWALL，再见Aventail，我会在思科或者阿里开始一个全新的职业生涯。","tags":[{"name":"job","slug":"job","permalink":"http://matthewgao.github.io/tags/job/"}]},{"title":"C\\C++ Notes","date":"2016-10-19T06:21:46.000Z","path":"2014-9-12-cpp-note/","text":"双重指针#include &lt;stdio.h&gt; int main(){ char **p=NULL; printf(&quot;2 level ptr is:%p\\n&quot;,&amp;p); printf(&quot;1 level ptr is:%p\\n&quot;,p); return 0; } 输出结果为 2 level ptr is:0x7fff2b440768 1 level ptr is:(nil) 分配地址传给子函数可行，指针传给子函数，让子函数分配地址回传不可行。 数组指针char addr[256]; memset(addr+4, 0,20); 这样实际上是错误的，虽然说addr本质上是一个指针，但是在addr+4还需要强制转换为void*才可以。 memset/memcpy具体内容man GDB检查core dump1thread apply all bt full 检查backtrace的每一层 up 向上一层 down 向下一层 显示变量类型1whatis (param) 常用命令 backtrace 显示程序中的当前位置和表示如何到达当前位置的栈跟踪（同义词：where） breakpoint 在程序中设置一个断点 cd 改变当前工作目录 clear 删除刚才停止处的断点 commands 命中断点时，列出将要执行的命令 continue 从断点开始继续执行 delete 删除一个断点或监测点；也可与其他命令一起使用 display 程序停止时显示变量和表达时 down 下移栈帧，使得另一个函数成为当前函数 frame 选择下一条continue命令的帧 info 显示与该程序有关的各种信息 jump 在源程序中的另一点开始运行 kill 异常终止在gdb 控制下运行的程序 list 列出相应于正在执行的程序的原文件内容 next 执行下一个源程序行，从而执行其整体中的一个函数 print 显示变量或表达式的值 pwd 显示当前工作目录 pype 显示一个数据结构（如一个结构或C++类）的内容 quit 退出gdb reverse-search 在源文件中反向搜索正规表达式 run 执行该程序 search 在源文件中搜索正规表达式 set variable 给变量赋值 signal 将一个信号发送到正在运行的进程 step 执行下一个源程序行，必要时进入下一个函数 undisplay display 命令的反命令，不要显示表达式 until 结束当前循环 up 上移栈帧，使另一函数成为当前函数 watch 在程序中设置一个监测点(即数据断点) 其他小诡计在程序中加abort() 从而可以在想拿到东西的地方得到core dump Valgrind: Memory leak check tool12sudo apt-get install valgrindvalgrind (option) (program) (program option) 参考网站 1234567#0 0xb7fe1424 in __kernel_vsyscall ()#1 0xb7d5c571 in raise () from /lib/libc.so.6#2 0xb7d5dd72 in abort () from /lib/libc.so.6#3 0xb7f9352f in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/libstdc++.so.6#4 0xb7f90eb5 in __cxxabiv1::__terminate(void (*)()) () from /usr/lib/libstdc++.so.6#5 0xb7f90ef2 in std::terminate() () from /usr/lib/libstdc++.so.6#6 0xb7f92155 in __cxa_pure_virtual () from /usr/lib/libstdc++.so.6 __cxa_pure_virtual() 调用虚函数，会导致一个runtime error， abort() dynamic_cast转换失败会返回一个NULL指针，基本只限于对于引用和指针，从父类转子类 或者从子类转父类，所谓的downcast和upcast 去const属性用const_cast。 基本类型转换用static_cast。 多态类之间的类型转换用dynamic_cast。 不同类型的指针类型转换用reinterpret_cast。 尽量使用C++的新式装换，尽量不用老式转换 switch-casecase 在没有{}指定范围的时候在其中声明变量会导致编译时候crosses initialization of “XXX” 错误 1case '0'...'9': //合法 ParametersstrC string to truncate.Notice that this string is modified by being broken into smaller strings (tokens).Alternativelly, a null pointer may be specified, in which case the function continues scanning where a previous successful call to the function ended. delimitersC string containing the delimiter characters.These can be different from one call to another. Example1234567891011121314151617/* strtok example */#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main ()&#123; char str[] =\"- This, a sample string.\"; char * pch; printf (\"Splitting string \\\"%s\\\" into tokens:\\n\",str); pch = strtok (str,\" ,.-\"); while (pch != NULL) &#123; printf (\"%s\\n\",pch); pch = strtok (NULL, \" ,.-\"); &#125; return 0;&#125; C99 支持可变长数组基本用法 变长数组只能是局部变量，不能是静态变量和全局变量，因为这两者的长度是编译时决定的，而变长数组的长度要到运行时才能确定。变长数组是局部变量，所以是有生命周期的，其生命周期仅在当前域内，即{}内。 变长数组使用的内存是栈内存，所以需要注意数组长度不能太大超过栈内存大小限制。linux 上可以用 ulimit -s 查看栈大小，一般为 8M. 同样适用于支持C99的C++程序 例如： 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt; int n = 10;int a[n]; /*非法，VM类型不能具有文件作用域*/int (*p)[n]; /*非法，VM类型不能具有文件作用域*/struct test&#123; int k; int a[n]; /*非法，a不是普通标识符*/ int (*p)[n]; /*非法，p不是普通标识符*/&#125;; int main( void )&#123; int m = 20; struct test1 &#123; int k; int a[n]; /*非法，a不是普通标识符*/ int (*p)[n]; /*非法，a不是普通标识符*/ &#125;; extern int a[n]; /*非法，VLA不能具有链接性*/ static int b[n]; /*非法，VLA不能具有静态存储周期*/ int c[n]; /*合法，自动VLA*/ int d[m][n]; /*合法，自动VLA*/ static int (*p1)[n] = d; /*合法，静态VM指针*/ n = 20; static int (*p2)[n] = d; /*未定义行为*/ return 0;&#125; 作为形参除了可以作为自动对象外，还可以作为函数的形参，下面几个函数原型声明是一样的： 123456void func( int a[m][n] );void func( int a[*][n] );void func( int a[ ][n] );void func( int a[*][*] );void func( int a[ ][*] );void func( int (*a)[*] ); 各种限定词除了标记外，形参中的数组还可以使用类型限定词const、volatile、restrict和static关键字。由于形参中的VLA被自动调整为等效的指针，因此这些类型限定词实际上限定的是一个指针，例如：`void func( int, int, int a[const][] );等效于void func( int, int, int ( const a )[] );` 它指出a是一个const对象，不能在func内部直接通过a修改其代表的对象。例如： 1234567void func( int, int, int a[const][*] );……void func( int m, int n, int a[const m][n] )&#123; int b[m][n]; a = b; /*错误，不能通过a修改其代表的对象*/&#125; static表示传入的实参的值至少要跟其所修饰的长度表达式的值一样大。例如： 1234567void func( int, int, int a[const static 20][*] );……int m = 20, n = 10;int a[m][n];int b[n][m];func( m, n, a );func( m, n, b ); /*错误，b的第一维长度小于static 20*/ 类型限定词和static关键字只能用于具有数组类型的函数形参的第一维中。这里的用词是数组类型，意味着它们不仅能用于VLA，也能用于一般数组形参。 const 函数 常成员函数不能更新对象的数据成员 不能调用该类中没有const修饰的成员函数 当类的实例为一个const object的时候只能调用const函数 12const Object* obj = new Object();obj.func(); //这里func必须为const函数 不然就不对 友元 friend 友元函数可以访问其类中的成员，并且不受private protect的限制 类也可以是友元，友元类可以访问其所在类的成员 123456789class A&#123; public： friend bool func(); //声明友元 private: int a;&#125;friend bool func()&#123; some code //友元的定义&#125; STL和boost make_pair(obj) 和 push_back(obj) 都会调用obj的拷贝构造函数，构造一个新函数，所以使用时要注意obj是否有一个合适的拷贝构造函数 Copy in, copy out. shared_ptr 注意循环引用（cycle） 可以正确的在STL container中使用 这里bad()的使用方法会可能导致临时shared_ptr指向对象不会被正确释放（在exception case下）12345678910void ok()&#123; shared_ptr&lt;int&gt; p( new int(2) ); f( p, g() );&#125;void bad()&#123; f( shared_ptr&lt;int&gt;( new int(2) ), g() );&#125; 12345678910111213141516171819shared_ptr&lt;Job&gt; j = make_shared&lt;Job&gt;(); //make_shared比用new更加高效，//这个函数会在传入时候复制一次shared_ptr，导致引用计数+1，之后return的时候又复制一次，导致引用计数又+1，但是这都会在函数执行后//被正确释放掉shared_ptr&lt;Job&gt; func(shared_ptr&lt;Job&gt; job)&#123; return job;&#125;//全程不会增加引用计数，但是要小心，如果这个shared_ptr的会被其他线程赋值，那么这可能会有问题shared_ptr&lt;Job&gt;&amp; func(shared_ptr&lt;Job&gt;&amp; job)&#123; return job;&#125;//这个时候job会被赋值，job所指的老的对象会被释放掉，job会继续跟踪这个新建对象。shared_ptr&lt;Job&gt;&amp; func(shared_ptr&lt;Job&gt;&amp; job)&#123; job = make_shared&lt;Job&gt;(); return job;&#125; 如果以引用传递shared_ptr参数，那么他不能操纵他自己，不然会编译报错 12Association::addToManager(shared_ptr&lt;Association&gt;&amp; assoc);assoc-&gt;addToManager(assoc);// 这里addToManager无法接受一个assoc的引用 shared_ptr不能用static_cast等直接做转换，要用它提供的“ static_pointer_cast const_pointer_cast dynamic_pointer_cast 91 Solution: Smart Pointer Parameters string是否是有引用实现的如果是引用实现的，在多线程条件下，可能因为要加锁所以带来性能上的影响，但是如果非引用实现，每个对象都是独立的copy则无影响。 vector 的增长vector的每次增长都会耗费一定时间去拷贝原有数据，所以如果能够预计大小，则预先reserve(size)会更好 vector赋值最快的是用assign，其次是copy，最后是赋值操作符 STL容器 迭代器(iterator) 实际上是一个指针所以 1vector&lt;string&gt;::iterator it = &amp;svec[10] 是正确的 *iter; //返回迭代器所指元素的引用 c.push_back(str); //新元素的值为str的副本 c.begin()/end(); //返回的是迭代器（即指针） c.front()/back(); //返回的是元素的引用 string可以看做为一个字符容器 Allocator虽然分配器的定制有所限制，但在许多情况下，仍需要用到自定义的分配器，而这一般是为封装对不同类型内存空间（如共享内存与已回收内存）的访问方式，或在使用内存池进行内存分配时提高性能而为。除此以外，从内存占用和运行时间的角度看，在频繁进行少量内存分配的程序中，若引入为之专门定制的分配器，也会获益良多。 任意满足分配器使用需求的C++类都可作分配器使用。具体来说，当一个类（在此设为类A）有为一个特定类型（在此设为类型T）的对象分配内存的能力时，该类就必须提供以下类型的定义： A::pointer 指针 A::const_pointer 常量指针 A::reference 引用 A::const_reference 常量引用 A::value_type 值类型 A::size_type 所用内存大小的类型，表示类A所定义的分配模型中的单个对象最大尺寸的无符号整型 A::difference_type 指针差值的类型，为带符号整型，用于表示分配模型内的两个指针的差异值。 map, unordered_map如果key是一个对象，那么需要对此对象定义一个hash function STL TIP 调用empty()去检查是否是空，而不是用size()==0检查 Vector&lt;bool&gt;会变成bitset 巧用swap()可以出去vector中的多余容量 vector extend长度很耗时，可以事前reserve() std::function与std::bind 函数指针function模板类和bind模板函数，使用它们可以实现类似函数指针的功能，但却却比函数指针更加灵活，特别是函数指向类 的非静态成员函数时。 std::function可以绑定到全局函数/类静态成员函数(类静态成员函数与全局函数没有区别),如果要绑定到类的非静态成员函数，则需要使用std::bind。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;functional&gt;using namespace std;typedef std::function&lt;void ()&gt; fp;void g_fun()&#123; cout&lt;&lt;\"g_fun()\"&lt;&lt;endl;&#125;class A&#123;public: static void A_fun_static() &#123; cout&lt;&lt;\"A_fun_static()\"&lt;&lt;endl; &#125; void A_fun() &#123; cout&lt;&lt;\"A_fun()\"&lt;&lt;endl; &#125; void A_fun_int(int i) &#123; cout&lt;&lt;\"A_fun_int() \"&lt;&lt;i&lt;&lt;endl; &#125; //非静态类成员，因为含有this指针，所以需要使用bind void init() &#123; fp fp1=std::bind(&amp;A::A_fun,this); fp1(); &#125; void init2() &#123; typedef std::function&lt;void (int)&gt; fpi; //对于参数要使用占位符 std::placeholders::_1 fpi f=std::bind(&amp;A::A_fun_int,this,std::placeholders::_1); f(5); &#125;&#125;;int main()&#123; //绑定到全局函数 fp f2=fp(&amp;g_fun); f2(); //绑定到类静态成员函数 fp f1=fp(&amp;A::A_fun_static); f1(); A().init(); A().init2(); return 0;&#125; 同时，std::bind绑定到虚函数时会表现出多态行为。 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;functional&gt;using namespace std;typedef std::function&lt;void ()&gt; fp;class A&#123;public: virtual void f() &#123; cout&lt;&lt;\"A::f()\"&lt;&lt;endl; &#125; void init() &#123; //std::bind可以表现出多态行为 fp f=std::bind(&amp;A::f,this); f(); &#125;&#125;;class B:public A&#123;public: virtual void f() &#123; cout&lt;&lt;\"B::f()\"&lt;&lt;endl; &#125;&#125;;int main()&#123; A* pa=new B; pa-&gt;init(); return 0;&#125; 预处理注释代码#if 0可以用作注释一段代码，因为/* */不支持迭代，所以有时候用预处理方式更好 123#if 0 //code#endif new operator 和 operator new new operator 就是我们经常在用的new，他会分配地址，构造对象，这个不能重构。（等同于operator new，之后调用构造函数） operator new 只分配内存，不构造对象，功能和malloc一样，可以重构。 placement new 在已有的空间上，构造对象 operator重载重载有两种方法，一种是在类中对于类的操作符重载，另外一种是全局重载，全局重载有一个条件，就是参数至少有一个是自定义类型，这个是C++标准特别限制的 b.operator+(a)等同于b+a, 等同于operator+(b,a)1234567891011121314151617int operator+(Factor &amp;lhs, int rhs)&#123; //do something return lhs.get() + rhs;&#125;//下面的方法是错误的int operator+(Int lhs, int rhs)&#123; //do something return lhs + rhs;&#125;//类中重载的例子class cls&#123; int operator+(cls &amp;rhs)&#123; return this + rhs; &#125;&#125; 解决 static 属性的初始化赋值问题1234567891011121314151617class c1&#123; private： static const size_t max = 10;&#125; //此种方法是通常不允许的//可以采用以下workaroundclass c1&#123; private： static const size_t max;&#125;const size_t c1::max =10;//或者class c1&#123; private： enum&#123; max = 10&#125;;&#125; 操作符operator char() const这是一个类型转换的操作符 Miscinline函数不一定inline 他只是给编译器的一个建议，inline函数中不建议有循环指令 在类的声明中实现的类（头文件中），默认就为inline函数 不建议inline 和 static 一起使用，因为会造成大量internal副本。最新版本的C++编译器已经修复此问题。 尽量以引用和指针方式传参 这样可以减少对象被构造和解析的过程 尽量推迟变量声明的时间 itr++ 和 ++itr在不考虑返回值的时候++itr效率更高，因为他不需要做一次数据拷贝，对于基本类型可以忽略，对于Class和迭代器，尽量使用前置自增（减）所以++++itr合法，而itr++++不合法 1234567891011//前置UPInt&amp; UPInt::operator++()&#123; *this+= 1; return *this;&#125;//后置UPInt&amp; UPInt::operator++(int)&#123; UPInt oldValue = *this; ++(*this); return oldValue;&#125; using如果子类中的属性或者局部变量的名称与父类的重名，可以用using指定使用哪个 1using base::m_attr; 纯虚函数可以有实现12345678910111213class base&#123; public: vitural bool func() = 0; ....&#125;bool base::func()&#123; //something&#125;class derived : public base&#123; &#125;derived* d = new derived();d-&gt;base::func(); //调用纯虚函数的默认实现 mutable 作用mutable修饰过的属性，即便在const函数中也可以被修改。另外我们也有另一种办法来实现，就是通过一个fake this指针，在const函数中，把const this指针cast成 this，这样就可以通过这个fake this指针做赋值操作了 const 调用规则类中二函数都存在的情况下： const对象默认调用const成员函数，非const对象默认调用非const成员函数； 若非const对象想调用const成员函数，则需显式转化，如(const Student&amp;)obj.getAge(); 若const对象想调用非const成员函数，同理const_cast(constObj).getAge();(注意：constObj要加括号) 类中只有一函数存在的情况下： 非const对象可以调用const成员函数或非const成员函数； const对象只能调用const成员函数,直接调用非const函数时编译器会报错； 指针和引用引用不可以为空，如果变量需要为空，则要用指针，如果希望不为空则尽量用引用，避免了不必要的验NULL检查 绝对不要以多态（Polymorphically）方式处理数组数组的基本原理是依靠数组下标来寻找对应的对象，所以在多态情况下，跳过的指针偏移不一样，所以用Base指正来使用Derived类数组会有错误。 避免类中Implicit的类型装换函数Implicit的类型转换（或者重载操作符），如果出现任何问题会非常难调试，所以尽量显示的进行类型转换，比如o.asInt(), o.asDouble()这样输出。或者以explicit修饰构造函数。 复合操作符（+=）复合操作符（+=）比单独操作符效率要高，不需要产生临时变量 size_tsize_t 解决了在不同系统32、64位系统上 strlen类型大小的问题， 32bit系统strlen返回4字节的值，而64是8字节 全局符号全局符号::表示调用global的变量或者方法，也适用于如下情况12//如果test类重构了operator new，则`::new`表示使用默认的new构造，而不是重构之后的test t = ::new test(); fork execl fork 会复制父进程的所有资源，包括文件描述符，会建立一个全新的pid，他的文件描述符复制父进程的 execl 会开始一个全新的程序全面覆盖父进程，但是他的pid依旧是是他父进程的pid，他也会继续share父进程已经打开的文件描述符，popen实际上就是调用了这个来运行一个新的程序。execl一旦运行 execl后面的code将不会被执行了，因为已经被覆盖掉了 vfork 父子空间共享内存空间，使得由子函数调用vfork创建的子进程（架设子进程为先执行函数的进程）调用其它函数或运行其他程序后会，父进程会出现段错误， dup dup2使newfd指向fd的文件 12newfd = dup(fd)dup(fd,newfd) strncpy and snprintf strncpy：如果字符串超过 size n， 那么他不会再字符串结尾加上\\0 snprintf: 如果字符串超出 n，他会在最后一个字符加上\\0， 所以这个更安全 strncat(char *dest, const char *src, size_t n): 最多从源中拷贝n个字符到目标串中，并在后面加一个0；也就是说，最多会有n+1个字符被写进dest。如果dest的容量为n，那么将会dest将会溢出。 execl与execlp的区别 execl只当前路径（不是当前路径必须加绝对路径） execlp使用系统的搜索路径 带l的exec函数：execl,execlp,execle，表示后边的参数以可变参数的形式给出且都以一个空指针结束。 带 p的exec函数：execlp,execvp，表示第一个参数path不用输入完整路径，只有给出命令名即可，它会在环境变量PATH当中查找命令 不带l的exec函数：execv,execvp表示命令所需的参数以char *arg[]形式给出且arg最后一个元素必须是NULL 带e的exec函数：execle表示，将环境变量传递给需要替换的进程 system()system函数对返回值的处理，涉及3个阶段： 阶段1：创建子进程等准备工作。如果失败，返回-1。 阶段2：调用/bin/sh拉起shell脚本,如果拉起失败或者shell未正常执行结束，原因值被写入到status的低8~15比特位中。system的man中只说明了会写了127这个值, 但实测发现还会写126等值。 阶段3：如果shell脚本正常执行结束，将shell返回值填到status的低8~15比特位中。 判断一个system函数调用shell脚本是否正常结束的方法应该是如下3个条件同时成立： -1 != status WIFEXITED(status)为真 0 == WEXITSTATUS(status) setbuf()函数setbuf()用于将指定缓冲区与特定的文件流相关联，实现操作缓冲区时直接操作文件流的功能。其原型如下： void setbuf(FILE * stream, char * buf); unlink()unlink(char* filename)用于删除link，如果没有任何link，且所有操作这个文件的fd已经关闭，unlink会删除文件, 这是个古老的UNIX方法 unordered_map 和 mapunordered_map 要比 map更快，同样是唯一键值，如果只关心键值，可以使用unordered_set 多态和类型转换考虑如下程序 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;iostream&gt;#include &lt;stdio.h&gt;class A&#123; public: virtual void f() &#123; printf(\"A::f()\\n\"); &#125; virtual void g() &#123; //printf(\"A::g(), %d\\n\",a); printf(\"A::g()\\n\"); &#125; virtual void g(int a) &#123; printf(\"A::g(), %d\\n\",a); //printf(\"A::g()\\n\"); g(); &#125; void h() &#123; printf(\"A::h()\\n\"); f(); g(); &#125; //virtual ~A()&#123;printf(\"destruct A\\n\");&#125;&#125;;class B: public A&#123; public: using A::g; \\\\ this C++11 keyword can make the derived class call a redefinited base class function virtual void f() &#123; printf(\"B::f()\\n\");&#125; virtual void g() &#123;printf(\"B::g()\\n\");&#125; void h() &#123;printf(\"B::h()\\n\");g();f();&#125; void u() &#123;printf(\"B::u()\\n\");&#125; //virtual ~B()&#123;printf(\"destruct B\\n\");&#125;&#125;; int main()&#123; B b; //b.g(1); A * p=&amp;b; A* p1 = new B(); p-&gt;h(); p-&gt;g(); p-&gt;g(2); A *a = dynamic_cast&lt;A*&gt;(&amp;b); printf(\"\\n\"); a-&gt;h(); a-&gt;g(); a-&gt;g(2); //a-&gt;u(); printf(\"\\n\"); B* pb = &amp;b; pb-&gt;g(2); pb-&gt;g(); printf(\"\\n\"); delete p1; return 0;&#125; 对应输出为： 123456789101112131415161718192021A::h()B::f()B::g()B::g()A::g(), 2B::g()A::h()B::f()B::g()B::g()A::g(), 2B::g()A::g(), 2B::g()B::g()destruct Adestruct Bdestruct A 结论 如果不是虚函数，指针类型的转换会导致调用对应类型的种的函数，即不为多态 如果是虚函数则，按照多态显示 如果是虚函数调用所在子类的非虚函数或者虚函数，则调用的都是子类中的函数，即便是非虚函数也不会调用到父类中的对应函数 如果Base指针去访问一个子类中的非虚函数，则编译报错 如果子类有父类的同名函数（不论是否是虚函数），则父类的所有同名的函数都被redefine（不同参数的），usingkeyword可以改进这个问题，using A::g()可以使B调用到A::g()，但是如果B已经有了g()，则无效?, 直接用Base::f()可以調用到父類的方法，但是this指针还是子类的，所以多台依旧 如果不是new出的对象不用考虑析构问题，系统可以很好的析构父类和子类 如果是new，需要虚析构函数，以保证父类指针也能正常析构一个指向子类的对象 C++11auto注意auto使用不当会导致vector被复制，而不是被引用 1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;vector&gt; int main() &#123; std::vector&lt;int&gt; v = &#123;0, 1, 2, 3, 4, 5&#125;; for (const int &amp;i : v) // access by const reference std::cout &lt;&lt; i &lt;&lt; ' '; std::cout &lt;&lt; '\\n'; for (auto i : v) // access by value, the type of i is int std::cout &lt;&lt; i &lt;&lt; ' '; std::cout &lt;&lt; '\\n'; for (auto&amp;&amp; i : v) // access by reference, the type of i is int&amp; std::cout &lt;&lt; i &lt;&lt; ' '; std::cout &lt;&lt; '\\n'; for(int n : &#123;0,1,2,3,4,5&#125;) // the initializer may be a braced-init-list std::cout &lt;&lt; n &lt;&lt; ' '; std::cout &lt;&lt; '\\n';&#125; Range-based for loop此方法常用语STL中内容的遍历，注意使用不当会导致容器中对象被复制 最佳用法是 for (auto&amp; elem : range)， 对于性能这和手动写的没什么区别。 for (auto elem : range) is very tempting and very bad. It produces auto elem = *__begin; (see 6.5.4 [stmt.ranged]/1), which copies each element, which is bad because: It might not compile - for example, unique_ptr elements aren’t copyable. This is problematic both for users who won’t understand the resulting compiler errors, and for users writing generic code that’ll happily compile until someone instantiates it for movable-only elements. It might misbehave at runtime - for example, “elem = val;” will modify the copy, but not the original element in the range. Additionally, &amp;elem will be invalidated after each iteration. It might be inefficient - for example, unnecessarily copying std::string. 重写 重载如果父类定义了一个g(int)，子类定义了一个g()，那么用子类的对象访问g(int)那么会编译出错，因为子类定义的g()函数覆盖了g(int)所以子类不能访问。如果父类定义了一个virtual g(int)，子类定义了一个virtualg()，那么用子类的对象访问(用.访问)virtual g(int)那么会编译出错，因为子类定义的virtual g()函数覆盖了virtual g(int)所以子类不能访问， 但是如果用指针（-&gt;）访问则会得到预期结果override-&gt;重写(=覆盖)、overload-&gt;重载、polymorphism -&gt; 多态 重定义（redefining）也叫隐藏，子类重新定义父类中的非虚函数，屏蔽了父类的同名函数 子类和父类的函数名称相同，但参数不同，此时不管父类函数是不是virtual函数，都将被隐藏(如果不用父类指针访问的话)。 子类和父类的函数名称相同，参数也相同，但是父类函数不是virtual函数，父类的函数将被隐藏。 using Base::f 可以手动指定使用哪个函数（子类父类会保留下来）子类和父类冲突时，保留父类的 重写（override）也称为覆盖，子类重新定义父类中有相同名称和参数的虚函数，主要在继承关系中出现。 重载（overload）函数有同样的名称，但是参数列表不相同的情形，这样的同名不同参数的函数之间，互相称之为重载函数。 NOTICE 除了赋值运算符重载函数以外，所有的运算符重载函数都可以被派生类继承。也就是说复制运算操作符不能被继承 attribute ((constructor)) gcc为函数提供了几种类型的属性，其中包含：构造函数(constructors)和析构函数(destructors)。程序员应当使用类似下面的方式来指定这些属性： static void start(void) attribute ((constructor)); static void stop(void) attribute ((destructor));带有”构造函数”属性的函数将在main()函数之前或者动态库被load之前被执行，而声明为”析构函数”属性的函数则将在main()或者动态库unload的时候退出时执行。 reference：https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#Common-Function-Attributes 多线程互斥量 注意互斥量的粒度，通常来讲对于一个变量就要对应一个互斥量，这是最优方案，另外可以增加粒度比如多个变量对应同一个互斥量，这样会影响效率，如果允许可以这样 互斥量尽量存在于基类中，这样对于使用者是透明的。 pthread_attr_setscopepthread_attr_setscope函数的作用是设置线程的在什么范围内竞争CPU资源，可以取值PTHREAD_SCOPE_SYSTEM或PTHREAD_SCOPE_PROCESS，前者表示在整个系统内竞争CPU资源，后者表示在同一进程内竞争CPU资源，默认为前者，原型如下：int pthread_attr_setscope(pthread_attr_t *attr, int scope); pthread_attr_setstacksize设置线程栈的大小, 单位是字节，在默认情况下线程的栈是比较大的 pthread_attr_setdetachstatepthread_attr_setdetachstate函数的作用是设置线程的detachedstate属性，可以取值PTHREAD_CREATE_JOINABLE和PTHREAD_CREATE_DETACHED，前者是默认值，表示其他线程可以使用pthread_join函数等待本线程结束，后者表示其他线程不可以对本线程使用pthread_join pthread_attr_setschedpolicypthread_attr_setschedpolicy函数的作用是设置schedpolicy属性，即线程调度算法。schedpolicy属性值可以是SCHED_RR、SCHED_FIFO、SCHED_OTHER，其中SCHED_RR表示轮训调度，SCHED_FIFO表示先进先出调度，SCHED_OTHER表示其他。拥有管理员权限的进程才可以创建具有SCHED_RR或SCHED_FIFO调度算法的线程，一般线程的默认调度算法都是SCHED_OTHER。 pthread_once12345#include &lt;pthread.h&gt;int pthread_once(pthread_once_t *once_control, void (*init_routine)(void));pthread_once_t once_control = PTHREAD_ONCE_INIT; The first call to pthread_once() by any thread in a process, with a given once_control, will call the init_routine() with no arguments. Subsequent calls of pthread_once() with the same once_control will not call the init_routine(). On return from pthread_once(), it is guaranteed that init_routine() has completed. The once_control parameter is used to determine whether the associated initialisation routine has been called.The function pthread_once() is not a cancellation point. However, if init_routine() is a cancellation point and is canceled, the effect on once_control is as if pthread_once() was never called. The constant PTHREAD_ONCE_INIT is defined by the header . The behaviour of pthread_once() is undefined if once_control has automatic storage duration or is not initialised by PTHREAD_ONCE_INIT. pthread_cond_signal()也要配合mutex来使用，不然会可能丢失signal，考虑如下： 123456789Process A Process Bpthread_mutex_lock(&amp;mutex);while (condition == FALSE) condition = TRUE; pthread_cond_signal(&amp;cond);pthread_cond_wait(&amp;cond, &amp;mutex); 如果刚好是这个情形，那么由于B没加锁，那么本来符合条件的A也再次被阻塞 fseek 线程不安全可考虑用pread，替代fseek和fread组合 strtok()strtok是一个线程不安全的函数，他的安全版本是strtok_r() 网络和进程通信readv()和writev()这两个函数类似于read和write，不过readv和writev允许单个系统调用读入到或写出自一个或多个缓冲区。这些操作分别称为分散读（scatter read）和集中写（gather write），因为来自读操作的输入数据被分散到多个应用缓冲区中，而来自应用缓冲区的输出数据则被集中提供给单个写操作。 12345678#include &lt;sys/uio.h&gt;ssize_t readv(int filedes, const struct iovec *iov, int iovcnt);ssize_t writev(int filedes, const struct iovec *iov, int iovcnt);struct iovec &#123; void *iov_base; /* starting address of buffer */ size_t iov_len; /* size of buffer */&#125;; TCP当服务器close了一个连接之后，如果client接着发送数据，会收到一个RST相应，client再发送数据时，就会收到一个SIGPIPE给进程，默认动作是结束client进程，我们可以使用如下方法来指定信号的处理 1234#include &lt;signal.h&gt;signal(SIGPIPE, SIG_IGN);signal(SIGCHLD, SIG_IGN); read and write他们有不同的buffer，所以是全双工运行， read返回0：表示连接关闭，或者说EOF read返回&lt;0: 表示发生错误，check errno DNS Lookup123456789101112struct hostent *gethostbyname(const char *name);int gethostbyname_r(const char *name,struct hostent *ret, char *buf, size_t buflen,struct hostent **result, int *h_errnop); struct hostent &#123; char *h_name; /* official name of host */ char **h_aliases; /* alias list */ int h_addrtype; /* host address type */ int h_length; /* length of address */ char **h_addr_list; /* list of addresses */&#125; gethostbyname_r线程安全，gethostbyname不是线程安全的。 Network Address Convertconst char *inet_ntop(int af, const void *src, char *dst, socklen_t size); This function converts the network address structure src in the af address family into a character string. The resulting string is copied to the buffer pointed to by dst, which must be a non-NULL pointer. The caller specifies the number of bytes available in this buffer in the argument size. 与此相似的还有inet_ntoa, 但是他是线程不安全的。 1int inet_pton(int af, const char *src, void *dst); 反向转换 多种sockaddr struct sockaddr struct sockaddr_in struct sockaddr_storage 网络字节序 htons ntohs htonl ntohl 类内初始化和初始化列表好像C++11之后就支持类内初始化了，在之前类内初始化是不允许的 1234class A&#123; static const int a = 7; //C++98允许 int b = 8; //C++11允许，而98不允许&#125; 如果两者同时出现 那么初始化列表会覆盖类内初始化 虚继承1234567891011121314151617class A&#123;public: void print()&#123; // &#125;&#125;class B&#123;public: void print()&#123; // &#125;&#125;class C:public A, B&#123; &#125; 如上例子如果我们使用c.print就会出现二义性的问题，采用虚继承可以解决这个问题 1234567891011class C:public virtual A, B&#123; &#125;int main()&#123; C c(); c.print() c.A::print()//可以指定使用哪个版本 c.B::print()&#125; Deamon一个守护进程需要fork两次，并且调用setsid()，两次是为了摆脱终端对于程序生命周期的控制，使其成为init 1进程的子进程，setsid会设置一个新的回话，不然进程会随着本回话的退出而结束。The second fork(2) is there to ensure that the new process is not a session leader。 mmap mmap allows all those processes to share the same physical memory pages, saving a lot of memory. 在swap的时候，如果是使用malloc的部分要交换到swap区，但是如果是mmap则不用，因为他可以找到对应文件，在swap back的时候可以重新映射，这在处理大文件的时候非常有用 限制是，如果是32位的系统，地址空间有限 不会拷贝到内存空间，不论是不论是物理内存还是虚拟内存，但是占用地址 删除一个已经打开的文件 If the file is moved (in the same filesystem) or renamed, then the file handle remains open and can still be used to read and write the file. If the file is deleted, the file handle remains open and can still be used (This is not what some people expect). The file will not really be deleted until the last handle is closed. If the file is replaced by a new file, it depends exactly how. Either the file is overwritten, in which case the file handle will still be valid and access the new file, or the existing file is unlinked and a new one created with the same name, in which case it’s the same as deletion (see above). In general, once the file is open, the file is open, and nobody changing the directory structure can change that - they can move, rename the file, or put something else in its place, it simply remains open. typename泛型编程中，经常出现泛型和变量混淆的情况例如FooClass::type * p，这里的歧义是，到底是声明一个指针，还是做乘法，这个时候我们就可以显示的告诉他typename FooClass::type* p 泛型的实例化和特例化 由于泛型是在编译期间，由编译器生成类或者函数的，所以编译器需要知道类或者方法的定义，不仅仅只是声明 特例化发生在，模板类不能被直接套用的时候，用tempalate &lt;&gt;特例化一个模板 extern “C”理论上我们在写C++程序的时候调用C标准库都需要告诉编译器这些C标准库的函数需要extern C，但是实际上标准库都为我们做好了 123456789#ifdef __cplusplusextern \"C\"&#123;#endif//declare.#ifdef __cplusplus&#125;#endif ranged-for下面两者等同 123RecordMap&lt;T&gt; replica_map;for(auto&amp; itr : replica_map)&#123;&#125;for(typename RecordMap&lt;T&gt;::iterator::value_type&amp; itr : replica_map)&#123;&#125; 另类SingletonThe friend declaration appears in a class body and grants a function or another class access to private and protected members of the class where the friend declaration appears.1234567891011Writer* getWriter()&#123; return new Writer();&#125;class Writer&#123; //这里的一个声明确保了外部的同名 函数可以访问内部protected资源，也是一种单例的模式 friend Writer* getWriter(); protected: Writer()&#123;&#125; ~Writer()&#123;&#125;&#125; C++ Idioms/Execute-Around Pointer有些时候我们需要像python装饰器一样的东西，这个时候Execute-Around Pointer是一个很好的技巧，如下code完成了在每次push_back之前后打印Size 123456789101112131415161718192021222324252627282930class VisualizableVector &#123; public: class proxy &#123; public: proxy (vector&lt;int&gt; *v) : vect (v) &#123; std::cout &lt;&lt; \"Before size is: \" &lt;&lt; vect-&gt;size (); &#125; vector&lt;int&gt; * operator -&gt; () &#123; return vect; &#125; ~proxy () &#123; std::cout &lt;&lt; \"After size is: \" &lt;&lt; vect-&gt;size (); &#125; private: vector &lt;int&gt; * vect; &#125;; VisualizableVector (vector&lt;int&gt; *v) : vect(v) &#123;&#125; proxy operator -&gt; () &#123; return proxy (vect); &#125; private: vector &lt;int&gt; * vect;&#125;;int main()&#123; VisualizableVector vecc (new vector&lt;int&gt;); //... vecc-&gt;push_back (10); // Note use of -&gt; operator instead of . operator vecc-&gt;push_back (20); //等同于vecc.operator-&gt;()&#125; C++ Idioms/Execute-Around Pointer operators overload Hack with LD_PRELOAD这个可以用来覆盖要load的动态库中的方法或者类什么的，可以做hack，是个hook Reverse Engineering with LD_PRELOAD 利用LD_PRELOAD进行hook 尾递归Tail call是一个处理递归爆栈的好方案，但是并不是说Tail call就一点栈开销的没有，另外C++有时候虽然使用了Tall call但是并没达到预期效果，因为一些对象的析构可能会影响他，可以采取一些传引用或者传指正的方法处理，不过如果能用循环就别用递归 FILE 线程安全 在同一个进程内, 针对同一个FILE*的操作(比如fwrite), 是线程安全的(Windows不是哦) As an example, the POSIX standard requires that C stdio FILE operations are atomic. POSIX-conforming C libraries (e.g, on Solaris and GNU/Linux) have an internal mutex to serialize operations on FILEs. However, you still need to not do stupid things like calling fclose(fs) in one thread followed by an access of fs in another. 对于PIPE和FIFO, 只要写入数据不超过PIPE_BUF size那么也是atomicPIPE DOC, 但是对于文件：This volume of POSIX.1-2008 does not specify behavior of concurrent writes to a file from multiple processes. Applications should use some form of concurrency control. O_APPEND The file is opened in append mode. Before each write(2), the file offset is positioned at the end of the file, as if with lseek(2). O_APPEND may lead to corrupted files on NFS filesystems if more than one process appends data to a file at once. This is because NFS does not support appending to a file, so the client kernel has to simulate it, which can’t be done without a race condition.O_APPEND DOC OpenBSD 的代码里 fwrite是有文件锁的。。。 有人写了程序验证超过PIPE_BUF会不会乱序，答复是这样的： It’s not luck, in the sense that if you dig into the kernel you can probably prove that in your particular circumstances it will never happen that one processes’ write is interleaved with another one. I am assuming that: You are not hitting any file size limits You are not filling the filesystem in which you create the test file The file is a regular file (not a socket, pipe, or something else) The filesystem is local The buffer does not span multiple virtual memory mappings (this one is known to be true, because it’s malloc()ed, which puts it on the heap, which it contiguous. The processes aren’t interrupted, signaled, or traced while write() is busy. There are no disk I/O errors, RAM failures, or any other abnormal conditions. (Maybe others)You will probably indeed find that if all those assumptions hold, it is the case that the kernel of the operating system you happen to be using always accomplishes a single write() system call with a single atomic contiguous write to the following file. That doesn’t mean you can count on this always being true. You never know when it might not be true when: the program is run on a different operating systemthe file moves to an NFS filesystemthe process gets a signal while the write() is in progress and the write() returns a partial result (fewer bytes than requested). Not sure if POSIX really allows this to happen but I program defensively!etc…So your experiment can’t prove that you can could on non-interleaved writes.","tags":[{"name":"c","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"}]},{"title":"Linux Command Notes","date":"2016-09-29T10:07:24.000Z","path":"2014-9-2-linux-command-note/","text":"stat可以用stat命令，查看某个文件的inode信息 mountmount a dir -t 指定文件系统类型，通常可以不指定，除了一些特殊的比如, smbfs, tmpfs, proc, sysfs等等 -bind 通常来讲mount是mount一个设备到文件目录，但是同样可以使用bind来mount一个目录到另一个目录 -o 代表 option，12mount -o bindmount -bind mount一个网络共享文件夹1mount //10.103.226.143/abc /mnt/net 这个对Ubuntu和Mint有效，有些情况下可能需要指定文件系统格式 -t smbfs -o username=root, password=pass umount a busy device1umount -l unpacked/rbe -l 代表lazy，可以强制umount一个device，如果依旧不行，可以尝试用 123lsof | grep unpacked/rbe//或者fuser a file 来查找具体是谁占用了，Kill他 skip an existed dir1mkdir -p dir1 Create a link12ln file1 file2ln -s file1 file2 hard link and soft link X windowsX Windows包含几个部分: X server, 主要用于和硬件打交道，把绘图展示到显示器上 X client，关注与如何绘图，和绘制什么样的图形，一个完全抽象出来的脱离硬件的层面 Display manager, 用来管理多个Xclient绘制的窗口，最常见的有gdm，lightdm，sddm(kde), twm，i3block等 调整分辨率12xrandr -lxrandr -s 1280x960 分辨率需要驱动支持，如果不支持会报错。 对于VBOX和VM，需要先安装VBOX tools和vmware-tools有些时候需要更改显示驱动，在Xorg.conf中，虚拟机和服务器大多默认vesa Console/Terminal这是两个很容易混淆的概念，Console通常指的是一个串行借口，Terminal通常指的是一个Bash, Console通常会启动一个Bash Console分为两种，ttyX和ttySX, 前者是一个逻辑上的Console，后者是物理上的Serial Console，Console的相关设置，可以在Grub这类工具中设置，Linux中通常是使用tty了，如果你有个COM口，那么可以用ttyS 系统在启动的时候inittab中会设置，通过getty来获得一个console Text Console的分辨率就不能用xrandr了，可以在grub中通过vga=ask/ID来设置，具体ID取决于硬件支持 stty可以设置tty相关属性，比如对应快捷键 权限操作 adduser addgroup 加user到group groupadd 新建一个group usermod 可以改变user的属性，比如属于哪个Group，注意group改完要重新gdm进去才能生效 SElinux是一个更高级的权限管理，可以避免一个有很高权限的程序随意访问文件系统，比如httpd，一个普通用户可以操作httpd来访问root权限的目录 DNS lookup1234567891011121314151617181920212223242526272829303132333435sslvpn:~# host -a baidu.comTrying \"baidu.com\";; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 53987;; flags: qr rd ra; QUERY: 1, ANSWER: 14, AUTHORITY: 0, ADDITIONAL: 7;; QUESTION SECTION:;baidu.com. IN ANY;; ANSWER SECTION:baidu.com. 462 IN A 123.125.114.144baidu.com. 462 IN A 220.181.111.85baidu.com. 462 IN A 220.181.111.86baidu.com. 86262 IN NS ns4.baidu.com.baidu.com. 86262 IN NS dns.baidu.com.baidu.com. 86262 IN NS ns3.baidu.com.baidu.com. 86262 IN NS ns2.baidu.com.baidu.com. 86262 IN NS ns7.baidu.com.baidu.com. 7062 IN SOA dns.baidu.com. sa.baidu.com. 2012120775 300 300 2592000 7200baidu.com. 7062 IN MX 20 mx1.baidu.com.baidu.com. 7062 IN MX 20 jpmx.baidu.com.baidu.com. 7062 IN MX 20 mx50.baidu.com.baidu.com. 7062 IN MX 10 mx.n.shifen.com.baidu.com. 7062 IN TXT \"v=spf1 include:spf1.baidu.com include:spf2.baidu.com include:spf3.baidu.com a mx ptr ~all\";; ADDITIONAL SECTION:ns4.baidu.com. 86262 IN A 220.181.38.10dns.baidu.com. 86262 IN A 202.108.22.220ns3.baidu.com. 86262 IN A 220.181.37.10ns2.baidu.com. 86262 IN A 61.135.165.235ns7.baidu.com. 86085 IN A 119.75.219.82mx1.baidu.com. 162 IN A 61.135.163.61jpmx.baidu.com. 7062 IN A 61.208.132.13Received 508 bytes from 10.8.85.239#53 in 218 ms man123456789man --regex ‘convert’--Man-- next: gsettings-schema-convert(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: tapconvert(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: 2to3(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: 2to3-3.2(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: addr2line(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: atobm(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: b2m(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ]--Man-- next: bdftopcf(1) [ view (return) | skip (Ctrl-D) | quit (Ctrl-C) ] 查看所有convert相关的手册 Source1source /root/.bashrc 查看程序依赖关系12345678ldd /usr/bin/openssl linux-vdso.so.1 =&gt; (0x00007fffcd05c000) libssl.so.1.0.0 =&gt; /tip/bldfs/usr/lib/libssl.so.1.0.0 (0x00007fe45fb99000) libcrypto.so.1.0.0 =&gt; /tip/bldfs/usr/lib/libcrypto.so.1.0.0 (0x00007fe45f7b1000) libdl.so.2 =&gt; /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fe45f5aa000) libz.so.1 =&gt; /tip/bldfs/usr/lib/libz.so.1 (0x00007fe45f394000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe45f009000) /lib64/ld-linux-x86-64.so.2 (0x00007fe45fe07000) nm 查看库文件导出symbol1234objdump -T /usr/lib/libcrypto.so.1.0.0| grep EVP_rc400000000000fbe20 g DF .text 0000000000000008 OPENSSL_1.0.0 EVP_rc400000000001086e0 g DF .text 0000000000000008 OPENSSL_1.0.1 EVP_rc4_hmac_md500000000000fbe30 g DF .text 0000000000000008 OPENSSL_1.0.0 EVP_rc4_40 RBE编译问题1LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/:$LD_LIBRARY_PATH 由于有两个libcrypto.so.1.0.0，分别在/tip/bldfs/usr/lib/里和/usr/lib/x86_64-linux-gnu, 两个版本不同 一个为1.0.0 一个为1.0.1 所以在使用ssl相关工具， 比如ssh，rsync时候会显示找不到symbol，这时需要手动设置LD_LIBRARY_PATH LIBRARY_PATH is used by gcc before compilation to search for directories containing libraries that need to be linked to your program. LD_LIBRARY_PATH is used by your program to search for directories containing the libraries after it has been successfully compiled and linked. 程序栈最大大小1ulimit -s 查看每个目录硬盘占的空间123du -smdf -ah //查看各个盘空间fdiks -l 作业控制123456789/usr/bin/policyserver&amp;(kili64-rbe)shgao-virtual-machine:/tip/src/avt/gentoo# jobs[1]+ Stopped /usr/local/extranet/bin/policyserver -f --logserverport 0(kili64-rbe)shgao-virtual-machine:/tip/src/avt/gentoo# bg 1[1]+ /usr/local/extranet/bin/policyserver -f --logserverport 0 &amp;(kili64-rbe)shgao-virtual-machine:/tip/src/avt/gentoo# jobs[1]+ Running /usr/local/extranet/bin/policyserver -f --logserverport 0 &amp;(kili64-rbe)shgao-virtual-machine:/tip/src/avt/gentoo# ctrl+z 暂停并放到后台 程序后面加上&amp;，使之自动在后台运行 bg 将一个在后台暂停的命令，变成继续执行 fg 将后台中的命令调至前台继续运行 kill %num num不是PID ldconfig1ldconfig -v ldconfig是一个动态链接库管理命令，为了让动态链接库为系统所共享,还需运行动态链接 库的管理命令--ldconfig ldconfig 命令的用途,主要是在默认搜寻目录(/lib和/usr/lib)以及动态库配置文件/etc/ld.so.conf内所列的目录下,搜索出可共享的动态 链接库(格式如前介绍,lib*.so*),进而创建出动态装入程序(ld.so)所需的连接和缓存文件.缓存文件默认为 /etc/ld.so.cache,此文件保存已排好序的动态链接库名字列表. 他的存在是为了程序可以更快的load相关的lib，相当于一个cache chkconfig1234567shgao@shgao-virtual-machine:~/workplace/Firmware/EXSeriesVPN$ chkconfig --listacpi-support 0:off 1:off 2:on 3:on 4:on 5:on 6:offacpid 0:off 1:off 2:off 3:off 4:off 5:off 6:offalsa-restore 0:off 1:off 2:off 3:off 4:off 5:off 6:offalsa-store 0:off 1:off 2:off 3:off 4:off 5:off 6:offanacron 0:off 1:off 2:off 3:off 4:off 5:off 6:offapparmor 0:off 1:off 2:off 3:off 4:off 5:off 6:off S:on –add 新增所指定的系统服务 –del 删除所指定的系统服务 –level 指定该系统服务要在哪个执行等级中开启或关闭 –list 列出当前可从chkconfig指令管理的所有系统服务和等级代号 on/off/reset 在指定的执行登记,开启/关闭/重置该系统服务 正则表达式 +表示重复一次或多次 [] 中的字符不需要转义，就表示本义 ?: 告诉引擎匹配前导字符0次或一次。事实上是表示前导字符是可选的。 +: 告诉引擎匹配前导字符1次或多次 *: 告诉引擎匹配前导字符0次或多次 {}: 表示前导字符重复的次数 (): 组（向后引用） . 匹配任意字符（除了\\n） \\b 匹配单词边界 \\B 匹配非单词边界 | 与 cat|dog，与[]相似，但是[]只能匹配一个字符 \\w 匹配一个单词 \\W 匹配任何非单词的字符 (?&gt;正则表达式) ：阻止海量回溯 正则表达式具有贪婪性，可以用在?,+,*,{}之后加一个?来实现这一点，或者靠取反：&lt;[^&gt;]+&gt; 在字符集[]中， 除了]\\^-需要转义，其他都不用转义，当然转义也不会错 向后引用： 123grep -E '(\\w)\\1' /var/log/test 3 rrrr135 nnn Grep1234grep -En \"\\-j\" Makefilegrep -En '\\-j' Makefilegrep -Ev ' ps [0-9a-z]* Debug 3 ' ap_ps.log &gt; ap_ps_rip_debug3.log 双引号会先解析其中的变量和命令 单引号是原样匹配 \\ 转义，不要记错… -A 5 向后5行 -B 5 向前5行 -C 5 前后各5行 -H 显示文件名 -v 取反 awk12awk -F' ' '$5=\"ap\" &#123;print NR \":\" $(NF) &#125;' /var/log/aventail/access_servers.logawk '&#123;if(NF&gt;=6)&#123;for (i=5;i&lt;=NF;i++)printf(\"%s \", $i);printf \"\\n\"&#125;&#125;' tmp.log //输出第六列之后所有列 -F 表示分隔符 $5 表示第五个 NR 表示行号，内嵌 NF 表示每行有几个分割域 sed1sed ‘s/^[A-Z]*/replace/g’ g 表示global strace记录命令的系统调用，例如 1234567891011121314151617181920212223242526272829303132333435363738394041#strace echo “abc”execve(\"/bin/echo\", [\"echo\", \"aa\"], [/* 36 vars */]) = 0brk(0) = 0x882000access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2ca3275000access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory)open(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=66284, ...&#125;) = 0mmap(NULL, 66284, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f2ca3264000close(3) = 0access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)open(\"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0&gt;\\0\\1\\0\\0\\0\\200\\30\\2\\0\\0\\0\\0\\0\"..., 832) = 832fstat(3, &#123;st_mode=S_IFREG|0755, st_size=1811128, ...&#125;) = 0mmap(NULL, 3925208, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f2ca2c96000mprotect(0x7f2ca2e4b000, 2093056, PROT_NONE) = 0mmap(0x7f2ca304a000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b4000) = 0x7f2ca304a000mmap(0x7f2ca3050000, 17624, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f2ca3050000close(3) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2ca3263000mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2ca3262000mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2ca3261000arch_prctl(ARCH_SET_FS, 0x7f2ca3262700) = 0mprotect(0x7f2ca304a000, 16384, PROT_READ) = 0mprotect(0x605000, 4096, PROT_READ) = 0mprotect(0x7f2ca3277000, 4096, PROT_READ) = 0munmap(0x7f2ca3264000, 66284) = 0brk(0) = 0x882000brk(0x8a3000) = 0x8a3000open(\"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3fstat(3, &#123;st_mode=S_IFREG|0644, st_size=7220736, ...&#125;) = 0mmap(NULL, 7220736, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f2ca25b3000close(3) = 0fstat(1, &#123;st_mode=S_IFCHR|0620, st_rdev=makedev(136, 6), ...&#125;) = 0mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2ca3274000write(1, \"aa\\n\", 3aa) = 3close(1) = 0munmap(0x7f2ca3274000, 4096) = 0close(2) = 0exit_group(0) = ? 各种重定向12345678910xmlread /home/xxx/abc/xml 2&gt;&amp;1find . -type d -depth 1 | xargs -I % tar cvzf %.tar.gz %tar cvf - /dir | tar xvf - -C /somewherecat &gt; new_file &lt;&lt; fuckendwrite somethingblablafuckend update-alternatives1234567891011root@shgao-virtual-machine:~# update-alternatives --config ncThere are 2 choices for the alternative nc (providing /bin/nc). Selection Path Priority Status------------------------------------------------------------* 0 /bin/nc.openbsd 50 auto mode 1 /bin/nc.openbsd 50 manual mode 2 /bin/nc.traditional 10 manual modePress enter to keep the current choice[*], or type selection number: 2update-alternatives: using /bin/nc.traditional to provide /bin/nc (nc) in manual mode. Network Tools netcat curl wget ngrep 解决windows下编辑文件结尾有^M问题^M 实际上就是\\r, 如果键盘输入要用C-v，C-m来输入 解决方法一：安装一个dos2unix，可以转换文本 解决方法二：source insight 中Preference-&gt;Files设置文件结尾 Grub rescue12345678grub rescue&gt;set root=(hd1,msdos1)grub rescue&gt;set prefix=(hd1,msdos1)/boot/grubgrub rescue&gt;insmod /boot/grub/i386-pc/normal.modgrub rescue&gt;normal//之后进入了grub&gt;grub&gt;linux /boot/bzImage //加载linux kernelgrub&gt;initrd /boot/initrd.gz //加载启动grub&gt;boot grub vga=ask/ID 可以设置text terminal分辨率 重新创建xorg.conf有些时候xorg.conf的配置会别改坏，用如下方法可以生成一个新的xorg.conf 1.switch to console mode: Alt+Ctrl+F1 2.kill x server: sudo service lightdm stop 3.generate new xorg.conf file: sudo X -configure – this will create xorg.conf.new file in your current dir 4.rename and move: sudo mv xorg.conf.new /etc/X11/xorg.conf 5.return to GUI: sudo start lightdm vnc4server12# vnc4server :1 //启动一个vnc display# vnc4server -kill :1 查看硬件状态12lscpulshw -C display //查看显卡 网络配置12ifconfig eth0 10.103.250.11 netmask 255.255.255.0route add default gw 10.103.250.1 DNS 配置在 /etc/resolv.conf /etc/hosts /etc/hostname echoecho -e 可以输出转义字符例如 echo -e &quot;abc\\ndef&quot;&gt; file, 注意有些shell支持的不好，比如sh（会把-e 一同输出出去），bash支持良好，最好的办法还是用printf命令替代echo -e， 注意printf命令不支持浮点类型 pipepopen, pclose - pipe stream to or from a process 12345#include &lt;stdio.h&gt;FILE *popen(const char *command, const char *type);int pclose(FILE *stream); pipe 实际上是fork了一个子进程来运行，所以调用popen运行的命令和主程序share同一套文件描述符 popen 打开的fp不能rewind(), 只有文件可以rewind 而pipe是一个流Stream xmllintxmllint是一个很方便的处理及验证xml的工具，linux下只要安装libxml2就可以使用这个命令，下面整理一些常用功能 –format 此参数用于格式化xml，使其具有良好的可读性。 –noblanks 与–format相反，有时为了节省传输量，我们希望去掉xml中的空白，这时我们可以使用–noblanks命令 –schema 使用scheam验证xml文件的正确性 xmllint --schema person.xsd person.xml 共享库的兼容问题动态链接库一般以lib开头，形如libmymodule.so.1.0.0. 后面跟的三个版本号，从左到右的含义为： 1) 大版本号，当接口变得和之前不兼容，则新增一个大版本号。2) 一般增加了接口，不过旧的接口不变，则新增此版本号。3) 接口不做任何变化，只是实现做了修改，则新增此版本号。 可以用ldconfig来设置程序对应的lib版本 1nm policyserver //查看导出符号 PATH每个shell都有自己的PATH，从这个shell运行的程序共享这个shell的PATH, 如果需要永久性保存一个PATH，则需要在/etc/profile或者~/.bashrc_profile中加入export PATH=/xxx/yyy:$PATH openssl生成证书 用户浏览器将其SSL版本号、加密设置参数、与session有关的数据以及其它一些必要信息发送到服务器。 服务器将其SSL版本号、加密设置参数、与session有关的数据以及其它一些必要信息发送给浏览器，同时发给浏览器的还有服务器的证书。如果配置服务器的SSL需要验证用户身份，还要发出请求要求浏览器提供用户证书。 客户端检查服务器证书，如果检查失败，提示不能建立SSL连接。如果成功，那么继续。 客户端浏览器为本次会话生成div-master secret，并将其用服务器公钥加密后发送给服务器。 如果服务器要求鉴别客户身份，客户端还要再对另外一些数据签名后并将其与客户端证书一起发送给服务器。 如果服务器要求鉴别客户身份，则检查签署客户证书的CA是否可信。如果不在信任列表中，结束本次会话。如果检查通过，服务器用自己的私钥解密收到的div-master secret，并用它通过某些算法生成本次会话的master secret。 客户端与服务器均使用此master secret生成本次会话的会话密钥(对称密钥)。在双方SSL握手结束后传递任何消息均使用此会话密钥。这样做的主要原因是对称加密比非对称加密的运算量低一个数量级以上，能够显著提高双方会话时的运算速度。 客户端通知服务器此后发送的消息都使用这个会话密钥进行加密。并通知服务器客户端已经完成本次SSL握手。 服务器通知客户端此后发送的消息都使用这个会话密钥进行加密。并通知客户端服务器已经完成本次SSL握手。 本次握手过程结束，会话已经建立。双方使用同一个会话密钥分别对发送以及接受的信息进行加、解密。 12345678910111213//生成CA根证书及私钥mkdir demoCA &amp;&amp; cd demoCA &amp;&amp; mkdir private crl certs newcerts #新建证书存放目录echo '00' &gt; serial #新建serial文件并写入初始序列号00touch index.txt #新建index.txt空文件openssl genrsa -out private/cakey.pem 1024 #生成CA根证书私钥openssl req -new -x509 -key private/cakey.pem -out cacert.pem #生成CA根证书，注意如果不是-x509生成的是一个证书的request，还要自签名CA： openssl ca -selfsign xxxxxxxxxxx//生成服务器证书私钥、证书，可用于https服务器openssl genrsa -out private/server.key 1024openssl req -new -key private/server.key -out crl/server.csr #生成证书请求文件，可提供认证CA签核，或自签名。//在这之前，你可能需要修改配置`/usr/lib/ssl/openssl.cnf`指定CA的位置, 否则退回上一级执行这个cd .. &amp;&amp; openssl ca -in ./demoCA/crl/server.csr -out ./demoCA/certs/server.crt #自签名证书openssl pkcs12 -export -clcerts -in certs/server.crt -inkey private/server.key -out server.p12 PKCS#12包含私钥，所以在需要客户端验证的时候要用PKCS证书，而crt不包含私钥 证书通常包含三种，CA证书，server证书，client证书 server和client证书（两者实际上可以互换）都是有CA签发的（应包含私钥），如果是crt格式其中是只有他的一个公共证书和公钥，PKCS#12可以包含私钥和公共证书 也可以没有CA证书，server和client自签名自己的证书 x509是一个证书格式，不是一个算法 证书是一个链，包含从根CA到用户cert所有证书，验证的时候要逐一验证。 CA的类别 自签名 CA: 在自签名 CA 中，证书中的公钥和用于验证证书的密钥是相同的。一些自签名 CA 是根 CA（参见第三项）。 从属 CA: 在从属 CA 中，证书中的公钥和用于核实证书的密钥是不同的。一个 CA 向另一个 CA 颁发证书的过程叫做 交叉认证 。 根 CA: 根 CA 是一种特殊的 CA，它受到客户无条件地信任，位于证书层次结构的最高层。所有证书链均终止于根 CA。根颁发机构必须对它自己的证书签名，因为在证书层次结构中再也没有更高的认证机构了。 所有自签名 CA 都是根 CA，因为到自签名 CA 时证书链就终止了。 vinoNo security type 问题解决方法1gsettings set org.gnome.Vino require-encryption false UNIX socket上限在使用Nginx+gunicorn+web.py unix socket方式时候，发现nginx会报“connect() to unix:/dev/shm/fcgi.sock failed (11: Resource temporarily unavailable) while connecting to upstream” 原因是需要修改如下： 12cat /proc/sys/net/core/somaxconn //默认是128，定义了系统中每一个端口最大的监听队列的长度，这是个全局的参数echo 8192 &gt; /proc/sys/net/core/somaxconn //放到/etc/rc.local中 Reference of /proc/sys/net/core mv tip12345mkdir folder1mkdir folder2touch folder1/file1touch folder2/file2mv -f folder1 folder2 这个时候folder1会成为folder2的一个子文件夹，而如果两个都是空文件夹的时候，才会是重命名到folder2 僵尸进程It’s a process that is dead, but its parent was busy doing some other work, hence it could not collect the child’s exit status. environment系统启动时候加载/etc/environment, 登陆时加载/etc/profile，针对每个用户的加载~/.profile, 对于non-login-shell, 读取~/.bashrc exec使用现有shell运行程序, 而不是作为子进程 sys, proc, tmpfsThe sysfs filesystem was mentioned briefly above. One may wonder how sysfs knows about the devices present on a system and what device numbers should be used for them. Drivers that have been compiled into the kernel directly register their objects with a sysfs (devtmpfs internally) as they are detected by the kernel. For drivers compiled as modules, this registration will happen when the module is loaded. Once the sysfs filesystem is mounted (on /sys), data which the drivers register with sysfs are available to userspace processes and to udevd for processing (including modifications to device nodes). With the development of the unstable 2.5 kernel tree, later released as the 2.6 series of stable kernels, a new virtual filesystem called sysfs came to be. The job of sysfs is to export a view of the system’s hardware configuration to userspace processes. With this userspace-visible representation, the possibility of developing a userspace replacement for devfs became much more realistic. DriverLinux的driver是根据一个设备ID来匹配kernel module的 udev通常来说linux不能保证多个同样的设备每次在被创建文件的时候对应同一个文件名，所以我们可以在/etc/udev/rules.d/中创建相关配置 Using the Udev method, only those devices which are detected by the kernel get device nodes created for them. Because these device nodes will be created each time the system boots, they will be stored on a devtmpfs file system (a virtual file system that resides entirely in system memory). Device nodes do not require much space, so the memory that is used is negligible 交叉编译 –with-sysroot=$LFS For cross compilation, this tells the build system to look in $LFS for the target system libraries as needed. –target=$LFS_TGT Because the machine description in the LFS_TGT variable is slightly different than the value returned by the config.guess script, this switch will tell the configure script to adjust Binutil’s build system for building a cross linker binutil, gcc, glibc 是比较关键的交叉编译部件，需要制定LFS_TGT, 可以用现有平台的编译器编译出对方平台的编译器 Reference of target, build, host chrootchroot之前要mount tmpfs proc 和 dev到新的root 常用命令 strip 可以去掉程序中的调试用的符号等 fuser 用来查谁用了哪个文件 vmstat 查看磁盘内存吞吐 free ifstat proc可以看到进程运行时的cmd和env 管道中常用 ‘-’ 表示stdout或者stdin cut -d “:” -f 2 :分割的第二个 cut -c 1-12 1-12个字符 strings 文件中打印字符串 tar 通常不会使用-P, 这样会把/目录包含进来，在extract的时候-C会不起作用 cpio 可以用来备份设备文件，不过要你指定每个文件，他不接受一个文件或者目录参数 dd if=xxx of=yyy bs=xbytes count=xxxx time 统计运行时间: time [command] [args...] tee stdin -&gt; stdout, 也可以同时写入文件，叫双重重定向 tr 可以替换或者删除字段 ^foo^bar 替换上一条命令中的foo为bar然后执行 sudo !! 以sudo运行上一条 dpkg-reconfigure 重新配置一个已经安装过的安装包 oh-my-zsh 是个好东西，加上powerline味道更好哦 journalctl 查看systemd log Process PID PPID SID PGID查看这些可以用ps -ao pid,ppid,sid,pgid,comm, PGID是父进程的PID号，但是父进程的结束并不影响PGID, 组中的所有进程还是沿用同一个PGID，程序中可以对一个进程组来群发信号，SID会有些不同，同一个shell下运行的程序都同属于一个Session，这个Session Leader挂了会导致所有session中的程序退出，所以根据这个我们可以再程序中使用setsid来新建一个新的session，这样程序就不会因为session leader的退出而退出，这也是daemon的基本原理 gsettingsGSettings configuration tool 12gsettings list-schemagsettings set org.mate.session.required-components windowmanager marco readlink获取符号链接 1readlink /proc/$&#123;pid&#125;/exe su and su -进入超级用户模式。也就是输入su -,系统会让你输入超级用户密码，输入密码后就进入了超级用户模式。（当然，你也可以直接用root用）(注意有- ，这和su是不同的，在用命令su的时候只是切换到root，但没有把root的环境变量传过去，还是当前用户的环境变量，用su -命令将环境变量也一起带过去，就象和root登录一样) for for i in {1..10}; do ./elk_tester.py done 给重要文件加锁只读权限示例：给重要文件加锁（添加不可修改位 immutable)，以避免各种误操作带来的灾难性后果（例如 : rm -rf） 12345678$ chattr +i regular_file$ lsattr regular_file----i-------- regular_file$ rm regular_file #加immutable位后就无法对文件进行任何“破坏性”的活动啦rm: remove write-protected regular file `regular_file'? yrm: cannot remove `regular_file': Operation not permitted$ chattr -i regular_file #如果想对它进行常规操作，那么可以把这个位去掉$ rm regular_file 主次设备号主 (major)、次(minor)设备号的作用有不同。当一个设备文件被打开时，内核会根据主设备号（major number）去查找在内核中已经以主设备号注册的驱动（可以 cat /proc/devices 查看已经注册的驱动号和主设备号的对应情况），而次设备号（minor number）则是通过内核传递给了驱动本身（参考《The Linux Primer》第十章）。因此，对于内核而言，通过主设备号就可以找到对应的驱动去识别某个设备，而对于驱动而言，为了能够更复杂地访问设备，比如访问设备的不同部分（如硬件通过分区分成不同部分，而出现 hda1，hda2，hda3 等），比如产生不同要求的随机数（如 /dev/random 和 /dev/urandom 等）。 locate省去打绝对路径1insmod `locate usbhid.ko` GNU parallel可以并行的处理Pipe X windows Xsession 配置/var/lib/AccountService/users/[username] 里面的xsession指定的，具体支持哪些xsession，查看这个目录/usr/share/xsessions/ systemd and upstart &quot;systemctl status networking.service&quot; and &quot;journalctl -xe&quot; 可以查看服务启动的错误原因 upstartupstart 没有 inittab， 所有的配置文件都在/etc/init/目录下，这些脚本是不可执行的，包含两种类型conf和override, rc-sysinit.conf是系统初始化的配置 man 8 init find find -maxdepth 1 -type f -exec ls -al {} \\; 一个转译的;表示命令的结束，这个命令是针对每一个文件执行一次ls find -maxdepth 1 -type f -exec ls -al {} + 这种情况文件只能加在命令尾部，被查到的文件被append到ls尾部，这个命令只执行一次ls available memroyWarning signs of a genuine low memory situation that you may want to look into: available memory (or “free + buffers/cache”) is close to zero swap used increases or fluctuates dmesg | grep oom-killer shows the OutOfMemory-killer at work How to force to release the cache nicetop命令里有%ni,与此相关，nice命令可以修改进程的优先级，这样就可以让进程运行得不那么频繁。 这个功能在运行cpu密集型的后台进程或批处理作业时尤为有用。 nice值的取值范围是[-20,19],-20表示最高优先级，而19表示最低优先级。 Linux进程的默认nice值为0。使用nice命令（不带任何参数时）可以将进程的nice值设置为10。这样调度器就会将此进程视为较低优先级的进程，从而减少cpu资源的分配。 apropos根据关键字找相关的指令 setuid, setgid如果一个可执行文件setuid/gid那么他拥有可执行文件owner、group相同的权限, 如果文件是root，那么他具有和root一样的权限很危险 12chmod u+s fileschmod g+s files 文件空洞在UNIX文件操作中，文件位移量可以大于文件的当前长度，在这种情况下，对该文件的下一次写将延长该文件，并在文件中构成一个空洞，这一点是允许的。位于文件中但没有写过的字节都被设为 0。如果 offset 比文件的当前长度更大，下一个写操作就会把文件“撑大（extend）”。这就是所谓的在文件里创造“空洞（hole）”。没有被实际写入文件的所有字节由重复的 0 表示。空洞是否占用硬盘空间是由文件系统（file system）决定的。","tags":[{"name":"shell","slug":"shell","permalink":"http://matthewgao.github.io/tags/shell/"},{"name":"command","slug":"command","permalink":"http://matthewgao.github.io/tags/command/"},{"name":"linux","slug":"linux","permalink":"http://matthewgao.github.io/tags/linux/"}]},{"title":"HTML CSS Notes","date":"2016-09-12T09:00:59.000Z","path":"html+css/","text":"CSS 这是一个很让人困惑的CSS特征，我之前也谈到过它。我们大家都知道，当按百分比设定一个元素的宽度时，它是相对于父容器的宽度计算的，但是，对于一些表示竖向距离的属性，例如padding-top,padding-bottom,margin-top,margin-bottom等，当按百分比设定它们时，依据的也是父容器的宽度，而不是高度。","tags":[{"name":"html css","slug":"html-css","permalink":"http://matthewgao.github.io/tags/html-css/"}]},{"title":"GDB Notes","date":"2016-08-31T09:34:24.000Z","path":"gdb/","text":"print /f exprexpr is an expression (in the source language). By default the value of expr is printed in a format appropriate to its data type; you can choose a different format by specifying ‘/f’, where f is a letter specifying the format. explore argAnother way of examining values of expressions and type information is through the Python extension command explore (available only if the gdb build is configured with –with-python). It offers an interactive way to start at the highest level (or, the most abstract level) of the data type of an expression (or, the data type itself) and explore all the way down to leaf scalar values/fields embedded in the higher level data types. arg is either an expression (in the source language), or a type visible in the current context of the program being debugged. In general, at any stage of exploration, you can go deeper towards the leaf values by responding to the prompts appropriately, or hit the return key to return to the enclosing data structure (the higher level data structure). Similar to exploring values, you can use the explore command to explore types. Instead of specifying a value (which is typically a variable name or an expression valid in the current context of the program being debugged), you specify a type name. If you consider the same example as above, your can explore the type struct ComplexStruct by passing the argument struct ComplexStruct to the explore command. 1(gdb) explore struct ComplexStruct By responding to the prompts appropriately in the subsequent interactive session, you can explore the type struct ComplexStruct in a manner similar to how the value cs was explored in the above example. The explore command also has two sub-commands, explore value and explore type. The former sub-command is a way to explicitly specify that value exploration of the argument is being invoked, while the latter is a way to explicitly specify that type exploration of the argument is being invoked. explore value exprThis sub-command of explore explores the value of the expression expr (if expr is an expression valid in the current context of the program being debugged). The behavior of this command is identical to that of the behavior of the explore command being passed the argument expr.explore type argThis sub-command of explore explores the type of arg (if arg is a type visible in the current context of program being debugged), or the type of the value/expression arg (if arg is an expression valid in the current context of the program being debugged). If arg is a type, then the behavior of this command is identical to that of the explore command being passed the argument arg. If arg is an expression, then the behavior of this command will be identical to that of the explore command being passed the type of arg as the argument. Examining MemoryYou can use the command x (for “examine”) to examine memory in any of several formats, independently of your program’s data types.x/nfu addrx addrxUse the x command to examine memory.n, f, and u are all optional parameters that specify how much memory to display and how to format it; addr is an expression giving the address where you want to start displaying memory. If you use defaults for nfu, you need not type the slash ‘/’. Several commands set convenient defaults for addr. n, the repeat countThe repeat count is a decimal integer; the default is 1. It specifies how much memory (counting by units u) to display. If a negative number is specified, memory is examined backward from addr. f, the display formatThe display format is one of the formats used by print (‘x’, ‘d’, ‘u’, ‘o’, ‘t’, ‘a’, ‘c’, ‘f’, ‘s’), and in addition ‘i’ (for machine instructions). The default is ‘x’ (hexadecimal) initially. The default changes each time you use either x or print. u: the unit size The unit size is any of b Bytes. h Halfwords (two bytes). w Words (four bytes). This is the initial default. g Giant words (eight bytes). The default for addr is usually just after the last address examined—but several other commands also set the default address: info breakpoints (to the address of the last breakpoint listed), info line (to the starting address of a line), and print (if you use it to display a value from memory). Tip Support pretty-print(python): info pretty-printer info sharedlibrary: 显示关联的动态库 info set 有环境变量？","tags":[{"name":"gdb","slug":"gdb","permalink":"http://matthewgao.github.io/tags/gdb/"}]},{"title":"SHELL Command/Script Notes","date":"2016-07-28T15:59:04.000Z","path":"2014-9-2-shell-note/","text":"$ $$ 返回PID， $是个内部变量 $? 表示上一个指令的返回值 $0 表示函数或者shell的第一个参数，后面类推 $@ 返回所有参数 当读取参数个数超过9的时候需要加括号$(10)，这是历史原因 set unset 设置程序自定义变量（只对本shell） unset不仅可以unset变量，也可以是函数 export设置为全局环境变量 declare将环境变量转成自定义变量 查找历史命令并执行1$(history | grep -E '^ +1148' | awk -F' ' '&#123;$1=\"\";print&#125;') 参数扩展 ${param:-default} 如果param为空，就把他设置成default ${ #param} 给出param长度 ${var:-string}: 若变量var为空，则用在命令行中用string来替换${var:-string}，否则变量var不为空时，则用变量var的值来替换${var:-string}； ${var:=string}: 替换规则和${var:-string}是一样的，所不同之处是${var:=string}若var为空时，用string替换${var:=string}的同时，把string赋给变量var：${var:=string}很常用的一种用法是，判断某个变量是否赋值，没有的话则给它赋上一个默认值。 ${var:+string}的替换规则和上面的相反，即只有当var不是空的时候才替换成string，若var为空时则不替换或者说是替换成变量 var的值，即空值。(因为变量var此时为空，所以这两种说法是等价的) ${var:?string}替换规则为：若变量var不为空，则用变量var的值来替换${var:?string}；若变量var为空，则把string输出到标准错误中，并从脚本中退出。我们可利用此特性来检查是否设置了变量的值。 变量变量仅仅在声明时、赋值时、被删除时（unset）、被导出时（export），算术运算中使用双括号结构时或在代表信号时（signal，查看样例 32-5）才不需要有 $ 前缀。赋值可以是使用 =（比如 var1=27），可以是在 read 语句中，也可以是在循环的头部（for var2 in 1 2 3）。1 变量即使在双引号””中被引用也不会影响变量替换。我们称之为部分引用，有时候也称弱引用。而使用单引号’’引用时，变量将会作为字符串显示，变量替换也不会发生。我们称之为全引用，有时也称强引用。${var}和用双引号一个效果 输出脚本每一行执行的内容打开这个功能，脚本执行的时候回返回每一个执行的命令12set -x #打开set +x #关闭 expect用于人机交互，属于密码什么的 /dev/tty读取它会自动重定向到一个终端，这在程序必须读取人工输入（比如密码）时候特别有用 1234printf \"Enter password\"stty -echo #关闭自动打印输入内容read pass &lt; /dev/ttystty echo #打开打印输入内容 PATH中添加当前路径PATH=:$PATH 这样会先查找本地路径，也可以用一个点，更明显一点，通常不建议这么用，会有安全问题 各种括号 $(command) 与 \\command`` 是一样的，但是后者已经不建议使用 ${VAR} 用来执行一些变量相关的动作，前面有描述 $((expr)) 用来执行一些运算 单引号不扩展字符串中变量 双引号会扩展字符串中变量 exec12exec 2 &gt; /tmp/file # 2重定向到fileexec 3 &lt; /home/file #打开新文件描述符3 &lt;&gt;&lt;&gt;打开一个文件作为输入输出 subShell与代码块subShell是一群被括在圆括号里的命令，这些命令会在另外的进程中执行 ~~tar -cf - . | (cd /newdir; tar -xpf -)~~","tags":[{"name":"shell","slug":"shell","permalink":"http://matthewgao.github.io/tags/shell/"}]},{"title":"ElasticSearch Note","date":"2016-07-28T06:10:37.000Z","path":"elasticsearch/","text":"ElasticSearch Conceptindex/indicesindex包含多个type typetype包含多个documents documents每一条记录是一个documents Restriction 对于SQL类似的Join命令，ES并不擅长，会消耗大量的计算cycle，间接上只支持子查询 Index LimitationEach Elasticsearch shard is a Lucene index. There is a maximum number of documents you can have in a single Lucene index. As of LUCENE-5843, the limit is 2,147,483,519 (= Integer.MAX_VALUE - 128) documents. You can monitor shard sizes using the _cat/shards api. Analyzed String默认所有string进来都是analyzed，这意味着可能会被分词，所以要在插入数据之前用MAPPing的API设置好MAPPing API Search支持lucence的语法Lucence语法和JSON的DSL语法 LucenceEnter a query string in the Search field: To perform a free text search, simply enter a text string. For example, if you’re searching web server logs, you could enter safari to search all fields for the term safari. To search for a value in a specific field, you prefix the value with the name of the field. For example, you could enter status:200 to limit the results to entries that contain the value 200 in the status field. To search for a range of values, you can use the bracketed range syntax, [START_VALUE TO END_VALUE]. For example, to find entries that have 4xx status codes, you could enter status:[400 TO 499]. To specify more complex search criteria, you can use the Boolean operators AND, OR, and NOT. For example, to find entries that have 4xx status codes and have an extension of php or html, you could enter status:[400 TO 499] AND (extension:php OR extension:html). 支持夸index查詢 Automatic index creation can be disabled by setting action.auto_create_index to false in the config file of all nodes. Automatic mapping creation can be disabled by setting index.mapper.dynamic to false in the config files of all nodes (or on the specific index settings). The index operation can be executed without specifying the id. In such a case, an id will be generated automatically. In addition, the op_type will automatically be set to create. Here is an example (note the POST used instead of PUT) A child document can be indexed by specifying its parent when indexing. When indexing a child document, the routing value is automatically set to be the same as its parent, unless the routing value is explicitly specified using the routing parameter. 需要設置mapping，dynamic mapping不能自动配置parant/child If you only need one or two fields from the complete _source, you can use the _source_include &amp; _source_exclude parameters to include or filter out that parts you need. This can be especially helpful with large documents where partial retrieval can save on network overhead. Both parameters take a comma separated list of fields or wildcard expressions. Example: 123curl -XGET 'http://localhost:9200/twitter/tweet/1?_source_include=*.id&amp;_source_exclude=entities'# shorter notationcurl -XGET 'http://localhost:9200/twitter/tweet/1?_source=*.id,retweeted' inner_hit用来处理nested/child/parent search, 不然他会返回最上级的结果，而不是你期待的，似乎ES本身不支持nested，nested也是会被flatten global aggregation, 可以控制aggs不受query结果影响， 与此类似reverse_nested 可以取回他的父结构的element significant Terms??? pipeline aggregation, 还在试验阶段，这个牛逼啊 Complex Core Field Types filter_pathURI可以指定一个filter_path参数来表示返回那些值，例如： 12345678curl -XGET 'localhost:9200/_nodes/stats?filter_path=nodes.*.ho*'&#123; \"nodes\" : &#123; \"lvJHed8uQQu4brS-SXKsNA\" : &#123; \"host\" : \"portable\" &#125; &#125;&#125; Bucket AggregationsAggregation的结果用于后续bucket或者metric aggregation使用，它只是取得子集Bucket AggregationsBuckets are analogous to SQL GROUP BY statements Metric AggregationsAggregation成可度量的数字Metric Aggregations Scripted fieldsScripted fields use the Lucene expression syntax. For more information, see Lucene Expressions Scripts. Conclusion nested 数据结构，导致insert的资源耗费上升大概50%，因为ES对于update采用的是DELETE-&gt;INSERT的方法，所以额外开销在这里，另外查询也会耗费一定时间，用indexID检索可以忽略这部分 正常的syslog like结构，插入数据高效，但是结构并不是特别清晰 官方文档上说Child/Parant方式查询效率远比nested低Practical Considerations, 如果index时间要求比search要求高，那么可以考虑用parant/child模式 AppendPartial Updates to Documents数据只能使用script方式，默认是关闭的，因为他有注入的风险，所以谨慎使用Scripting include_in_parent 可以把nested的数据，以flat的格式加到他的父节点上，但是这个功能似乎已经deprecate了，开了这个速度有所下降，因为他会反过来搜索parent的element 设计一个以时间为主线的Log分析系统的时候建议使用index_name+time作为index名字，这样更加方便管理和做shard Kibana filter is global?? Include/Exclude Pattern Include/Exclude Pattern Flags JSON input Discover的query不能是一个最终统计值，只是检索数据 Sense 是个好插件，省了用Curl了 Restriction 暂时不支持nested、parant/child的可视化，但是已经有人在做了，不久的将来应该会有 table不支持导出 Discover展开数据也不够友好 Requirement &amp; Desgin Runtime实际上Runtime数据不应该是一个log analyzer应该处理的事情，但是我们依旧暂时假定支持这样做 Active user: 检查session template是否有endtime Active user’s Realm/Zone/Community/IP Statistics TopN Resource的inbound/outbound总和 TopN User的inbound/outbound总和 总的Realm/Zone/Community个数 最常访问资源TopN inbound/outbound流量TopN资源 AccessAgent总个数 Platform总个数 地理位置范围 TopN failure profile 以上都可以做细致区分，比如Active User的如上结果，Web Access的如上结果，Tunnel的如上结果，已经断开连接用户的如上结果 是否是web用户可以通过是否有IP来确定，但是有误差 Design基本包含两个数据类型： SessionInfo: 包含Username, Realm, Community, ClientIP, assigned IP, starttime, endtime, failure profile, Zone, Platform, AccessAgent, 所有这些信息可以通过partial update, 来在后期插入，资源开销基本可控, sessionInfo都以teamID作为_id AccessInfo: 包含teamID, destination, port, protocol, inbound, outbound, 以及所有SessionInfo的数据（可以尝试通过parent/child方式实现), 实际上我们只需要复制一些基础的信息，比如teamID，username，两个IP，accessAgent， 对于其他的item和access resource没有直接关系，也不大可能去分析他们之间的关系，为了这个可能需要KernelSession发送一个teamID（12bytes）出来 CurrentUser: 一个单一的数据，只通过partial update更新 Type Public Internal Modules lower_with_under _lower_with_under TODO 定义timestamp 检索所有不重复的teamId列表(nested query) scripted update可以自加 自減，对于concurrent user可能有用Update Doc, access 记录都加到同一个document下面（会不会有性能问题），kibana支持nested aggregation Upsert 可以处理存在更新， 不存在创建的问题","tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://matthewgao.github.io/tags/elasticsearch/"}]},{"title":"XSLT and XPATH","date":"2016-07-19T05:47:09.000Z","path":"xslt/","text":"xslt这次是为了用xslt来转换一个xml所以临时学习了下xslt call-template和apply-templates对xml模板 来说，name属性是很关键的 call-template /apply-template 的name必须要和模板的name相对应。模板相当于一个函数，可以暂时这么看。而name相当于函数名称. 简单说apply是应用，call是调用。用apply时，引擎自动搜索与当前select指定xpath的匹配节点相匹配的template（该template必须有属性match）并使用该template进行处理，此时需要指定的是select的path。用call时就跟其它语言调用函数一样，必须指定name属性，相应的，该template必须有name属性，当然，也可以在这时with-param(当然相应的模板中有对应的param才行，不过这个不强制要求)。 从名字区分：call-template，一次只对一个node名字有效；而apply-templates，注意是是复数，所以这个是对所有符合条件的node有效。 从手法上：call-template，手段是通过name；apply-templates手段是通过match。 使用apply调用的模板, 其中的上下文节点是与之匹配的节点。使用call调用的模板, 它没有上下文节点，参数通过param进行传递 xpathxsl:if的test，一般对象的select都是一个xpath的表达式 name()函数可以用来取当前element的名字 text()可以取当前element的内容 count()统计element个数 一个xpath可以包含一些条件例如$resource_type[@external = &#39;true&#39;]，表示attribute有externel且为true的节点 12345678910111213&lt;xsl:element name=\"&#123;name($resource_type)&#125;\"&gt; &lt;xsl:attribute name=\"count\"&gt; &lt;xsl:value-of select=\"count($resource_type)\" /&gt; &lt;/xsl:attribute&gt; &lt;xsl:if test=\"count($resource_type[@external = 'true']) != 0\"&gt; &lt;xsl:element name=\"externalServer\"&gt; &lt;xsl:attribute name=\"count\"&gt; &lt;xsl:value-of select=\"count($resource_type[@external= 'true'])\" /&gt; &lt;/xsl:attribute&gt; &lt;/xsl:element&gt; &lt;/xsl:if&gt;&lt;/xsl:element&gt; parser12345678910111213141516171819202122232425262728293031323334#!/usr/bin/env python3# coding=utf-8# Created Time: 2016-06-20__author__ = 'Matthew Gao'import lxml.etree as ETimport pprintdef parse(): pp = pprint.PrettyPrinter(indent=4) xml_filename = 'amc_one_of_everything.xml' xsl_filename = 'phonehometranslator.xsl' dom = ET.parse(xml_filename) xslt = ET.parse(xsl_filename) transform = ET.XSLT(xslt) newdom = transform(dom) # print(ET.tostring(newdom, pretty_print=True)) pp.pprint(ET.tostring(newdom, pretty_print=True).decode()) print(transform.error_log) for entry in transform.error_log: print('message from line %s, col %s: %s' % (entry.line, entry.column, entry.message)) print('domain: %s (%d)' % (entry.domain_name, entry.domain)) print('type: %s (%d)' % (entry.type_name, entry.type)) print('level: %s (%d)' % (entry.level_name, entry.level)) print('filename: %s' % entry.filename)if __name__ == \"__main__\": parse() 调试有人会说用来调试，但是这个在解析出错的时候似乎帮助不大，有些xslt的编辑器可以调试，但是都是付费的，所以没有具体尝试","tags":[{"name":"xml","slug":"xml","permalink":"http://matthewgao.github.io/tags/xml/"}]},{"title":"Vagrant","date":"2016-07-19T05:45:27.000Z","path":"vagrant/","text":"安装和启动 首先安装如下 VirutalBox Vagrant 123456mkdir testvagrant init [an image path]vagrant up # start that imagevagrant ssh # ssh to that hostvagrant destroy #删除 要点 文件共享默认vagrant会连接到本地的一个/vagrant目录，所以要小心不要删除了host上的文件 Isolate每个vagrant都会共享同一个base image，但是他们并不会修改那个image，所以可以放心使用","tags":[{"name":"vagrant","slug":"vagrant","permalink":"http://matthewgao.github.io/tags/vagrant/"}]},{"title":"A Samba Issue","date":"2016-07-19T05:44:47.000Z","path":"samba-issue/","text":"问题描述在安装好Samba之后按照如下配置配置好 123456[Public] path = /home/myname guest ok = yes writable = yes browsable = yes read only = no 但是发现windows并不能访问，始终说没有权限，用其他linux系统可以正常访问 问题定位检查Log，发现多处backtrace 12345678910111213141516171819202122232425262728293031[2016/04/20 21:52:16.574827, 0] ../source3/lib/util.c:900(log_stack_trace) BACKTRACE: 29 stack frames: #0 /usr/lib/x86_64-linux-gnu/samba/libsmbregistry.so.0(log_stack_trace+0x1a) [0x7f470509616a] #1 /usr/lib/x86_64-linux-gnu/samba/libsmbregistry.so.0(smb_panic_s3+0x20) [0x7f4705096240] #2 /usr/lib/x86_64-linux-gnu/libsamba-util.so.0(smb_panic+0x2f) [0x7f4705e0c8ef] #3 /usr/lib/x86_64-linux-gnu/libtalloc.so.2(+0x1b5f) [0x7f4702b94b5f] #4 /usr/lib/x86_64-linux-gnu/libtalloc.so.2(_talloc_steal_loc+0xab) [0x7f4702b9b77b] #5 /usr/lib/x86_64-linux-gnu/libtalloc.so.2(_talloc_move+0x13) [0x7f4702b9b7b3] #6 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(+0x19c868) [0x7f4705a60868] #7 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(get_share_mode_lock+0x17e) [0x7f4705a6149e] #8 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(+0x107b8b) [0x7f47059cbb8b] #9 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(+0x10c1bc) [0x7f47059d01bc] #10 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(create_file_default+0x1cf) [0x7f47059d164f] #11 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(+0x1dab6e) [0x7f4705a9eb6e] #12 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(smb_vfs_call_create_file+0xd8) [0x7f47059d7e78] #13 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(smbd_smb2_request_process_create+0xaff) [0x7f4705a059ff] #14 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(smbd_smb2_request_dispatch+0xc4d) [0x7f47059fe3ed] #15 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(+0x13b072) [0x7f47059ff072] #16 /usr/lib/x86_64-linux-gnu/libsmbconf.so.0(run_events_poll+0x16c) [0x7f4703d2ea8c] #17 /usr/lib/x86_64-linux-gnu/libsmbconf.so.0(+0x25ce0) [0x7f4703d2ece0] #18 /usr/lib/x86_64-linux-gnu/libtevent.so.0(_tevent_loop_once+0x8d) [0x7f4702988cbd] #19 /usr/lib/x86_64-linux-gnu/libtevent.so.0(tevent_common_loop_wait+0x1b) [0x7f4702988e5b] #20 /usr/lib/x86_64-linux-gnu/samba/libsmbd-base.so.0(smbd_process+0x6c9) [0x7f47059ed569] #21 smbd(+0x96b6) [0x7f47064a66b6] #22 /usr/lib/x86_64-linux-gnu/libsmbconf.so.0(run_events_poll+0x16c) [0x7f4703d2ea8c] #23 /usr/lib/x86_64-linux-gnu/libsmbconf.so.0(+0x25ce0) [0x7f4703d2ece0] #24 /usr/lib/x86_64-linux-gnu/libtevent.so.0(_tevent_loop_once+0x8d) [0x7f4702988cbd] #25 /usr/lib/x86_64-linux-gnu/libtevent.so.0(tevent_common_loop_wait+0x1b) [0x7f4702988e5b] #26 smbd(main+0x15b4) [0x7f47064a46c4] #27 /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47025e1ec5] #28 smbd(+0x7a96) [0x7f47064a4a96] 原来是他所依赖的库有兼容性问题，所以更新相关的库 解决1sudo apt-get install -y libsmbclient libsmbclient-dev libtevent0 libtalloc2","tags":[{"name":"linux","slug":"linux","permalink":"http://matthewgao.github.io/tags/linux/"},{"name":"samba","slug":"samba","permalink":"http://matthewgao.github.io/tags/samba/"}]},{"title":"MySQL Note","date":"2016-07-19T05:44:30.000Z","path":"mysql/","text":"基本命名和约束规范 表字符集选择UTF8 ，如果需要存储emoj表情，需要使用UTF8mb4(MySQL 5.5.3以后支持) 存储引擎使用InnoDB 变长字符串尽量使用varchar varbinary 不在数据库中存储图片、文件等 单表数据量控制在1亿以下 库名、表名、字段名不使用保留字 库名、表名、字段名、索引名使用小写字母，以下划线分割 ，需要见名知意 库表名不要设计过长，尽可能用最少的字符表达出表的用途 字段规范 所有字段均定义为NOT NULL ，除非你真的想存Null 字段类型在满足需求条件下越小越好，使用UNSIGNED存储非负整数 ，实际使用时候存储负数场景不多 使用TIMESTAMP存储时间 使用varchar存储变长字符串 ，当然要注意varchar(M)里的M指的是字符数不是字节数；使用UNSIGNED INT存储IPv4 地址而不是CHAR(15) ，这种方式只能存储IPv4，存储不了IPv6 使用DECIMAL存储精确浮点数，用float有的时候会有问题 少用blob text 关于为什么定义不使用Null的原因 浪费存储空间，因为InnoDB需要有额外一个字节存储 表内默认值Null过多会影响优化器选择执行计划 索引规范 单个索引字段数不超过5，单表索引数量不超过5，索引设计遵循B+ Tree索引最左前缀匹配原则 选择区分度高的列作为索引 建立的索引能覆盖80%主要的查询，不求全，解决问题的主要矛盾 DML和order by和group by字段要建立合适的索引 避免索引的隐式转换 避免冗余索引 关于索引规范，一定要记住索引这个东西是一把双刃剑，在加速读的同时也引入了很多额外的写入和锁，降低写入能力，这也是为什么要控制索引数原因。之前看到过不少人给表里每个字段都建了索引，其实对查询可能起不到什么作用。 注意索引引起的死锁问题，会导致性能严重下降，可以通过组合索引来解决这个问题 控制索引前缀长度可以有效的提高效率 冗余索引例子 12345idx_abc(a,b,c) idx_a(a) 冗余 idx_ab(a,b) 冗余 隐式转换例子 1234567字段:remark varchar(50) NOT Null MySQL&gt;SELECT id, gift_code FROM gift WHERE deal_id = 640 AND remark=115127; 1 row in set (0.14 sec) MySQL&gt;SELECT id, gift_code FROM pool_gift WHEREdeal_id = 640 AND remark=‘115127’; 1 row in set (0.005 sec)字段定义为varchar，但传入的值是个int，就会导致全表扫描，要求程序端要做好类型检查 SQL类规范 尽量不使用存储过程、触发器、函数等 避免使用大表的JOIN，MySQL优化器对join优化策略过于简单 避免在数据库中进行数学运算和其他大量计算任务 SQL合并，主要是指的DML时候多个value合并，减少和数据库交互 合理的分页，尤其大分页UPDATE、DELETE语句不使用LIMIT ，容易造成主从不一致 表设计 NULL 表示允许是空值，空值是不同于0，‘’这样的值，所以允许空值会降低索引的效率，通常都设置成NOT NULL 在非STRICT模式下，插入记录时候没有显示的给出一个没有defalut值得时候，不会报错，会默认设置一个默认值，STRICT模式下回直接报错 Log error 日志：记录启动、运行或停止 mysqld 时出现的问题，默认开启。 general 日志：通用查询日志，记录所有语句和指令，开启数据库会有 5% 左右性能损失。 binlog 日志：二进制格式，记录所有更改数据的语句，主要用于 slave 复制和数据恢复。 slow 日志：记录所有执行时间超过 long_query_time 秒的查询或不使用索引的查询，默认关闭。 Innodb日志：innodb redo log、undo log，用于恢复数据和撤销操作。 Tips innodb不仅会打印出事务和事务持有和等待的锁，而且还有记录本身，不幸的是，它可能超过innodb为输出结果预留的长度(只能打印1M的内容且只能保留最近一次的死锁信息)，如果你无法看到完整的输出，此时可以在任意库下创建innodb_monitor或innodb_lock_monitor表，这样innodb status信息会完整且每15s一次被记录到错误日志中。如：create table innodb_monitor(a int)engine=innodb;，不需要记录到错误日志中时就删掉这个表即可。 Commands SHOW ENGINE INNODB STATUS","tags":[{"name":"mysql","slug":"mysql","permalink":"http://matthewgao.github.io/tags/mysql/"}]},{"title":"JavaScript Note","date":"2016-07-19T05:43:06.000Z","path":"javascript/","text":"作用域和声明提前 Javascript并不被作用域{}所控制，所以函数内声明的变量在所有的函数内的scope里都是可见的，因此可以把函数所有的变量都放在最开始声明 123456var scope = \"global\"function func()&#123; console.log(scope)// undefine var scope = \"local\" console.log(scope) // \"local\"&#125; 没初始化的变量默认为undefined NaN Infinity 不能够用x == NaN 判断是否是NaN或者Infinity，可以使用isNaN()或者isInfinity()来判断 属性的四个特性 数据属性 value writable enumerable configurable 存取器属性不具有value和writable特性，写特性是由有没有setter方法决定的 get set enumerable configurable 12345Object.getOwnPropertyDescriptor(&#123;x:1&#125;, 'x') //return &#123;value:1, writable:true, enumerable:true, configurable:true&#125;Object.defineProperty(obj, 'x', &#123;value:1, writable:true, enumerable:true, configurable:true&#125;)//设置属性//不能修改继承属性 this 在构造函数中的this指向所创建的对象 一般的this指向他的上下文 注意他并不遵循 lexical scope, 只是表示上下文（context） 建议不要使用thisYou actually don’t want to access this in particular, but the object it refers to. That’s why an easy solution is to simply create a new variable that also refers to that object. The variable can have any name, but common ones are self and that. 1234567function MyConstructor(data, transport) &#123; this.data = data; var self = this; transport.on('data', function() &#123; alert(self.data); &#125;);&#125; 使用bindExplicitly set this of the callbackIt might look like you have no control over the value of this, because its value is set automatically, but that is actually not the case. Every function has the method .bind [docs], which returns a new function with this bound to a value. The function has exactly the same behavior as the one you called .bind on, only that this was set by you. No matter how or when that function is called, this will always refer to the passed value. 1234567function MyConstructor(data, transport) &#123; this.data = data; var boundFunction = (function() &#123; // parenthesis are not necessary alert(this.data); // but might improve readability &#125;).bind(this); // &lt;- here we are calling `.bind()` transport.on('data', boundFunction);&#125; In this case, we are binding the callback’s this to the value of MyConstructor’s this. Set this of the callback - part 2Some functions/methods which accept callbacks also accept a value to which the callback’s this should refer to. This is basically the same as binding it yourself, but the function/method does it for you. Array#map [docs] is such a method. Its signature is: array.map(callback[, thisArg])The first argument is the callback and the second argument is the value this should refer to. Here is a contrived example: 123456var arr = [1, 2, 3];var obj = &#123;multiplier: 42&#125;;var new_arr = arr.map(function(v) &#123; return v * this.multiplier;&#125;, obj); // &lt;- here we are passing `obj` as second argument 1234567SmaApi.prototype.trigger_all = function(obj)&#123; var propNames = Object.getOwnPropertyNames(obj); propNames.forEach(function(name) &#123; this.trigger(name); &#125;, this);&#125; argument函数会有一个argument属性对应于他的实参 callee和caller属性 callee 正在执行的函数 caller 调用它的函数 函数 prototype属性每个函数都有一个prototype属性，这个属性是一个对象的引用，每个函数都包含不同的原型对象 call方法和apply方法他可以用来绑定一个函数func到任意对象obj 12func.call(obj, args...)func.apply(obj, [args...]) bind它和apply和call的不同是，bind返回的是一个函数1var func2 = func.bind(obj, args) Function() 构造函数Function()创建的函数并不使用词法作用于，所以他作为嵌套函数的时候不能捕获上层函数的对象 不完全函数把一个函数调用拆成，若干个子调用f(1,2,3,4,5)=&gt;f(1,2)(3,4)(5) 类类包含一个构造函数，一个prototype，对于prototype相同的对象是属于一类的。 Javascript里面的类实际上感觉就是用对象构造对象，他没有其他OO中类的概念 构造函数中的属性是等同于static 而prototype的等同于方法/属性 构造函数并不是生成对象的主体，主体是prototype，构造函数只能作为类似静态方法的方式操作 TIP 使用分号 不区分整数和浮点 如果没使用var声明一个变量，那么他会默认变成全局的。 a = a || a.func() JSON.stringify and JSON.parse Javascript 相等运算符比较对象时，比较的是引用而不是值，可以用equals()来做完整比较 代码质量检查 jslint.com let 声明块级作用域的变量 const 声明常量 v &gt;1.8","tags":[{"name":"javascript","slug":"javascript","permalink":"http://matthewgao.github.io/tags/javascript/"}]},{"title":"Docker","date":"2016-07-12T14:38:39.000Z","path":"docker/","text":"Docker vs Vagrant为了解决固件编译环境的种种问题，我们尝试了使用vagrant来创建一个编译环境的镜像，但是vagrant基于VM的实现导致了对于宿主机的要求很高，同时编译多个release耗费相当多的系统资源，并且严重拖慢编译速度。 所以我考虑用Docker来替代vagrant，Docker提供了足够的隔离，所以可以像一个虚拟机一样运行，但是非常轻且高效，能满足所有编译环境的需求。 Build RBE Image1234# Build a docker image `mkdir docker-builder &amp;&amp; cd docker-builder` `rsync -av this_Dockerfile .` `docker build -t release_name .` Run It12345# Run this docker image `docker run -itd -v tip_on_host:tip_on_container /bin/bash`# Access to the console `docker attach &lt;CID or name&gt;` or `docker exec -it &lt;CID or name&gt;` Util12345# How to get the CID or name `docker ps`# List all the image which avaiable in your host `docker images` DockerfileFROM指定base image MAINTAINERAuthor信息 LABEL描述性的，不重要 RUN运行一些命令 CMD每个container时候启动的，只能有一个 ENV设置环境变量 Attach or Exec我们有两种方式来attach到container的TTY 12docker attach &lt;CID or name&gt;docker exec -it &lt;CID&gt; Attach会有个问题是如果从container中exit，那么container会被结束，而exec不会，但是exec每次执行会返回一个exit code，因为他是stdout到了stdin来得到tty结果的 配置文件/etc/default/docker管理docker所有启动的配置 1echo 'DOCKER_OPTS=\"-b=bridge0\"' &gt;&gt; /etc/default/docker 网络docker的网络依赖于一个linux网桥docker0， 所以你也可以使用自己建立的网桥来处理docker container之间的网络 存储docker支持建立数据容器，那么正常的容易可以通过--volume-from挂载数据容器","tags":[{"name":"docker","slug":"docker","permalink":"http://matthewgao.github.io/tags/docker/"}]},{"title":"Python Notes","date":"2016-06-07T08:21:48.000Z","path":"python-notes/","text":"Pypi镜像解决国内访问pypi速度慢的问题，注意要加上--trusted-host pypi.mirrors.ustc.edu.cn 因为有些不提供安全连接，或者证书不可信 1234http://pypi.douban.com/simple 豆瓣http://pypi.hustunique.com/simple 华中理工大学http://pypi.sdutlinux.org/simple 山东理工大学http://pypi.mirrors.ustc.edu.cn/simple 中国科学技术大学 1pip3.4 install -i http://pypi.mirrors.ustc.edu.cn/simple --trusted-host pypi.mirrors.ustc.edu.cn flask-restful 模块from import 如果module1中有变量X，module2用from来导入module1，则在赋值X的时候并不会改动module1中的X，而用import可以。 from会导致reload失效，因为from导入的模块拿的只是一个被reload的引用，必须在reload之后再执行一次from import 类 子类并不会自动调用父类的构造函数，需要显示的调用。 类的赋值操作并不会查询搜索树。 init 函数不支持重载，因为python支持可变参数 两个下划线开头的是伪私有类属性, 他会变成_ClassName__X 内建属性12345678__class__ # 返回类名__base__ # 父类__dict__ # 属性字典，dir()__slot__ # 禁止生成dict树__getattr__ # X.undefined__getattribute__ # X.any__contain__ # item in X__call__ # 可以直接这样使用 class_object_name() 委托1234567class Super: def delegate(self): self.action() #action需要被实现 class Provider(Super): def action(self): print('in provider.action') 函数闭包12345def func(): _x = \"attr\" def printf(): print(_x) return printf DecoratorSingleton12345678910def singleton(cls, *args, **kw): _instance = &#123;&#125; def wrapper(): if cls not in _instance: _instance[cls] = cls(*args, **kw) return _instance[cls] return wrapper @singleton class MyClass(gentoo.LXRPClientHandler): 缺点是MyClass实际上是一个函数（wrapper），所以不能直接通过MyClass取类中属性 且m = MyClass(); n = MyClass(); o = type(n)(); then m == n &amp;&amp; m != o &amp;&amp; n != o @staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样。 @classmethod也不需要self参数，但第一个参数需要是表示自身类的cls参数。 规范命名规则 Type Public Internal Modules lower_with_under _lower_with_under Packages lower_with_under Classes CapWords _CapWords Exceptions CapWords Functions lower_with_under() _lower_with_under() Global/Class Constants CAPS_WITH_UNDER _CAPS_WITH_UNDER Global/Class Variables lower_with_under _lower_with_under Instance Variables lower_with_under _lower_with_under (protected) or __lower_with_under (private) Method Names lower_with_under() _lower_with_under() (protected) or __lower_with_under() (private) Function/Method Parameters lower_with_under Local Variables lower_with_under single_trailing_underscore_ : used by convention to avoid conflicts with Python keyword, e.g. 1Tkinter.Toplevel(master, class_='ClassName') __double_leading_underscore : when naming a class attribute, invokes name mangling (inside class FooBar, boo becomes _FooBarboo). __double_leading_and_trailing_underscore__ : “magic” objects or attributes that live in user-controlled namespaces. E.g. init , import or file . Never invent such names; only use them as documented. _single_leading_underscore : weak “internal use” indicator. E.g. from M import * does not import objects whose name starts with an underscore. 编程规范 每行80字符，注释72字符 参数多的时候要换行，少数情况下要用\\ 使用 if not alist 检查是否为空，而不是用if len(alist) == 0 import顺序不要一行import多个包 Imports should be grouped in the following order: standard library imports related third party imports local application/library specific imports Wildcard imports ( from import * ) should be avoided 类设计如果在不确定函数或者属性是public还是non-public，尽量还是先声明为non-public，从non到public很容易，反过来则很难 Programming Recommendations1234567Yes:def f(x): return 2*xNo:f = lambda x: 2*x The first form means that the name of the resulting function object is specifically ‘f’ instead of the generic ‘‘. This is more useful for tracebacks and string representations in general. The use of the assignment statement eliminates the sole benefit a lambda expression can offer over an explicit def statement (i.e. that it can be embedded inside a larger expression) Use exception chaining appropriately. In Python 3, “raise X from Y” should be used to indicate explicit replacement without losing the original traceback. Derive exceptions from Exception rather than BaseException . Direct inheritance from BaseException is reserved for exceptions where catching them is almost always the wrong thing to do. Additionally, for all try/except clauses, limit the try clause to the absolute minimum amount of code necessary. Again, this avoids masking bugs. 12345678910111213141516Yes:try: value = collection[key]except KeyError: return key_not_found(key)else: return handle_value(value)No:try: # Too broad! return handle_value(collection[key])except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key) Object type comparisons should always use isinstance() instead of comparing types directly. 123Yes: if isinstance(obj, int):No: if type(obj) is type(1): For sequences, (strings, lists, tuples), use the fact that empty sequences are false. 12345Yes: if not seq: if seq:No: if len(seq) if not len(seq) Don’t compare boolean values to True or False using == . 123Yes: if greeting:No: if greeting == True:Worse: if greeting is True: Class 继承当一个类被设计为基类的时候，要考虑到那些方法是要被子类覆盖的，那些是给子类用的（subclass API），那些只是基类用的 公共属性，前面不应该有一个下划线 如果你的属性名与keyword或者其他什么的冲突，则可以考虑在尾部加一个下划线 对于简单的公共属性，直接用属性名访问，而不要像jave一样定义一些accessor/mutator methods，如果之后需要对于这个属性进行额外处理， 那么可以使用@property来强化这个属性（防止用property来计算复杂属性） 如果你的类可能被继承，则把那些不想被子类使用的属性和方法用两个下划线开头 super() 还是 BaseClass()12345678class Base: name = \"Base\" def __init__(self):pass class Sub(Base): def __init__(self): #Base.__init__(self) super().__init__() 这两种方法都可以用作调用父类初始化函数，但是super()更好，不会在菱形继承中导致一些重复初始化的问题 为了弄清它的原理，我们需要花点时间解释下Python是如何实现继承的。对于你定义的每一个类而已，Python会计算出一个所谓的方法解析顺序(MRO)列表。 这个MRO列表就是一个简单的所有基类的线性顺序表。例如： 123C.__mro__(&lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;,&lt;class '__main__.Base'&gt;, &lt;class 'object'&gt;) 为了实现继承，Python会在MRO列表上从左到右开始查找基类，直到找到第一个匹配这个属性的类为止。 而这个MRO列表的构造是通过一个C3线性化算法来实现的。 我们不去深究这个算法的数学原理，它实际上就是合并所有父类的MRO列表并遵循如下三条准则： 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 当你使用 super() 函数时，Python会在MRO列表上继续搜索下一个类。 只要每个重定义的方法统一使用 super() 并只调用它一次， 那么控制流最终会遍历完整个MRO列表，每个方法也只会被调用一次。 我们来看下super的实现，可以发现他在找这个列表里后一个class 123def super(cls, inst): mro = inst.__class__mro() return mro[mro.index(cls)+1] 123456789101112131415161718192021222324252627282930313233343536class Base: name = \"Base\" def __init__(self):passa = Base()print(a.name)a.name = \"Base c\"print(a.name)print(Base.name)print('--------')class Sub(Base): def __init__(self): Base.__init__(self) @property def name(self): print('property name') print(Base.name) Base.name = 'abc' print(super(Sub,self).name)b = Sub()b.nameprint(b.__dict__)print(Base.name)print('--------')class Sub2(Sub): def __init__(self): Base.__init__(self) print(super(Sub, self).name)c = Sub2()c.nameprint(c.__class__.mro()) 结果是：123456789101112131415BaseBase cBase--------property nameBaseabc&#123;&#125;abc--------abcproperty nameabcabc[&lt;class '__main__.Sub2'&gt;, &lt;class '__main__.Sub'&gt;, &lt;class '__main__.Base'&gt;, &lt;class 'object'&gt;] weakrefList和Dict不支持weakref，但是他们的子类可以 Unicode为了解决多国语言的问题，ASCII显然已经不适合，他是用一个字节代表一个字符，这远远不够世界各种语言使用，Unicode是一个更大的集合，他包含了ASCII，因此他是一个变长的编码方式我们有两种方式来声明一个str 12str = ‘abcd’ # 这是一个struni = u‘Hi \\u2119\\u2602’ # 这是一个unicode类型 unicode.encode(‘UTF-8’) -&gt; bytes bytes.decode(‘UTF-8’) -&gt; unicode 123u'abcd'.encode('ascii', 'replace') #不能被encode就会变成一个`?`u'abcd'.encode('ascii', 'xmlcharrefreplace') #produces an HTML/XML character entity referenceu'abcd'.encode('ascii', 'ignore') #ignore Python 2 will automatically decode the byte string to produce a second unicode string, then will complete the operation with the two unicode strings. So “str” in Python 2 is now called “bytes,” and “unicode” in Python 2 is now called “str”. This makes more sense than the Python 2 names, since Unicode is how you want all text stored, and byte strings are only for when you are dealing with bytes.[Pragmatic Unicode][http://nedbatchelder.com/text/unipain.html] 元类type是所有类的元类(metaclass) TIPinif elem in alist 用来检查元素是否在列表里，但是注意这里的elem必须是一个元素，不能是alist列表中的一个子集，他是不能够检查子集的。 yeildgenerator可以包含一个return语句，但是他会导致generator不再能返回任何结果，而且return不能有返回值，return 5会报一个syntax error _ 占位符可以像Haskell一样有个占位符_ 来表示不关心的内容 Flask获得message body123request.formrequest.jsonrequest.headers Functional programminggenerator expression and list comprehensions12345# Generator expression -- returns iteratorstripped_iter = (line.strip() for line in line_list)# List comprehension -- returns liststripped_list = [line.strip() for line in line_list] List comprehension 会一次性返回所有的值，而generator expression返回一个可迭代的对象，他不会一次性返回所有值，只会根据需要获取，适合处理无限长度的数据。 Passing values into a generatorIn Python 2.4 and earlier, generators only produced output. Once a generator’s code was invoked to create an iterator, there was no way to pass any new information into the function when its execution is resumed. You could hack together this ability by making the generator look at a global variable or by passing in some mutable object that callers then modify, but these approaches are messy.In Python 2.5 there’s a simple way to pass values into a generator. yield became an expression, returning a value that can be assigned to a variable or otherwise operated on: 1val = (yield i) I recommend that you always put parentheses around a yield expression when you’re doing something with the returned value, as in the above example. The parentheses aren’t always necessary, but it’s easier to always add them instead of having to remember when they’re needed. (PEP 342 explains the exact rules, which are that a yield-expression must always be parenthesized except when it occurs at the top-level expression on the right-hand side of an assignment. This means you can write val = yield i but have to use parentheses when there’s an operation, as in val = (yield i) + 12.) Values are sent into a generator by calling its send(value) method. This method resumes the generator’s code and the yield expression returns the specified value. If the regular next() method is called, the yield returns None. Here’s a simple counter that increments by 1 and allows changing the value of the internal counter. 123456789def counter (maximum): i = 0 while i &lt; maximum: val = (yield i) # If value provided, change counter if val is not None: i = val else: i += 1 And here’s an example of changing the counter: 123456789101112131415&gt;&gt;&gt;&gt;&gt;&gt; it = counter(10)&gt;&gt;&gt; print it.next()0&gt;&gt;&gt; print it.next()1&gt;&gt;&gt; print it.send(8)8&gt;&gt;&gt; print it.next()9&gt;&gt;&gt; print it.next()Traceback (most recent call last): File \"t.py\", line 15, in ? print it.next()StopIteration Because yield will often be returning None, you should always check for this case. Don’t just use its value in expressions unless you’re sure that the send() method will be the only method used to resume your generator function. In addition to send(), there are two other new methods on generators: throw(type, value=None, traceback=None) is used to raise an exception inside the generator; the exception is raised by the yield expression where the generator’s execution is paused. close() raises a GeneratorExit exception inside the generator to terminate the iteration. On receiving this exception, the generator’s code must either raise GeneratorExit or StopIteration; catching the exception and doing anything else is illegal and will trigger a RuntimeError. close() will also be called by Python’s garbage collector when the generator is garbage-collected. If you need to run cleanup code when a GeneratorExit occurs, I suggest using a try: … finally: suite instead of catching GeneratorExit. The cumulative effect of these changes is to turn generators from one-way producers of information into both producers and consumers. Generators also become coroutines, a more generalized form of subroutines. Subroutines are entered at one point and exited at another point (the top of the function, and a return statement), but coroutines can be entered, exited, and resumed at many different points (the yield statements). getattr getattr(object, name[, default])Return the value of the named attribute of object. name must be a string. If the string is the name of one of the object’s attributes, the result is the value of that attribute. For example, getattr(x, &#39;foobar&#39;) is equivalent to x.foobar. If the named attribute does not exist, default is returned if provided, otherwise AttributeError is raised. class type(object) class type(object) class type(name, bases, dict)With one argument, return the type of an object. The return value is a type object and generally the same object as returned by object.class. The isinstance() built-in function is recommended for testing the type of an object, because it takes subclasses into account. With three arguments, return a new type object. This is essentially a dynamic form of the class statement. The name string is the class name and becomes the name attribute; the bases tuple itemizes the base classes and becomes the bases attribute; and the dict dictionary is the namespace containing definitions for class body and becomes the dict attribute. For example, the following two statements create identical type objects: 12345&gt;&gt;&gt;&gt;&gt;&gt; class X:... a = 1...&gt;&gt;&gt; X = type('X', (object,), dict(a=1)) monkey patchmonkey patch指的是在运行时动态替换,一般是在startup的时候. 用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了. 之前做的一个游戏服务器,很多地方用的import json,后来发现ujson比自带json快了N倍,于是问题来了,难道几十个文件要一个个把import json改成import ujson as json吗? 其实只需要在进程startup的地方monkey patch就行了.是影响整个进程空间的. 同一进程空间中一个module只会被运行一次.12345678910import jsonimport ujsondef monkey_patch_json(): json.__name__ = 'ujson' json.dumps = ujson.dumps json.loads = ujson.loadsmonkey_patch_json()print 'main.py',json.__name__import sub sub.py12import jsonprint 'sub.py',json.__name__ with如下情况 with一旦结束，那么as后面的对象就会被清除，即便是赋值给了c.response，那只是一个引用，除非用deepcopy123456with urllib.request.urlopen(c.request, context=context) as response: c.response = response return c#print(c.response.read())#return c pdb可以通过代用set_trace()来设置一个断点，然后运行的时候就会自动进入pdb，然后就可以调试啦12345678910111213141516import inspectimport pdbclass a:passclass b(a): class c(a): def hell(self): print(inspect.getmodule(self)) def guess(self): self.hell() def __call__(self): cc = self.c() pdb.set_trace() cc.guess()cc() 函数式编程map从python3开始map变得lazy，如果你不主动调用next或者使用它 它是不会马上返回结果的，跟Haskell一样 12345678class Test： def __init__(self, string) print(string) x = map(Test, ['ggg','rrr']) //return only a map objectx.next()list(x)// will get a result. TIPOrderedDict.move_to_end(key, last=False)这种方式并不能用于排序，在把某个元素放到最后的同时也会改变其他元素的顺序 1234x=OrderedDict(&#123;'a':1,'b':2,'c':3&#125;)x.move_to_end('a')print(x)&gt;&gt;OrderedDict([('c', 3), ('b', 2), ('a', 1)]) raise new_exc from original_excWhen raising a new exception (rather than using a bare raise to re-raise the exception currently being handled), the implicit exception context can be supplemented with an explicit cause by using from with raise: Reference PEP 0008 – Style Guide for Python Code","tags":[{"name":"python","slug":"python","permalink":"http://matthewgao.github.io/tags/python/"}]},{"title":"Sublime Text & Plugin","date":"2016-04-18T15:10:33.000Z","path":"sublime-and-its-plugin/","text":"没记住的快捷键 Ctrl+G 跳转到相应的行 Ctrl+J 合并行（已选择需要合并的多行时） Ctrl+L 选择整行（按住-继续选择下行） Shift+鼠标右键（或使用鼠标中键）可以用鼠标进行竖向多行选择 Ctrl+Shift+L 鼠标选中多行（按下快捷键），即可同时编辑这些行 Ctrl+T 词互换 Ctrl+U 软撤销 Ctrl+Y 恢复撤销 Ctrl+K Backspace 从光标处删除至行首 Ctrl+Shift+K 删除整行 Ctrl+K+B 开启/关闭侧边栏 Ctrl+KK 从光标处删除至行尾 Ctrl+K+U 改为大写 Ctrl+K+L 改为小写 Ctrl+Tab 当前窗口中的标签页切换 Shift+F2 上一个书签 F2 下一个书签 Ctrl+F2 设置/取消书签 Ctrl+Shift+↑可以移动此行代码，与上行互换 Ctrl+Shift+↓可以移动此行代码，与下行互换 来写一个插件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import sublime, sublime_pluginimport datetimeclass FileHeaderCreatorCommand(sublime_plugin.TextCommand): def run(self, edit): # print(self.view.settings().get(\"author\")) if self.view.size() == 0: self.check_file_type(edit) def check_file_type(self, edit): file_path = self.view.file_name() pos = file_path.rfind('.') if pos == -1: return suffix = file_path[pos+1:] token = '/' if sublime.platform() == 'windows': token = '\\\\' file_name_pos = file_path.rfind(token) if file_name_pos == -1: return file_name = file_path[file_name_pos+1:] header = '' if suffix == 'py': header = self._python(file_name) elif suffix == 'cpp': header = self._cpp(file_name) elif suffix == 'h': header = self._h(file_name) elif suffix == 'hs': header = self._haskell(file_name) self.view.insert(edit, 0, header) def _h(self, name): author = self.view.settings().get(\"author\") if author is None: author = \"Anonymous\" company = self.view.settings().get(\"company\") if company is None: company = \"Anonymous\" string = \"/*\\n\" string += \" * \" + name + \"\\n\" string += \" * Created By: \" + author + \"\\n\" string += \" * \" + company + \"\\n\" string += \" * Created Time: \" + datetime.date.today().isoformat() + \"\\n\" string += \" */\\n\" string += \"#ifndef _\" + name.replace('.', '_').upper() + \"\\n\" string += \"#define _\" + name.replace('.', '_').upper() + \"\\n\\n\\n\" string += \"#endif\" return string def _python(self, name): author = self.view.settings().get(\"author\") if author is None: author = \"Anonymous\" string = \"#!/usr/bin/env python3\\n\" string += \"# coding=utf-8\\n\" string += \"# Created Time: \" + datetime.date.today().isoformat() + \"\\n\\n\" string += \"__author__ = \" + \"\\'\" + author + \"\\'\" return string def _cpp(self, name): author = self.view.settings().get(\"author\") if author is None: author = \"Anonymous\" company = self.view.settings().get(\"company\") if company is None: company = \"Anonymous\" string = \"/*\\n\" string += \" * \" + name + \"\\n\" string += \" * Created By: \" + author + \"\\n\" string += \" * \" + company + \"\\n\" string += \" * Created Time: \" + datetime.date.today().isoformat() + \"\\n\" string += \" */\\n\" return string def _haskell(self, name): passclass FileHeaderCreator(sublime_plugin.EventListener): def on_load(self, view): print(\"FileHeaderCreator on_load invoked\") view.run_command(\"file_header_creator\") def on_post_save(self, view): print(\"FileHeaderCreator on_post_save invoked\") view.run_command(\"file_header_creator\")","tags":[{"name":"editor","slug":"editor","permalink":"http://matthewgao.github.io/tags/editor/"},{"name":"sublime","slug":"sublime","permalink":"http://matthewgao.github.io/tags/sublime/"}]},{"title":"Makefile Notes","date":"2016-04-17T16:50:55.000Z","path":"2014-9-26-makefile/","text":"样板12345678910111213141516171819202122232425262728CC=g++ -g LPTHREAD= -lpthreadTARGET=mainOBJS=ThreadPool.o \\ main.oall : $(TARGET) echo \"ALL Done\"#$^ 会一次返回所有结果#$&lt; 一次返回一个结果$(TARGET) : $(OBJS) $(CC) $(LPTHREAD) -o $@ $^%.o : %.cpp $(CC) -c $&lt; -o $@#这部分可以保证对头文件的依赖性，不然会导致头文件更新，对应的#cpp没有被更新的情况%.dep : %.cpp $(CC) -M $&lt; &gt; $@ $(BOOST_LIB)include $(OBJS:.o=.dep)include $(TEST_OBJS:.o=.dep) clean: rm -f *.o main echo \"Remove Done\" 在make中有四种方式对变量赋值：:=运算符如MAKE_DEPEND := $(CC) -M 这种方式叫做“简单展开”，因为在读到makefile中的这一行时等号右边就立即被展开了， 等号右边引用的所有变量（如例子中的CC）也会被立即展开。其行为与一般编程和脚本语言相同。当等号右边引用的变量（如例子中的CC）还没有被定义时，它被展开成空（nothing）而不是空格之类。 =运算符如MAKE_DEPEND = $(CC) -M 这种方式叫做“递归展开”，直到该变量被使用时等号右边的内容才会被展开，其实叫做“迟滞展开”更合适。神奇的是，这种展开方式可以不按顺序定义变量。比如： 1234MAKE_DEPEND = $(CC) -M...# Some time laterCC = gcc 只要在此之前没有引用过MAKE_DEPEND就没问题。另外，不止是“迟滞展开”，事实上每次使用该变量，等号右边的内容都会被重新展开。 ?=运算符如OUTPUT_DIR ?= $(PROJECT_DIR)/out 这种方式叫“条件展开”，只有当OUTPUT_DIR 还没有被定义过时才进行赋值，否则什么都不做。这种方式在处理环境变量是特别有用。 +=运算符如OUTPUT_DIR += $(PROJECT_DIR)/out “追加”方式。 其主要目的是给“递归展开”的变量追加内容。因为简单变量可以用simple := $(simple) new stuff的方式来追加内容；而对于递归展开的变量，recursive = $(recursive) new stuff会导致循环引用。这种情况只能用+=运算符。 Pattern模式模式中的%大体上等效于shell中的*星号，他可以代表任意多个字符，不过模式中只能出现一次。 $$Because dollar signs are used to start make variable references, if you really want a dollar sign in a target or prerequisite you must write two of them, ‘$$’ (see How to Use Variables). If you have enabled secondary expansion (see Secondary Expansion) and you want a literal dollar sign in the prerequisites list, you must actually write four dollar signs (‘$$$$’). define还有一种设置变量值的方法是使用define关键字。使用define关键字设置变量的值可以有换行，这有利于定义一系列的命令（前面我们讲过“命令包”的技术就是利用这个关键字）。 define指示符后面跟的是变量的名字，而重起一行定义变量的值，定义是以endef关键字结束。其工作方式和“=”操作符一样。变量的值可以包含函数、命令、文字，或是其它变量。因为命令需要以[Tab]键开头，所以如果你用define定义的命令变量中没有以[Tab]键开头，那么make就不会把其认为是命令。 下面的这个示例展示了define的用法： 1234define two-linesecho fooecho $(bar)endef origin functionThe origin function is unlike most other functions in that it does not operate on the values of variables; it tells you something about a variable. Specifically, it tells you where it came from. The syntax of the origin function is: $(origin variable)Note that variable is the name of a variable to inquire about, not a reference to that variable. Therefore you would not normally use a ‘$’ or parentheses when writing it. (You can, however, use a variable reference in the name if you want the name not to be a constant.) The result of this function is a string telling you how the variable variable was defined: ‘undefined’if variable was never defined. ‘default’if variable has a default definition, as is usual with CC and so on. See Variables Used by Implicit Rules. Note that if you have redefined a default variable, the origin function will return the origin of the later definition. ‘environment’if variable was inherited from the environment provided to make. ‘environment override’if variable was inherited from the environment provided to make, and is overriding a setting for variable in the makefile as a result of the ‘-e’ option (see Summary of Options). ‘file’if variable was defined in a makefile. ‘command line’if variable was defined on the command line. ‘override’if variable was defined with an override directive in a makefile (see The override Directive). ‘automatic’if variable is an automatic variable defined for the execution of the recipe for each rule (see Automatic Variables).","tags":[{"name":"makefile","slug":"makefile","permalink":"http://matthewgao.github.io/tags/makefile/"}]},{"title":"NodeJS","date":"2015-12-08T06:29:50.000Z","path":"NodeJS/","text":"Unit testmocha describe可以嵌套 it不能嵌套 时序 describe里地it的非异步部分按它们定义的顺序执行，它们所触发的回调的注册顺序也遵从it的注册顺序 不被describe包裹的部分执行顺序的优先级最高 同一层次的describe执行顺序遵从它们的定义顺序 外层describe的所有it执行优先级高于嵌套的describe describe内所有函数全部是non-block的，所以不能再其中指望以顺序的方式传递变量什么的 处理异步单元测试尤其在需要发出请求，处理返回的时候，由于NodeJs是全异步的，所以describe不会捕捉到返回结果，所以需要在it的callback中给一个done，并在异步调用结束后调用done() 同时它的几个hook也接受使用done的异步调用。","tags":[{"name":"javascript","slug":"javascript","permalink":"http://matthewgao.github.io/tags/javascript/"}]},{"title":"A NodeJS Issue","date":"2015-12-06T07:39:28.000Z","path":"nodejs-promise-issue/","text":"描述 在《深入浅出NodeJS》一书中的第四章，给出了一个promise/deferred的一个简单实现，但是读来读去总觉得有些问题，所以拿来作者的代码做了个实验 [Code in Github][https://github.com/JacksonTian/diveintonode_examples/tree/master/04/promise_a] 实验代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122var util = require(\"util\");var http = require(\"http\");var EventEmitter = require('events').EventEmitter;var Deferred = function () &#123; this.state = 'unfulfilled'; this.promise = new Promise();&#125;;Deferred.prototype.resolve = function (obj) &#123; this.state = 'fulfilled'; this.promise.emit('success', obj); console.log(\"emit success\");&#125;;Deferred.prototype.reject = function (err) &#123; this.state = 'failed'; this.promise.emit('error', err); console.log(\"emit error\");&#125;;Deferred.prototype.progress = function (data) &#123; this.promise.emit('progress', data); console.log(\"emit progress\");&#125;;Deferred.prototype.all = function (promises) &#123; var count = promises.length; var that = this; promises.forEach(function (promise) &#123; promise.then(function () &#123; count--; if (count === 0) &#123; that.resolve(); &#125; &#125;, function () &#123; that.reject(); &#125;); &#125;); return this.promise;&#125;;var Promise = function () &#123; EventEmitter.call(this);&#125;;util.inherits(Promise, EventEmitter);Promise.prototype.then = function (fulfilledHandler, errorHandler, progressHandler) &#123; if (typeof fulfilledHandler === 'function') &#123; // 利用once方法，保证成功回调只执行一次 this.once('success', fulfilledHandler); console.log(\"register success\"); &#125; if (typeof errorHandler === 'function') &#123; // 利用once方法，保证异常回调只执行一次 this.once('error', errorHandler); console.log(\"register error\"); &#125; if (typeof progressHandler === 'function') &#123; this.on('progress', progressHandler); console.log(\"register progress\"); &#125; return this;&#125;;var client = function()&#123; var options = &#123; hostname:'103.249.252.29', port:80, path:'/', method: 'get' &#125;; var deferred = new Deferred(); var req = http.request(options, function(res)&#123; res.setEncoding('utf-8'); var data = ''; console.log(\"callback called\"); //必须consume这个data不然会一直保持下去，直到内存满了，所以可以晚点注册这个 //callback res.on('data', function(chunk)&#123; data += chunk; console.log(\"res.on('data')\"); deferred.progress(chunk); &#125;); res.on('end', function()&#123; console.log(\"res.on('end')\"); deferred.resolve(data); &#125;); &#125;); req.on('error', function(err)&#123; deferred.reject(err); &#125;) req.end(); console.log(\"request sended\"); return deferred.promise;&#125;var c = client();console.log(\"Going to call then1\");// c.then1(function(data)&#123;// // console.log('请求完成', data);// console.log('请求完成');// &#125;, function(err)&#123;// console.log('访问错误', err);// &#125;, function(chunk)&#123;// // console.log('正在读取', chunk);// console.log('正在读取');// &#125;);setTimeout(function()&#123; c.then(function(data)&#123; //console.log('请求完成', data); console.log('请求完成'); &#125;, function(err)&#123; console.log('访问错误', err); &#125;, function(chunk)&#123; //console.log('正在读取', chunk); console.log('正在读取'); &#125;);&#125;, 10); 如果我们在最后setTimeout中设置10ms之后执行，那么then函数注册的三个callback可以正常处理response，结果如下 123456789101112131415161718request sendedGoing to call then1register successregister errorregister progresscallback calledres.on('data')正在读取emit progressres.on('data')正在读取emit progressres.on('data')正在读取emit progressres.on('end')请求完成emit success 可以看出register callback发生在emit之前，这大概是网络IO速度比较慢造成的，那我们加大setTimeout延迟的时间到1000ms 1234567891011121314request sendedGoing to call then1callback calledres.on('data')emit progressres.on('data')emit progressres.on('data')emit progressres.on('end')emit successregister successregister errorregister progress 可以看到emit发生在register callback之前，所以then注册的callback并没有执行 结论 这实际上就是一个巧合，因为IO的低速导致了register callback之前，这种promise方式并不能保证then每次都能拿到结果","tags":[{"name":"node.js","slug":"node-js","permalink":"http://matthewgao.github.io/tags/node-js/"}]},{"title":"Multiple Thread & Thread Safety","date":"2015-09-22T13:59:58.000Z","path":"thread-safe/","text":"Multiple Threadpthread_mutex有两种方式创建一个mutex一种是静态方法，一种是动态方法，似乎静态方法不需要Destroy??? 123pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;pthread_mutex_t lock;pthread_mutex_init (&amp;lock, NULL); pthread_cancel1234int pthread_cancel(pthread_t thread);int pthread_setcancelstate(int state, int *oldstate);int pthread_setcanceltype(int type, int *oldtype);void pthread_testcancel(void); [Option End] cancel，用来取消一个线程，但是按照默认的配置他是不会立刻退出的，会在cancelpoint选择退出。取消点是在程序在运行的时候检测是否收到取消请求，是否允许允许操作执行的点。下面的POSIX线程函数就是取消点： 1234567pthread_join()pthread_cond_wait()pthread_cond_timedwait()pthread_testcancel()sem_wait()sigwait()... pthread_setcancelstate设置状态，有两种 PTHREAD_CANCEL_ENABLE （default） PTHREAD_CANCEL_DISABLEEnable表示线程支持cancel pthread_setcanceltype PTHREAD_CANCEL_DEFERRED： 默认值，他不会马上结束，会在下一个cancelpoint结束 PTHREAD_CANCEL_ASYNCHRONOUS： 马上结束 pthread_cleanup_push &amp; pthread_cleanup_pop12void pthread_cleanup_push(void (*routine)(void *), void *arg);void pthread_cleanup_pop(int execute); ##Thread Safety ###对象构造 不要在构造函数中注册毁掉 不要过早的把this传给其他线程的对象 两段式构造，是个有效的解决方案 ###对象析构尽管我们会用互斥量来保证线程安全，但是还是难免会碰到如下情况 1234567global shared_ptr&lt;Job&gt; ptr = make_shared&lt;Job&gt;()Thread Ashared_ptr&lt;Job&gt; p1(ptr)Thread Bptr is going out of scope 在这种情况下，直接使用互斥量就很难保证不会出问题，所以使用一个RAII构建的mutex是一个解决方法 1234MutexGuard lock(mtx)//operate the ptr....When it's going out of the scope, the lock object will continue to protect it until ptr destroyed 或者使用如下方法，p1和p2都是栈上对象，所以没有析构问题。 12345678910global shared_ptr&lt;Job&gt; ptr = make_shared&lt;Job&gt;()Thread Ashared_ptr&lt;Job&gt; p1(ptr)use p1 to operate object ptr pointed toThread Bshared_ptr&lt;Job&gt; p2(ptr)use p2 to operate object 另外一个解决方法是可以用另外一个线程专门管理这些对象的析构，相当于维护一个对象池 或者考虑使用atomic来保护对象 ###不要使用递归mutex ###每个对象保证自身的数据安全对于数据的访问给予互斥量保护，这个时候要留心析构的问题，因为内部互斥量无法保证析构，如果两个线程同时在做析构（在使用shared_ptr的时候），那么会有双重释放的问题，一个符合RAII标准的mutexlock能够派上用场，因为他可以保护析构，在析构结束前lock不会析构。 ###TCP作为进程间通信的方法TCP是一个相对普适的方法来处理进程间通信，他甚至可以扩展到主机间通信，所以是个非常好的选择","tags":[{"name":"c++","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"boost","slug":"boost","permalink":"http://matthewgao.github.io/tags/boost/"},{"name":"multi-thread","slug":"multi-thread","permalink":"http://matthewgao.github.io/tags/multi-thread/"}]},{"title":"Vim on OSX","date":"2015-08-24T02:58:41.000Z","path":"Vim-on-OSX/","text":"Quick Start已经实现了一个非常基本的自动化脚本，可以输入如下命令进行自动化安装，如果是OSX，需要提前安装brew： 1ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 之后运行：1wget -qO- https://raw.github.com/matthewgao/MyVim/master/setup.sh | sh 当所有安装完成，就得到了一个包含如下插件的Vim： Bundle FuzzyFinder L9 tagslist ctags NERDtree NERD-Commenter Auto-pair Ctrlp ctrlp-funky airline powerline translate vim chinese doc calendar molokai colorscheme 项目托管在github上 MyVim 自动安装包含如下过程： 检查系统，yum or apt-get or brew 安装组件 安装MyVim 复制vim到.vim 复制vimrc到.vimrc 安装Bundle 执行BundleInstall Powerline font12git clone https://github.com/powerline/fonts.gitfonts/install.sh ##安装中文Help doc 下载vimdoc包猛击下载，下载的 tar.gz 包括所有翻译过的 vim 文档 (.cnx 文件) 先将其解压缩： 1tar zxvf vimcdoc-&lt;version&gt;.tar.gz 然后进入 vimcdoc- 目录并执行 1./vimcdoc.sh -i 就可以了。该安装程序会自动识别 Vim 的安装路径，将中文的文档拷贝 到相应的地方。原有的英文文档不受影响。 插件简介NERDtree在nerdtree窗口常用操作：12345678910x.......Close the current nodes parent收起当前目录树R.......Recursively refresh the current root刷新根目录树r.......Recursively refresh the current directory刷新当前目录P.......Jump to the root nodep.......Jump to current nodes parentK.......Jump up inside directories at the current tree depth 到同目录第一个节点J.......Jump down inside directories at the current tree depth 最后一个节点o.......Open files, directories and bookmarksi.......Open selected file in a split window上下分屏s.......Open selected file in a new vsplit左右分屏 配置解析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697set nocompatible \" be iMprovedset shell=/bin/shset tabstop=4set softtabstop=4set shiftwidth=4\" FIXMEset expandtabset autoindentset nuset rulercolorscheme molokaiset showcmd\" 高亮搜索set hlsearch\" 跟随搜索set incsearchset mouse=aset linebreakset mousemodel=popupset autowriteset cmdheight=2\" 去掉输入错的提示音set noebset ignorecaseset wildmenu\"FIXME 允许backspace和光标跨越行边界set backspace=eol,start,indentset whichwrap+=&lt;,&gt;,h,lset linespace=0set wildmenuset completeopt=preview,menuset completeopt=longest,menu \"tab替换成空格if version&gt;=603 set helplang=cn set encoding=utf-8endiffiletype onfiletype plugin onfiletype plugin indent on \" required!syntax onsyntax enableset rtp+=~/.vim/bundle/vundle/call vundle#rc()\" let Vundle manage Vundle\" required! \"这是vundle本身的设置Bundle 'gmarik/vundle' \" My Bundles here: \"这里是设置你自己自定义的插件的设置vundle设置，注意：下载 \"的插件git为：https://github.com/godlygeek/tabular.git，则设置为Bundle \"'godlygeek/tabular';https://github.com/gmarik/vundle.git设置则为 \" Bundle 'gmarik/vundle' \" original repos on githubBundle 'godlygeek/tabular' \" vim-scripts repos，vim-scripts的访问地址，格式则如下：Bundle 'L9'Bundle 'FuzzyFinder' \" non github repos ，非git的访问地址的，格式如下：Bundle 'git://git.wincent.com/command-t.git'Bundle 'Auto-Pairs'Bundle 'The-NERD-Commenter'\"Bundle 'ctrlp.vim'Plugin 'ctrlp.vim'Plugin 'scrooloose/nerdtree'\"\" Brief help\" :BundleList - list configured bundles\" :BundleInstall(!) - install(update) bundles\" :BundleSearch(!) foo - search(or refresh cache first) for foo\" :BundleClean(!) - confirm(or auto-approve) removal of unused bundles\"\" see :h vundle for more details or wiki for FAQ\" NOTE: comments after Bundle command are not allowed..nmap tt :%s/\\t/ /g&lt;CR&gt;map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt;imap &lt;F3&gt; &lt;ESC&gt; :NERDTreeToggle&lt;CR&gt;map &lt;silent&gt; &lt;F9&gt; :TlistToggle &lt;CR&gt;let Tlist_Auto_Open=1let Tlist_Exit_OnlyWindow=1let Tlist_Use_Right_Window=1let NERDTreeIgnore=['\\.pyc']\" crtlp settingset wildignore+=*/tmp/*,*.so,*.swp,*.zip,*.pyc,*.png,*.jpg,*.gif \" Mac/Linux","tags":[{"name":"shell","slug":"shell","permalink":"http://matthewgao.github.io/tags/shell/"},{"name":"vim","slug":"vim","permalink":"http://matthewgao.github.io/tags/vim/"},{"name":"linux","slug":"linux","permalink":"http://matthewgao.github.io/tags/linux/"}]},{"title":"异步IO与协程框架","date":"2015-07-20T05:44:13.000Z","path":"coroutine/","text":"基于就绪通知的协程框架 首先需要包装read/write，在发生read的时候检查返回。如果是EAGAIN，那么将当前协程标记为阻塞在对应fd上，然后执行调度函数。 调度函数需要执行epoll(或者从上次的返回结果缓存中取数据，减少内核陷入次数)，从中读取一个就绪的fd。如果没有，上下文应当被阻塞到至少有一个fd就绪。 查找这个fd对应的协程上下文对象，并调度过去。 当某个协程被调度到时，他多半应当在调度器返回的路上——也就是read/write读不到数据的时候。因此应当再重试读取，失败的话返回1。 如果读取到数据了，直接返回。 这样，异步的数据读写动作，在我们的想像中就可以变为同步的。而我们知道同步模型会极大降低我们的编程负担。 异步IOLinux AIO Blocking Non-Blocking Synchronous Read/Write Read/Write(O_NONBLOCK) Asynchronous IO Multiplexing AIO 基本方法： 1234567int aio_read( struct aiocb *aiocbp );int aio_error( struct aiocb *aiocbp );ssize_t aio_return( struct aiocb *aiocbp );int aio_write( struct aiocb *aiocbp );int aio_suspend( const struct aiocb *const cblist[], int n, const struct timespec *timeout );int aio_cancel( int fd, struct aiocb *aiocbp );int lio_listio( int mode, struct aiocb *list[], int nent, struct sigevent *sig ); 保存上下文的块： 123456789101112struct aiocb &#123; int aio_fildes; // File Descriptor int aio_lio_opcode; // Valid only for lio_listio (r/w/nop) volatile void *aio_buf; // Data Buffer size_t aio_nbytes; // Number of Bytes in Data Buffer struct sigevent aio_sigevent; // Notification Structure /* Internal fields */ ...&#125;; LibeioLibevent","tags":[{"name":"async i/o","slug":"async-i-o","permalink":"http://matthewgao.github.io/tags/async-i-o/"},{"name":"networking","slug":"networking","permalink":"http://matthewgao.github.io/tags/networking/"}]},{"title":"HTTP Notes","date":"2015-07-13T07:18:09.000Z","path":"http-notes/","text":"Transfer-Encoding通常来说，HTTP 1.0 默认都不是持续连接，这使得判断HTTP包结束变得非常容易，只要连接关闭了，就可以作为结束的标志。但是这会带来很多额外的开销。所以HTTP 1.1把keep-alive作为了默认项，所以通常我们需要一个Content-Length来表示包的长度，以便于正确的判断包的边界，这样带来的问题是，如果一个文件非常大，那么只有能所有的文件都被下载完成才会开始显示给用户，这样延迟可能非常大，所以采用了另外一种办法Transfer-Encoding，与之相类似的还有Content-Encoding： Transfer-Encoding: 对于传输的定义，目前只有chunked一种类型，表示分块 Content-Encoding：对于内容的编码，比如压缩什么的 如果使用了chunked方式，那么HTTP报文要遵循如下规则： 在头部加入 Transfer-Encoding: chunked 之后，就代表这个报文采用了分块编码。 报文中的实体需要改为用一系列分块来传输。 每个分块包含十六进制的长度值和数据，长度值独占一行，长度不包括它结尾的 CRLF（\\r\\n），也不包括分块数据结尾的 CRLF 最后一个分块长度值必须为 0，对应的分块数据没有内容，表示实体结束。 例如： 123456789HTTP/1.1 200 OKServer: nginx/1.1.19Date: Mon, 13 Jul 2015 06:58:31 GMTTransfer-Encoding: chunkedConnection: keep-alive2f&#123;\"connectionId\": \"qwertyu23456\", \"version\": 2&#125;0 与之对应，如果采用Content-Encoding 12345678HTTP/1.1 200 OKServer: nginx/1.1.19Date: Mon, 13 Jul 2015 07:07:42 GMTContent-Type: vnd.collection+jsonContent-Length: 47Connection: keep-alive&#123;\"connectionId\": \"qwertyu23456\", \"version\": 2&#125; GET with body message通常来讲，GET方法的body是空的，但是这并不是一个强制标准，只是一个习惯的用法，有些语义下，一个带有Body的GET方法是符合情理的，但是可能所用的web框架不支持，甚至curl也不支持，所以要手写内容检查方法，比如： 123456def check_body(req): msg_body = req.json for itr in msg_body: if check(itr) == False: abort(404) return msg_body 这里要注意，GET with body 不能够留下任何状态，必须是等幂的，不然违背GET的原则 web.pyFastCGI/WSGI各个参数在web.ctx中的解释，我遇到的问题是关于homepath，如果在nginx的location中配置了/api/hello，而在webpy中配置了(&quot;/api/hello&quot;,&quot;hello&quot;)， 那么webpy中homepath会是/api/home 而path是\\，这显然会匹配失败，正确的做法是(&quot;&quot;,&quot;hello&quot;) environ a.k.a. env – a dictionary containing the standard WSGI environment variables home – the base path for the application, including any parts “consumed” by outer applications http://example.org/admin homedomain – ? (appears to be protocol + host) http://example.org homepath – The part of the path requested by the user which was trimmed off the current app. That is homepath + path = the path actually requested in HTTP by the user. E.g. /admin This seems to be derived during startup from the environment variable REAL_SCRIPT_NAME. It affects what web.url() will prepend to supplied urls. This in turn affects where web.seeother() will go, which might interact badly with your url rewriting scheme (e.g. mod_rewrite) host – the hostname (domain) and (if not default) the port requested by the user. E.g. example.org, example.org:8080 ip – the IP address of the user. E.g. xxx.xxx.xxx.xxx method – the HTTP method used. E.g. GET path – the path requested by the user, relative to the current application. If you are using subapplications, any part of the url matched by the outer application will be trimmed off. E.g. you have a main app in code.py, and a subapplication called admin.py. In code.py, you point /admin to admin.app. In admin.py, you point /stories to a class called stories. Within stories, web.ctx.path will be /stories, not /admin/stories. E.g. /articles/845 protocol – the protocol used. E.g. https query – an empty string if there are no query arguments otherwise a ? followed by the query string. E.g. ?fourlegs=good&amp;twolegs=bad fullpath a.k.a. path + query – the path requested including query arguments but not including homepath. E.g. /articles/845?fourlegs=good&amp;twolegs=bad 跨域 form是不受跨域影响的 xmlhttprequest受跨域影响，不过可以通过Access-Control-Allow-Origin来突破W3C document","tags":[{"name":"http","slug":"http","permalink":"http://matthewgao.github.io/tags/http/"}]},{"title":"VIM Command Notes","date":"2014-10-05T04:52:36.000Z","path":"2014-9-2-vim-command-note/","text":"生成tags在所在目录运行 1ctags -R 在vim中 1:set tags = /your/path/tags 生成cscope索引1cscope -Rbq 命令 :A 打开头文件 :E 浏览打开文件 :wqa :b(buffer) 浏览/切换缓冲区, 例如:b1 :cd 改变工作目录 :lcd 改变当前窗口工作目录 :pwd 显示当前工作目录 :He :He!上分屏 :Ve 横分屏 :Te tag explore :colorscheme test3 更改配色方案 快捷键 {c-f12}, {c-n} 自动补全 , ; 结合f{char}查找, 上一个, 下一个 g; 上一个修改过的地方 g, 下一个修改过的地方 {c-o},{c-i} 回到上一个地方, 下一个地方 {c-a}{num},{c-x}{num} 增加num, 减少num u undo {c-r} 重做 文件比较1vim -d file1 file2 d = diff 在你忘记用 root 方式打开文件时的文件保存1:w !sudo tee % 按时间回退文件123:earlier 1m \\\\会把文件回退到 1 分钟以前的状态。:later \\\\ 注意，你可以使用这个的命令进行相反的转换","tags":[{"name":"vim","slug":"vim","permalink":"http://matthewgao.github.io/tags/vim/"},{"name":"command","slug":"command","permalink":"http://matthewgao.github.io/tags/command/"}]},{"title":"Software Engineering","date":"2014-10-01T04:52:36.000Z","path":"2014-12-18-softwareengineering/","text":"原则 DRY原则- Don’t repeat yourself 总是使用get/set方法来读写对象的属性， 这将使未来增加功能更方便。 构建正交系统 编写shame代码，不会没有必要的向其他模块暴露任何事情，也不依赖于其他模块的实现。如果需要改变这个对象的状态，让这个对象替你去做。 避免使用全局变量，单例经常被用作全局变量 避免写相似的函数 原型 prototype与 曳光弹 类设计高扇入让大量的类使用某个给定的类 低扇出让一个类里少量的或者适中的使用其他的类，一般不要超过七个","tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://matthewgao.github.io/tags/软件工程/"}]},{"title":"Git Command Notes","date":"2014-09-02T04:52:36.000Z","path":"2014-9-2-git-note/","text":"基本概念Git 是一个分布式的版本管理工具，不同于perforce的是，他每个人都有一个完整的版本库，这种结构及其像bitcoin的原理。 工作区 Workplace即文件夹所在的位置 索引区 Index（stage）git add 提交到的区域，可以理解为缓存区 版本库 Repositorygit commit 提交到的区域，即为本地Repository。即.git文件夹 stash与perforce中shelve的概念非常相似 基本应用创建一个Repository1git init 添加文件到stage区1git add readme.md 提交到版本库1git commit -m “new file” 查看现有branch的状态1git status 查看工作区中文件和版本库中区别1git diff readme.md 查看commit历史记录123git loggit log --pretty=onelinegit log --graph --pretty=oneline --abbrev-commit \\\\显示分支图 退回上一个版本12git reset --hard HEAD^git reset --hard 3628164 上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 当你用$ git reset –hard HEAD^回退到“add distributed”版本时，再想恢复到“append GPL”，就必须找到“append GPL”的commit id。Git提供了一个命令git reflog用来记录你的每一次命令： 12345$ git reflogea34578 HEAD@&#123;0&#125;: reset: moving to HEAD^3628164 HEAD@&#123;1&#125;: commit: append GPLea34578 HEAD@&#123;2&#125;: commit: add distributedcb926e7 HEAD@&#123;3&#125;: commit (initial): wrote a readme file 丢弃工作区的修改1git checkout -- readme.md 注意：有无 “–” 是有区别的，没有表示切换branch 删除文件12git rm readme.mdgit commit -m \"remove file\" 分支管理git的分支与perforce的分支大不同，git的分支是基于类似于指针的方式来实现的，它是在创建不同的指针指向不同的commit版本 创建分支1git checkout -b dev 上面的命令建立了dev分支并切换到dev，等同于如下： 12git branch devgit checkout dev 切换分支1git checkout dev 查看分支1git branch 删除分支1git branch -d dev 合并分支12git checkou mastergit merge dev 如果有冲突，git会标示在有冲突的文件中，按照如下格式 123456Git tracks changes of files.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADCreating a new branch is quick &amp; simple.=======Creating a new branch is quick AND simple.&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature1 另外一种合并分支的方法是 1git merge --no-ff -m \"merge with no-ff\" dev 这种方法的不同是 合并会是一个新的commit， 而之前的只是简单的把master指向dev 远程管理查看远程库信息1git remote -v 推送分支12git push origin mastergit push origin dev 获得分支12git branch --set-upstream dev origin/dev \\\\第一次的时候需要关联本地和远程的分支git pull 在本地创建和远程分支对应的分支1git checkout -b branch-name origin/branch-name 标签添加标签在某个分支上执行 12git tag v1.0git tag v1.0 6224799 \\\\commit id 查看标签1git show v1.0 删除标签1git tag -d v0.1 reset 某个文件 首先查看该文件的历史版本信息：git log Default@2x.png 记录下需要恢复的commit版本号：如 9aa51d89799716aa68cff3f30c26f8815408e926 恢复该文件：git reset 9aa51d89799716aa68cff3f30c26f8815408e926 Default@2x.png 提交git:git commit -m “revert old file”","tags":[{"name":"git","slug":"git","permalink":"http://matthewgao.github.io/tags/git/"}]},{"title":"Splunk add-on 开发","date":"2014-09-01T04:52:36.000Z","path":"howtowritesplunkplugin/","text":"Splunk简介Splunk是一个广泛用于信息分析的一个软件，功能非常强大，并且提供了非常好的二次开发体验，总的来说Splunk支持两种二次开发，一种是关于统计分析内容的，splunk提供多种多样的数据可视化的功能，开发人员只要简单的编写符合splunk标准的xml文件或者Django的文件就可以轻松实现多种多样的数据分析和显示；另外一种是关于数据导入的，虽然splunk提供了众多的导入方式，但是并不是所有的都能覆盖到，所以用户可以根据自己的数据结构来开发plugin，来导入特定的信息类型，比如IPFIX。本文就简述如何开发一个splunk plugin。 Splunk SDKSplunk 提供了多种语言的SDK，本文我们以Python为例，猛击这里下载Python SDK 建立自己的splunk pluginSplunk SDK 提供三种主要的功能 设置plugin需要接受的参数, 这部分参数会在你配置你的plugin的时候在splunk页面上显示出来 验证参数, 确保你设置的参数有效. 发送数据流. 下面是一个plugin的框架, 你必须继承于splunk提供的Script类, 并且实现三个函数: get_scheme, validate_input, stream_events 12345678910111213141516171819import sysfrom splunklib.modularinput import *class MyScript(Script): def get_scheme(self): # Returns scheme. def validate_input(self, validation_definition): # Validates input. def stream_events(self, inputs, ew): # Splunk Enterprise calls the modular input, # streams XML describing the inputs to stdin, # and waits for XML on stdout describing events.if __name__ == \"__main__\": sys.exit(MyScript().run(sys.argv)) 好, 这就是最基本的plugin的框架, 下面我们来具体实现它, 我们将建立一个plugin来监听UDP端口, 来转发到Splunk server, 你可能要说Splunk不是已经提供了一个UDP类型的输入么, 当然, 我们这里只是以此为例, 因为很多UDP的数据都是自定义的, 所以Splunk自带的UDP未必能够满足你的需求, 所以还是可能需要自己开发. UDP receiver例子我把各个部分的解释放到了注释中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105class UDPreceiver(Script): def get_scheme(self): \"\"\" 这里我们声明了 Scheme, 叫做UDP receiver. 然后use_external_validation = true 表示我们要用自己写的函数来验证这个receiver的参数 use_single_instance 表示如果只想启用一个plugin的实例, 则设为true, 不然设置为false. 接下来Argument(\"port\"), 声明了一个输入参数叫做port required_on_create = True 设置这个参数是必须的。 \"\"\" scheme = Scheme(\"UDP receiver\") scheme.description = \"UDP receiver\" scheme.use_external_validation = True #if con-current start the input modular set it False scheme.use_single_instance = False port_argument = Argument(\"port\") port_argument.data_type = Argument.data_type_number port_argument.description = \"Listen Port\" port_argument.required_on_create = True scheme.add_argument(port_argument) return scheme def validate_input(self, validation_definition): \"\"\" 这里我们要验证我们的参数。 通过\"port\"这个key我们找到要验证的参数, 如果没有则调用raise ValueError(\"Port is not a integer\"), 这样会在splunk web上弹出错误提醒. 接下来我们在验证端口是否在范围内, 是否被占用. \"\"\" try: port = int(validation_definition.parameters[\"port\"]) except Exception as e: raise ValueError(\"Port is not a integer\") if(port&lt;0 or port&gt;65535): raise ValueError(\"Port range exceeded\") try: sk = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) sk.settimeout(2) sk.bind(('', port)) sk.close() except socket.error, e: sk.close() if e.errno == 98 or e.errno == 13: raise ValueError(\"This port is already in use\") def stream_events(self, inputs, ew): \"\"\" 这里就是我们建立一个UDP socket监听端口的地方 \"\"\" host ='' port =0 for input_name, input_item in inputs.inputs.iteritems(): port = int(input_item[\"port\"]) ew.log(EventWriter.INFO,\"IPFIX converter init\") #checkForRunningProcess(port) #writePidFile(port) #ew.log(EventWriter.INFO,\"Start to listen port \"+str(port)) #ew.log(EventWriter.INFO,port) try: s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) s.bind((host, port)) except Exception as e: ew.log(EventWriter.ERROR,str(sys._getframe().f_code.co_name)+\":Failed When Establish Connection:\"+str(e)) while True: try: message, address = s.recvfrom(16384) except Exception as e: ew.log(EventWriter.ERROR,str(sys._getframe().f_code.co_name)+\"=\"+str(e)) \"\"\" Event() 是Splunk一条数据的一个对象, 里面可以设置多种信息, 包括data, stanza, time, host等等 最主要的还是data信息 最后调用ew.write_event()来发送这条数据 \"\"\" try: event1 = Event() event1.data = str(message) event1.stanza = str(address) event1.time = time.strftime(\"%Y-%m-%d %H:%M:%S\") event1.host = str(address[0]) event1.sourcetype = \"UDP packets\" #event1.index=None #event1.done=None #event1.unbroken=None ew.write_event(event1) except Exception as e: f = sys.exc_info()[2].tb_frame.f_back ew.log(EventWriter.ERROR,str(f.f_code.co_name)+\" at line \"+str(f.f_lineno)+\", failure reason:\"+ str(e)) s.close()if __name__ == \"__main__\": sys.exit(UDPreceiver().run(sys.argv)) stream_events方法中包含两个参数，一个是input，一个是ew， 从input中可以获取我们设置的参数，ew是eventWriter，是splunk sdk内置的一个类，用来发送数据，同时也具备log功能。 添加logSplunk具有log的功能，在sdk也提供了写入系统log的功能，我们可以通过这样的语句来发送一个log ew.log(EventWriter.ERROR,&quot;OUTPUT STRING:&quot;+str(outstr)) 除了ERROR我们还有几种log level ERROR WARNING INFO DEBUG 现在的DEBUG level的log似乎会有问题，不知道原因，所以慎用。log最终被写入splunkd.log文件中，实际上splunk sdk的log是对标准输出和标准错误输出进行了重新定向。 生成安装包在生成之前先建立自己的目录结构 12345678910$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/ bin/ app_name.py splunklib/ __init__.py ... default/ app.conf README/ inputs.conf.spec 需要把splunklib目录拷贝到$SPLUNK_HOME/etc/apps/&lt;app_name&gt;/bin, 然后根据需要建立app.conf和inputs.conf.spec. Splunk的安装包是spl格式，但实际上就是个tar.gz格式，所以可以直接打包目录： 1234cd $SPLUNK_HOME/etc/appstar cv MyApp/ &gt; MyApp.targzip MyApp.tarmv MyApp.tar.gz MyApp.spl 之后我们就可以在splunk上直接安装啦。 参考文档 Package your app or add-on How to create modular inputs 联系方式Matthew Gao, matthewgao[at]gmail.com","tags":[{"name":"splunk","slug":"splunk","permalink":"http://matthewgao.github.io/tags/splunk/"},{"name":"python","slug":"python","permalink":"http://matthewgao.github.io/tags/python/"},{"name":"add-on","slug":"add-on","permalink":"http://matthewgao.github.io/tags/add-on/"}]},{"title":"Include和Static Link的区别和联系","date":"2014-07-09T04:52:36.000Z","path":"2014-7-9-staticlinkandinclude/","text":"include简介最简单的对于include的理解可以这样理解，实际上他就是把多个文件组成一个文件，编译的时候include的所有的文件都会包含到C/CPP文件中，这里涉及到一个重复定义的问题#ifndef来解决这个问题，大家应该都会使用。 静态链接简介静态链接是把多个目标文件链接成一个可执行文件，这些链接过程在编译时候就完成的就是静态链接。下面我们来举例说明静态链接和include的区别。 比较 Case1我们现在定义三个文件a.h/c main.ca.h: 1void funca(); a.c: 12345#include &lt;stdio.h&gt;#include \"a.h\"void funca()&#123; printf(\"Hello\\n\");&#125; main.c: 1234int main()&#123; funca(); return 0;&#125; 下面我们编译一下生成目标文件 12gcc -c a.cgcc -c main.c 然后我们用objdump来查看下目标文件 1objdump -t a.o 可以得到如下结果 1234567891011SYMBOL TABLE:0000000000000000 l df *ABS* 0000000000000000 a.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .rodata 0000000000000000 .rodata0000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000000 g F .text 0000000000000010 funca0000000000000000 *UND* 0000000000000000 puts 我们可以看到我们自己定义的函数funca在查看下main.o 12345678910SYMBOL TABLE:0000000000000000 l df *ABS* 0000000000000000 main.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000000 g F .text 0000000000000015 main0000000000000000 *UND* 0000000000000000 funca main中有一个未定义的函数funca，虽然main.c这里并没有include “a.h” 但是这并不影响最后的连接 我们可以得到一个最终正确的应用程序。 比较 Case2修改main.c 12345#include \"a.c\"int main()&#123; funca(); return 0;&#125; 在编译之后我们查看目标文件main.o，得到如下结果： 12345678910110000000000000000 l df *ABS* 0000000000000000 main.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .rodata 0000000000000000 .rodata0000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000000 g F .text 0000000000000010 funca0000000000000000 *UND* 0000000000000000 puts0000000000000010 g F .text 0000000000000015 main 可见a.c被简单的直接加入到了main.c中，所以这里的funca 不是一个UND函数（UND 意为 undefined，是找不到这个函数的定义，需要从其他目标文件中寻找）。如果直接gcc -o main main.o是可以直接得到一个正确的可执行文件的。 比较 Case3把a.h/c中的funca改为static，这样理论上这个函数是不能被其他文件所使用的 12345#include &lt;stdio.h&gt;#include \"a.h\"static void funca()&#123; printf(\"Hello\\n\");&#125; 再重新编译获得main的目标文件，并查看： 123456789101112SYMBOL TABLE:0000000000000000 l df *ABS* 0000000000000000 main.c0000000000000000 l d .text 0000000000000000 .text0000000000000000 l d .data 0000000000000000 .data0000000000000000 l d .bss 0000000000000000 .bss0000000000000000 l d .rodata 0000000000000000 .rodata0000000000000000 l F .text 0000000000000010 funca0000000000000000 l d .note.GNU-stack 0000000000000000 .note.GNU-stack0000000000000000 l d .eh_frame 0000000000000000 .eh_frame0000000000000000 l d .comment 0000000000000000 .comment0000000000000000 *UND* 0000000000000000 puts0000000000000010 g F .text 0000000000000015 main 可见我们依然可以正确的得到funca的定义。 总结 1.正常函数的声明，默认就为extern 2.static只是针对不同模块间链接的时候有效，并不是以前经常所说的其他文件中，应该叫其他目标文件中。 3.实际上#include和静态链接两者是互通的，或者说作用及其相似，至少以我现在的经验来看，而且他们生成的最终文件大小是相同的。大概静态链接的方法更适合代码的管理吧。 4.所有未被定义的函数和变量在编译时都会被标记为UND，在之后的连接过程中来进行连接，#include和gcc时候用-I folder/header 似乎是有同样的效果的，另外前置声明也可以达到同样效果 5.-L 告诉编译器动态库位置","tags":[{"name":"c","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"static link","slug":"static-link","permalink":"http://matthewgao.github.io/tags/static-link/"}]},{"title":"IPFIX 原理以及实现","date":"2013-11-07T04:52:36.000Z","path":"2013-11-7-ipfix/","text":"简介Internet Protocol Flow Information Export (IPFIX)是一个IETF标准协议，他是用来标准化输出IP流的一个格式，可以用在网络监控，审计，管理等多个方面，方便的分析网络上数据流的情况，它在设置QoS 策略、部署应用和进行容量规划上都有着巨大的价值。他定义了一个标准的传输格式，IPFIX的格式是以思科的NetFlow v9为基础的，可以使IP流从一个exporter传输到collector上去。 术语 IE: Information Element Template &amp; TemplateID (To Be Continue)","tags":[{"name":"ipfix","slug":"ipfix","permalink":"http://matthewgao.github.io/tags/ipfix/"}]},{"title":"UDP 多种使用方法","date":"2013-05-20T04:52:36.000Z","path":"2013-5-20-UDP/","text":"创建UDP客户端的典型过程为：首先调用socket()函数，接下来定义发送和接收数据的远程主机和端口，然后用sendto()和recvfrom()来发送接收数据，如果使用sendto()和recvfrom()函数则可以在发送数据时再指定目标地址及端口。 除此之外UDP数据报的发送也可以使用write()、send()函数。如果使用write()或send()，则必须事先以UDP套接字为参数调用connect()函数。 与TCP不同的是，在UDP套接字上收发的数据是作为单独的单元接收或发送的，而不是作为字节流。每次调用write()、send()、或sendto()函数都会在线路上产生一个UDP数据报。接收到的UDP数据报的读取也是一个单独的操作，如果读取报文时提供的缓冲区长度不够，则会返回一个出错代码。 例如： 123456789101112131415161718sockaddr_in serv_addr;// create udp socketm_sock = socket(AF_INET, SOCK_DGRAM, 0);if (m_sock &lt; 0)&#123; return false;&#125;memset(&amp;serv_addr, 0, sizeof(struct sockaddr_in));serv_addr.sin_family = AF_INET;serv_addr.sin_addr.s_addr = inet_addr(m_serv_addr);serv_addr.sin_port = htons(m_serv_port);if (connect(m_sock, (struct sockaddr *)&amp;serv_addr, sizeof(serv_addr))&lt;0) &#123; fprintf(stderr,\"connect fail.\\n\"); return false;&#125;char buf[]=\"abcdefg\";send(m_sock,(void*)buf,sizeof(buf),0); 或者我们可以用sendto 1234567891011121314sockaddr_in serv_addr;// create udp socketm_sock = socket(AF_INET, SOCK_DGRAM, 0);if (m_sock &lt; 0)&#123; return false;&#125;memset(&amp;serv_addr, 0, sizeof(struct sockaddr_in));serv_addr.sin_family = AF_INET;serv_addr.sin_addr.s_addr = inet_addr(m_serv_addr);serv_addr.sin_port = htons(m_serv_port);char buf[]=\"abcdefg\";sendto(m_sock,(void*)buf,sizeof(buf),0,(struct sockaddr *)&amp;serv_addr,sizeof(serv_addr));","tags":[{"name":"socket","slug":"socket","permalink":"http://matthewgao.github.io/tags/socket/"},{"name":"udp","slug":"udp","permalink":"http://matthewgao.github.io/tags/udp/"},{"name":"c","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"}]},{"title":"free/delete 怎么知道有多少内存要释放","date":"2013-05-20T04:52:36.000Z","path":"2013-5-20-aboutfree/","text":"在使用c或者c++的时候我们经常用到malloc/free和new/delete，在使用malloc申请内存的时候我们给定了需要申请的内存大小，但是在free或者delete的时候并不需要提供这个大小，那么程序是怎么实现准确无误的释放内存的呢？ 实际上，在申请内存的时候，申请到的地址会比你实际的地址大一点点，他包含了一个存有申请空间大小的结构体。 比如你申请了20byte的空间，实际上系统申请了48bytes的block 16-byte header containing size, special marker, checksum, pointers to next/previous block and so on. 32 bytes data area (your 20 bytes padded out to a multiple of 16)) 这样在free的时候就不需要提供任何其他的信息，可以正确的释放内存 这里有个在stackoverflow.com上的提问，可以参考 http://stackoverflow.com/questions/1518711/c-programming-how-does-free-know-how-much-to-free","tags":[{"name":"c","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"c++","slug":"c","permalink":"http://matthewgao.github.io/tags/c/"},{"name":"free","slug":"free","permalink":"http://matthewgao.github.io/tags/free/"}]},{"title":"主流数字图像信息隐藏软件的使用方法","date":"2013-05-15T04:52:36.000Z","path":"2013-5-15-info-hiding/","text":"硕士期间做过隐写分析，在生成训练图片时候费了很大周折去找F5，Outguess，MB，Jsteg等软件的程序，网上又没有很明确的说明，所以只能自己逐渐摸索，为了给后人铺路，这里我做一总结。空域的LSB方法就不说了，这个自己用Matlab编起来也不是很麻烦，这里就说说变换域的： F5F5是Westfeld 2001年提出来的一个嵌入算法，本来在他个人的主页中是可以下载的，但是后来由于学校网页的变动，下载不到了，我前几天给westfeld发了邮件，他又重新把它放到网上了 Download F5 Download F5 in github 这还有一个在google code上的 Download F5 in google code 他们其实是一样的 这个是一个Java写的程序，有兴趣的人可以去看一下他的源代码，其实并不是非常复杂，他没有提供更改嵌入率的参数，这个问题我也问过westfeld本人，他的确没写这块，可以改写下Java程序，根据其capacity来控制嵌入文本的长度以实现。 OutguessOutguess就非常恶心了，他是unix下的程序，所以你要到linux里去跑，还好有ubuntu，ubuntu的软件库里已经有了这个软件，可以ubuntu的新立得软件中心去搜索outguess，安装就可以了，他同样不能更改嵌入率，所以采用的方法和F5一样，根据其容量来控制嵌入文本的长度，在outguess.c的文件中，有一个mmap_file函数，这个函数便是打开文本的，在里面你可以把fs.st_size赋值为bitmap-&gt;bits/16，然后通过乘上一个ratio来实现 MBMB1和MB2就非常善良了，有他的Matlab程序，这个就不用多说了，你只要改就可以了 Download MB RS分析自己写过一个RS分析的Matlab程序，可以方便的画出RS分析的特性曲线，我把他放在了github上，有兴趣的同学可以下载使用： Download RS","tags":[{"name":"隐写","slug":"隐写","permalink":"http://matthewgao.github.io/tags/隐写/"},{"name":"隐写分析","slug":"隐写分析","permalink":"http://matthewgao.github.io/tags/隐写分析/"},{"name":"F5","slug":"F5","permalink":"http://matthewgao.github.io/tags/F5/"},{"name":"outguess","slug":"outguess","permalink":"http://matthewgao.github.io/tags/outguess/"},{"name":"MB","slug":"MB","permalink":"http://matthewgao.github.io/tags/MB/"}]},{"title":"用APR解析XML文件","date":"2013-05-15T04:52:36.000Z","path":"2013-5-15-Use-APR-parse-XML/","text":"Apache portable runtime（APR）Apache server中一个非常关键的部分，他剥离了Apache server对于OS的依赖，使得它更容易在不同系统中迁移，另外他实现了垃圾的自动回收，解决了C/C++程序编写中非常头疼的问题。 这个APR中自带了大量的库文件，XML Parser便是其中一个。 定义使用XMLParser需要引用apr_xml.h头文件，文件中定义了基本数据类型，和部分函数。主要的有： apr_xml_attr apr_xml_elem apr_text_header apr_text apr_xml_doc 他们的定义如下，看清楚这些结构体有助于更好的使用它： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253typedef struct apr_text apr_text;struct apr_text &#123; const char *text; struct apr_text *next;&#125;;typedef struct apr_text_header apr_text_header;struct apr_text_header &#123; apr_text *first; apr_text *last;&#125;;typedef struct apr_xml_attr apr_xml_attr;typedef struct apr_xml_elem apr_xml_elem;typedef struct apr_xml_doc apr_xml_doc;struct apr_xml_attr &#123; const char *name; int ns; const char *value; struct apr_xml_attr *next;&#125;;struct apr_xml_elem &#123; const char *name; int ns; const char *lang; apr_text_header first_cdata; apr_text_header following_cdata; struct apr_xml_elem *parent; struct apr_xml_elem *next; struct apr_xml_elem *first_child; struct apr_xml_attr *attr; /* used only during parsing */ struct apr_xml_elem *last_child; struct apr_xml_ns_scope *ns_scope; /* used by modules during request processing */ void *priv;&#125;;#define APR_XML_ELEM_IS_EMPTY(e) ((e)-&gt;first_child == NULL &amp;&amp; \\ (e)-&gt;first_cdata.first == NULL)struct apr_xml_doc &#123; apr_xml_elem *root; apr_array_header_t *namespaces;&#125;; 所有关于xml的数据都存储在apr_xml_doc中，这里记录了他的子节点，父节点，每个节点的名称，属性和cdata（也就是value），很好的处理好这个结构体，就可以轻松的得到所有你想要的内容。 怎么使用对于解析SOAP非常简单，只需调用ap_xml_parse_input()就可以将request的内容解析为apr_xml_doc格式，下面是一个实例程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;ctype.h&gt;#include \"httpd.h\"#include \"http_config.h\"#include \"http_protocol.h\"#include \"ap_config.h\"#include &lt;apr_xml.h&gt; #define apr_isspace(c) (isspace(((unsigned char)(c))))//if you using g++ to compile the module, extern should be critical.extern module AP_MODULE_DECLARE_DATA soap_module;extern \"C\" int ap_xml_parse_input (request_rec * r,apr_xml_doc ** pdoc);const char * soap_xml_get_cdata(const apr_xml_elem *elem, apr_pool_t *pool, int strip_white);/* The sample content handler */void dump_xml(request_rec *r, apr_xml_elem *root)&#123; if(root==NULL) return; if(root-&gt;name!=NULL) ap_rprintf(r,\" Name:%s \\n\", root-&gt;name); if(root-&gt;lang!=NULL) ap_rprintf(r,\" lang:%s \\n\", root-&gt;lang ); if(root-&gt;attr!=NULL) ap_rprintf(r,\" Attr: %s:%s \\n\", root-&gt;attr-&gt;name,root-&gt;attr-&gt;value ); if(root-&gt;first_cdata.first!=NULL)&#123; apr_text *itr=root-&gt;first_cdata.first; for(;itr!=NULL;itr=itr-&gt;next) ap_rprintf(r,\" cdata:%s \\n\", itr-&gt;text); &#125; if(root-&gt;following_cdata.first!=NULL)&#123; apr_text *itr=root-&gt;following_cdata.first; for(;itr!=NULL;itr=itr-&gt;next) ap_rprintf(r,\" following_cdata:%s \\n\", itr-&gt;text); &#125; /* const char * buf=soap_xml_get_cdata(root, r-&gt;pool,1); if(buf==NULL) ap_rprintf(r,\"Buf is NULL\"); else ap_rprintf(r,\" Value: %s \\n\", buf ); */ dump_xml(r,root-&gt;first_child); dump_xml(r,root-&gt;next); //dump_xml(r,root-&gt;parent); &#125;static int mod_soap_handler(request_rec *r)&#123; int result; if (strcmp(r-&gt;handler, \"mod_soap\")) &#123; return DECLINED; &#125; r-&gt;content_type = \"text/html\"; apr_xml_doc *doc = NULL; if ((result = ap_xml_parse_input(r, &amp;doc)) != 0) &#123; ap_rputs(\"parse the xml fail\\n\", r); &#125; if(doc==NULL) &#123; ap_rprintf(r,\" Doc is NULL\"); return OK; &#125; if(doc-&gt;root==NULL) &#123; ap_rprintf(r,\" root is NULL\"); return OK; &#125; dump_xml(r,doc-&gt;root); return OK;&#125;static void mod_soap_register_hooks(apr_pool_t *p)&#123; ap_hook_handler(mod_soap_handler, NULL, NULL, APR_HOOK_MIDDLE);&#125;/* Dispatch list for API hooks */module AP_MODULE_DECLARE_DATA soap_module = &#123; STANDARD20_MODULE_STUFF, NULL, /* create per-dir config structures */ NULL, /* merge per-dir config structures */ NULL, /* create per-server config structures */ NULL, /* merge per-server config structures */ NULL, /* table of config file commands */ mod_soap_register_hooks /* register hooks */&#125;; Install这个module，之后向apache发送一个SOAP request，例如： 123456789&lt;soapenv:Envelope xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:urn=\"urn:AventailLogonV2\"&gt; &lt;soapenv:Header/&gt; &lt;soapenv:Body&gt; &lt;urn:getMicroInterrogationList soapenv:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"&gt; &lt;version xsi:type=\"xsd:int\"&gt;2&lt;/version&gt; &lt;logonId xsi:type=\"xsd:string\"&gt;QAABAFrlfQsUJvsQVh5kRozpavo=&lt;/logonId&gt; &lt;/urn:getMicroInterrogationList&gt; &lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt; Apache server会回复如下内容： 123456789101112Name：Envelopecdata：Name：Headercdata：Name：Bodycdata：Name：getMicroInterrogationListcdata： Name：versioncdata：2Name：logonIdcdata：QAABAFrlfQsUJvsQVh5kRozpavo= 结语进一步的开发就很容易了，只要按照自己的需要去处理数据就可以了。","tags":[{"name":"apache","slug":"apache","permalink":"http://matthewgao.github.io/tags/apache/"},{"name":"xml","slug":"xml","permalink":"http://matthewgao.github.io/tags/xml/"}]},{"title":"用C++进行 Apache Module 开发","date":"2013-05-14T04:52:36.000Z","path":"2013-5-14-Apache-with-cpp/","text":"为什么要用C++很多时候我们可以不必使用C++，很多时候linux开发只要用C就可以了，但是在对于一些大型应用程序，他本身就是由C++编写，而Apache Module又只能默认使用C，所以不能够用apxs来编译module，只能够通过g++，但是这里就需要一点要的技巧来搞定它。 Why因为Apache是通过dlopen()/dlsym()来加载module的，但是这两个函数不能够很好的处理C++的命名方式，所以如果用g++来编译so文件，就会出现不能够找到module的情况。 Solution所以我们要强制它以C语言的方式来编译，在module的声明前加上extern 或者extern “C” 1extern module AP_MODULE_DECLARE_DATA soap_module; 或者 1extern “C” module AP_MODULE_DECLARE_DATA soap_module; 更进一步的，可以使用如下定义： 123456789101112#ifdef __cplusplusextern \"C\" &#123;#endif//TO-DO#ifdef __cplusplus&#125;#endif~~~ 再通过g++来编译~~~ g++ -fPIC -shared -o mod_soap.so mod_soap.c test.o -I/usr/include/apr-1.0 -I/usr/include/openssl -I/usr/include/xmltok -pthread -I/usr/include/apache2 -I/usr/include/apr-1.0 -I/usr/include/apr-1.0 -I/usr/include/httpd -std=c++0x 就可以得到正确的module了，下面就可以使用apxs来安装module 1sudo apxs2 -i mod_soap.so","tags":[{"name":"apache","slug":"apache","permalink":"http://matthewgao.github.io/tags/apache/"},{"name":"module dev","slug":"module-dev","permalink":"http://matthewgao.github.io/tags/module-dev/"}]},{"title":"Bitcoin 原理","date":"2013-05-13T04:52:36.000Z","path":"2013-5-13-Bitcoin/","text":"Bitcoin是最早实现“加密货币”这一概念的系统，该设想最早由戴伟（Dai Wei,音译）于1998年在cypherpunks函件用户组首次提出的。 它建立在这样一个概念之上，即货币可以是任何东西或记录，只要它在一个国家或社会经济体系内被接受为商品服务的支付方式，或是债务偿还的方式。比特币的设计核心思想是以数学题答案作为货币，其发行权独立于任何中央机构之外。 我是最近接触Bitcoin的，他的复杂的机制和需要大规模的计算来换取BTC（bitcoin的缩写）很吸引我，我花了些时间简单的了解他的机理，由于网上对他的介绍的中文很少，而且有些写得不是很对，容易误导，官网wiki中文只翻译了部分，所以我写了这个，供大家参考。 明确概念 第一个是BTC，就是这个货币，和RMB一样是个单位 第二，Transaction，表示一条交易记录，里面包含了货币接收方的address和BTC数量 第三，Block，多个Transaction打包存为一个Block，每一个人的机器上都会自动下载所有的Blocks，从而才能够进行转账和查看address中金额，也就是说每个人的电脑都存数了网络上所有的交易（Transaction） 第四，Blocks-chain，所有的Block都是连起来的，组成一个Block链。address相当于我们现实生活中的帐号，是你账户的唯一标识。 密码学的知识公开密钥加密（Public-key cryptography，也称为非对称密钥加密），该加密算法使用两个不同的密钥，各名为加密密钥和解密密钥。前者公开，又称公开密钥，简称公钥。后者保密，又称私有密钥，简称私钥。这两个金钥是数学相关，用某用户加密密钥加密后所得的信息，只能用该用户的解密密钥才能解密。公钥加密的另一用途是身份验证：用私钥加密的信息，可以用公钥对其解密。接收者由此可知：这条信息确实来自于拥有私钥的某人，公钥的形式就是数字证书。Bitcoin正是利用了这个加密方法的密钥不对称性的优点。address（例如1KTj9TdiXtPcerF4XsCsFWU5NEPpFfdLiv）实际上就是一个公钥，每一个有address的人的计算机中都会存有这个公钥对应的私钥，每一次对这个address中的BTC的转出交易必须有私钥进行签署，如果你的私钥丢失了，那么你的这个address里的BTC就再也拿不出来了。 工作原理转账的过程是这样的：把你要转到的address和金额合并成一个Transaction，并用你自己的私钥进行签署，并发到整个P2P的网络上，所以网络上所有的拥有你address的人都可以看的到这笔Transaction是要从哪里转到哪里转了多少钱，但是由于没有私钥，他们没有办法修改。 我们有了一个新的Transaction就要有一个Block来存储它，所以要不断的生成Block，按照计划平均每十分钟生成一个Block，这个block成功生成后会给生成这个Block的人一笔奖赏，这就是miner赚钱的方法，这个我们一会再说。生成了一个存有这个transaction的block之后，那么整个blocks-chain的长度就增加了一个，所以网络上会以丢弃所有比这个短的block-chain的分支，所有的在线节点也会自动下载这个新的Block加到自己的index中来，当在网络上有一定人数的人认可你的transaction了，那么交易就认为合法。 防伪造怎么防止伪造货币？由于每一笔Transaction中都存数了来源address和目的addresss，所以每一笔钱都是可以追根溯源的，如果你想非法造币，那么你要修改整条chain，还要保证你的chain最后最长，所以如果你想自己伪造BTC货币那么你就要控制P2P网络上相当大一部分的机器，要他们生成新Block的速度比你自己伪造的速度慢，这样你伪造的才可能被公认，但是这个是相当小概率事件，几乎绝对不可能。 如果 p2p 网络过大，交易Transaction不能尽量的迅速的广播到全网络。就会出来 p2p 的网络的局部保持有小群体共同认可的一份全局Transaction。多个全局Transaction的分支同时发展是有可能的。因为每个小群体都可能认为他们看见的那部分更长更有效。但是， 只有有人发现另一条分支更长，它就会转换阵营。所以，有一定的可能性，你的Transaction被一个小群体接受，但在一段时间后，被更大的阵营抛弃，所以非法的总会是非法的。 挖矿下面我们说怎么赚钱，也就是mining，挖矿，block的生成非常苛刻，一定要保证block的hash值的前几位为0，这个0的个数越多，需要计算的时间就越长，复杂度越大，所以如果网络中有一个人用了最短的时间生成了这个Block他将有权利在这个block中生成一个Transaction，而这个Transaction是给他的address中存取一定数额的BTC，现在这个数额是50BTC，按照规则，每四年数额减半，那么若干年后，BTC的数额少的可怜时候，谁来做miner，那么有另一个机制，就是可以从你给打包的Transaction那里收取fee，也就是消费，如果他给的多那么你当然会把它加进你的Block中来，从而你可以从所有的Block中的所有Transactions的fee中获得利润。 所以现在开始mining吧，根据现在的BTC对USD的汇率是8.1，这个汇率每天都在浮动，如果你能自己创建一个block，那你就有50*8.1美元了。 首先你要有一个address，所以你要去下载一个client，然后安装它，运行时会自动生成一个address，之后他会自动从网上下载所有的blocks，现在大概有128000个blocks，这个时候你的address才能够进行转账和查看transaction信息等等。 如果你想自己mining，那可能你能制造一个block的概率很低，所以你不如加入一个mining pool，这样你的每一部分贡献会得到一定回报，相当于你贡献出你的计算量大家一起来挖一个。另外，CPU的挖矿能力也不太行了，都要用GPU，我用过一个AMD的CPU只能达到3Mhash/s，但是用GPU就完全不同了，nVIDIA的GPU采用CUDA架构在双精度计算上有优势，但是hash都是整型计算，CUDA似乎并不太适合，也可能是他用openCL的标准性能不高，总是ATI要比nVIDA的效率高，我用两张Tesla C1060的卡只能达到104Mhash/s，但是用ati的5870一张卡就能达到370Mhash/s。 总之下载好GPU挖矿的软件，去注册个mining pool的帐号，我用的是http://deepbit.net/，然后绑定你的address，设置好最小的收款金额，就可以开始挖矿啦。我挖了两天已经有0.34BTC了。 对了，由于你的address是要你自己维护的，要备份好wallet.dat文件，因为这里存储的是你的私钥，如果这个丢了那么你的钱就没有了，为了避免这个悲剧发生，简易你去注册个wallet，我用的是https://www.mybitcoin.com 这样wallet都有他们来托管，我们只要用账户登录就可以了（和支付宝有那么一点相似） 参考连接 [1] https://en.bitcoin.it/wiki/Main_Page 官方WIKI [2] http://www.bitcoin.org/ 官方网站 [3] http://shaneliu.org/archives/506 强烈推荐看看这篇 [4] http://btcchina.com/index.php 一个中文论坛 [5] https://github.com/downloads/Kiv/poclbm/guiminer-20110521.exe GUI的GPU挖矿程序 如果你觉得我写的对你有帮助可以denote我，我的address是：1H8FR8aWYCBd8MoXCBoEQUqw6pH7bq6kXi","tags":[{"name":"bitcoin","slug":"bitcoin","permalink":"http://matthewgao.github.io/tags/bitcoin/"}]},{"title":"Apache Module 开发入门","date":"2013-05-10T04:52:36.000Z","path":"2013-5-13-Apache/","text":"Actually to build a apache module is not very hard if you can find a nice way to do it. Here I want to show you my way. The EnvironmentTo build a apache module you have to install two things: Apache http server APR(apache portable runtime) Nothing much to describe How to install these, Just apt-get install!!(Debian) Build a Module sampleif you have successfuly installed these two kinds of thing above, you can use the following command to automatically build a module sample 1sudo apxs2 -n mod_foo -g Now you can see a mod_foo.c and a Makefile in your working dirtectroy. Next! How to use it?To play with this sample module first compile it into a DSO file and install it into Apache’s modules directory by running: 1apxs -c -i mod_foo.c Then activate it in Apache’s apache2.conf file for instance for the URL /foo in as follows: 12345#apache2.confLoadModule foo_module modules/mod_foo.so&lt;Location /foo&gt; SetHandler foo&lt;/Location&gt; Then after restarting Apache via 1apachectl restart you immediately can request the URL /foo and watch for the output of this module. This can be achieved for instance via: 1lynx -mime_header http://localhost/foo The output should be similar to the following one: 12345HTTP/1.1 200 OKDate: Tue, 31 Mar 1998 14:42:22 GMTServer: Apache/1.3.4 (Unix)Connection: closeContent-Type: text/html More infomation: Looking at 《The Apache Module Book》you can find a pdf version on the internet.","tags":[{"name":"apache","slug":"apache","permalink":"http://matthewgao.github.io/tags/apache/"},{"name":"module dev","slug":"module-dev","permalink":"http://matthewgao.github.io/tags/module-dev/"}]},{"title":"Markdown sample","date":"2012-07-06T04:52:36.000Z","path":"Markdown-sample/","text":"Head1Head2Head3ajgjgrrg This text will be italic This text will be bold In the words of Abraham Lincoln: Pardon my french Item 1 Item 2 ֵ ���� baseline Ĭ��Ԫ�ط����ڸ�Ԫ�صĻ����� sub ��ֱ�����ı����±� super ��ֱ�����ı����ϱ� top ��Ԫ�صĶ�������������Ԫ�صĶ��˶��� Reference of /proc/sys/net/core","tags":[{"name":"markdown","slug":"markdown","permalink":"http://matthewgao.github.io/tags/markdown/"}]}]